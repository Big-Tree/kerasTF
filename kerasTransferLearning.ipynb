{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-10T14:08:12.704576Z",
     "start_time": "2018-08-10T14:04:19.605001Z"
    },
    "code_folding": [
     102,
     107,
     131,
     155,
     179,
     188,
     214,
     238,
     280,
     291,
     305,
     413
    ],
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keras version:  2.2.0\n",
      "TensorFlow version:  1.7.1\n",
      "\n",
      "Loading images...\n",
      "Getting dicom images\n",
      "/vol/vssp/cvpwrkspc01/scratch/wm0015/download/prem/Segments/\n",
      "1176  Files found\n",
      "Loading images...\n",
      "/vol/vssp/cvpwrkspc01/scratch/wm0015/download/prem/2D/6mm/\n",
      "531  Files found\n",
      "Loading images...\n",
      "tmp[0].shape:  (531, 429, 429, 1)\n",
      "tmp[1].shape:  (531, 429, 429, 1)\n",
      "data[Img].shape =  (1062, 429, 429, 1)\n",
      "data[Img].shape =  (1062, 429, 429, 3)\n",
      "labels0.shape:  (531, 2)\n",
      "labels1.shape:  (531, 2)\n",
      "data[label].shape:  (1062, 2)\n",
      "data[img].dtype:  float64\n",
      "data[img].dtype:  float64\n",
      "val_data[label].shape:  (53, 2)\n",
      "test_data[label].shape:  (53, 2)\n",
      "train_data[label].shape:  (956, 2)\n",
      "Train...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/user/HS204/wm0015/anaconda3/envs/tensorflow/lib/python3.6/site-packages/keras/callbacks.py:432: RuntimeWarning: Can save best model only with val_accuracy available, skipping.\n",
      "  'skipping.' % (self.monitor), RuntimeWarning)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m-----------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-38-6553acc18e5c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    561\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 563\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-38-6553acc18e5c>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    516\u001b[0m                     \u001b[0mEarlyStopping\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmonitor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'val_loss'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpatience\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mPATIENCE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    517\u001b[0m                     ModelCheckpoint(filepath=MODEL_SAVE, monitor='val_accuracy', save_best_only=True)],\n\u001b[0;32m--> 518\u001b[0;31m                 validation_data=(val_data['img'], val_data['label']))\n\u001b[0m\u001b[1;32m    519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m         \u001b[0;31m# Restore best model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1040\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1042\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1043\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1044\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.6/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2665\u001b[0m                     \u001b[0;34m'In order to feed symbolic tensors to a Keras model '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2666\u001b[0m                     'in TensorFlow, you need tensorflow 1.8 or higher.')\n\u001b[0;32m-> 2667\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2668\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2669\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_legacy_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2647\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2648\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[0;32m-> 2649\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2650\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2651\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    903\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    904\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 905\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    906\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    907\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1107\u001b[0m             \u001b[0mfeed_handles\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msubfeed_t\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msubfeed_val\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1108\u001b[0m           \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1109\u001b[0;31m             \u001b[0mnp_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubfeed_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msubfeed_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1110\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1111\u001b[0m           if (not is_tensor_handle_feed and\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.6/site-packages/numpy/core/numeric.py\u001b[0m in \u001b[0;36masarray\u001b[0;34m(a, dtype, order)\u001b[0m\n\u001b[1;32m    490\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m     \"\"\"\n\u001b[0;32m--> 492\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    493\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    494\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# fold\n",
    "import numpy as np\n",
    "import cv2\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "from keras.models import Sequential\n",
    "import keras\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.utils import np_utils\n",
    "from keras import optimizers\n",
    "# For some reason I have to tell it to use TensorFlows dimension ordering\n",
    "from keras import backend as K\n",
    "K.set_image_dim_ordering('tf')\n",
    "from keras.callbacks import TensorBoard, EarlyStopping, ModelCheckpoint\n",
    "from time import time\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from keras import applications\n",
    "from keras.utils import multi_gpu_model\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "config = tf.ConfigProto()\n",
    "#config.gpu_options.per_process_gpu_memory_fraction = 0.5\n",
    "config.gpu_options.visible_device_list = \"2,3\"\n",
    "config.gpu_options.allow_growth = True\n",
    "set_session(tf.Session(config=config))\n",
    "\n",
    "# Globals\n",
    "VERBOSE = 0\n",
    "ARCHITECTURE = 0\n",
    "NORMALISE = 4096\n",
    "# Class 0 = backgrounds\n",
    "# Prem..\n",
    "CLASSDIR_0 = '/vol/vssp/cvpwrkspc01/scratch/wm0015/download/prem/Segments/'#P_Tomo_6CMBCF_XYZ_5*'\n",
    "CLASSDIR_1 = '/vol/vssp/cvpwrkspc01/scratch/wm0015/download/prem/2D/6mm/'#P_6CMBCF*'\n",
    "# CLASSDIR_0 = '/vol/vssp/cvpwrkspc01/scratch/wm0015/download/prem/Segments/'#P_Tomo_6CMBCF_XYZ_5*'\n",
    "# CLASSDIR_1 = '/vol/vssp/cvpwrkspc01/scratch/wm0015/download/prem/2D/my/6mm_c95'#P_6CMBCF*\n",
    "\n",
    "# CLASSDIR_0 = '/vol/vssp/cvpwrkspc01/scratch/wm0015/download2/4AFC-study-data/BgTomoFiltered_visualcheck_6mm'\n",
    "# CLASSDIR_1 = '/vol/vssp/cvpwrkspc01/scratch/wm0015/download2/4AFC-study-data/Final_dataset/2D/6mm'\n",
    "# CLASSDIR_0 = '/vol/vssp/cvpwrkspc01/scratch/wm0015/crops256/malignant/1.2.840.113619.2.227.2079*'\n",
    "# CLASSDIR_1 = '/vol/vssp/cvpwrkspc01/scratch/wm0015/crops256/malignant/1.2.840.113619.2.227.2079*'\n",
    "# CLASSDIR_0 = '/vol/vssp/cvpwrkspc01/scratch/wm0015/crops256/normal/*'\n",
    "# CLASSDIR_1 = '/vol/vssp/cvpwrkspc01/scratch/wm0015/crops256/malignant/*'\n",
    "\n",
    "# Calcs\n",
    "# CLASSDIR_0 = '/user/HS204/wm0015/student/allCalcs/0/*'\n",
    "# CLASSDIR_1 = '/user/HS204/wm0015/student/allCalcs/1/*'\n",
    "MODEL_SAVE = '/vol/vssp/cvpwrkspc01/scratch/wm0015/models/best_model.h5'\n",
    "BATCH_SIZE = 100\n",
    "EPOCHS = 1000\n",
    "TRAIN_RATIO = 0.9\n",
    "INPUT_SHAPE = [429, 429, 3]\n",
    "# INPUT_SHAPE = [256, 256, 3]\n",
    "#INPUT_SHAPE = [385, 385, 3]\n",
    "FOLDS = 10\n",
    "PATIENCE = 500\n",
    "\n",
    "class TrainValTensorBoard(TensorBoard):\n",
    "    def __init__(self, log_dir='/vol/vssp/mammo2/will/logs/new', **kwargs):\n",
    "        # Make the original `TensorBoard` log to a subdirectory 'training'\n",
    "        fCount=0\n",
    "        while os.path.exists(os.path.join(log_dir, 'training' + '_' + str(fCount))):\n",
    "            fCount+=1\n",
    "        training_log_dir = os.path.join(log_dir, 'training' + '_' + str(fCount))\n",
    "        super(TrainValTensorBoard, self).__init__(training_log_dir, **kwargs)\n",
    "\n",
    "        # Log the validation metrics to a separate subdirectory\n",
    "        self.val_log_dir = os.path.join(log_dir, 'validation' + '_' + str(fCount))\n",
    "\n",
    "    def set_model(self, model):\n",
    "        # Setup writer for validation metrics\n",
    "        self.val_writer = tf.summary.FileWriter(self.val_log_dir)\n",
    "        super(TrainValTensorBoard, self).set_model(model)\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        # Pop the validation logs and handle them separately with\n",
    "        # `self.val_writer`. Also rename the keys so that they can\n",
    "        # be plotted on the same figure with the training metrics\n",
    "        logs = logs or {}\n",
    "        val_logs = {k.replace('val_', ''): v for k, v in logs.items() if k.startswith('val_')}\n",
    "        for name, value in val_logs.items():\n",
    "            summary = tf.Summary()\n",
    "            summary_value = summary.value.add()\n",
    "            summary_value.simple_value = value.item()\n",
    "            summary_value.tag = name\n",
    "            self.val_writer.add_summary(summary, epoch)\n",
    "        self.val_writer.flush()\n",
    "\n",
    "        # Pass the remaining logs to `TensorBoard.on_epoch_end`\n",
    "        logs = {k: v for k, v in logs.items() if not k.startswith('val_')}\n",
    "        super(TrainValTensorBoard, self).on_epoch_end(epoch, logs)\n",
    "\n",
    "    def on_train_end(self, logs=None):\n",
    "        super(TrainValTensorBoard, self).on_train_end(logs)\n",
    "        self.val_writer.close()\n",
    "\n",
    "    \n",
    "        \n",
    "def getSensitivityCallback(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    return true_positives / (possible_positives + K.epsilon())\n",
    "def getSpecificityCallback(y_true, y_pred):\n",
    "    true_negatives = K.sum(K.round(K.clip((1-y_true) * (1-y_pred), 0, 1)))\n",
    "    possible_negatives = K.sum(K.round(K.clip(1-y_true, 0, 1)))\n",
    "    return true_negatives / (possible_negatives + K.epsilon())        \n",
    "\n",
    "def getBitDepth(img):\n",
    "    print('Bit depth: img.shape: ', img.shape)\n",
    "    print('img.shape: ', img.shape)\n",
    "    maxmax = 0\n",
    "    count = 0\n",
    "    for _ in img:\n",
    "        count += 1\n",
    "        print(np.amax(_), ' ', count)\n",
    "        if np.amax(_) > maxmax:\n",
    "            maxmax = np.amax(_)\n",
    "    return maxmax\n",
    "\n",
    "def get_labels_one_hot(num_classes, class_id, num_samples):\n",
    "    x = np.zeros((num_samples, num_classes))\n",
    "    x[np.arange(num_samples),class_id] = 1\n",
    "    return x\n",
    "\n",
    "def fourCNN():\n",
    "    model = Sequential()\n",
    "    # Layer 1\n",
    "    model.add(Conv2D(32, (3,3), activation='relu', input_shape=INPUT_SHAPE, data_format='channels_last'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    # Layer 2\n",
    "    model.add(Conv2D(32, (3,3), activation='relu')) \n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    # Layer 3    \n",
    "    model.add(Conv2D(32, (3,3), activation='relu'))  \n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    # Layer 4     \n",
    "    model.add(Conv2D(32, (3,3), activation='relu'))   \n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))    \n",
    "    # Layer 5     \n",
    "    #model.add(Conv2D(32, (3,3), activation='relu'))   \n",
    "    #model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    # Layer 6\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1024, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(2, activation='softmax'))\n",
    "    return model\n",
    "    \n",
    "def fiveCNN():\n",
    "    model = Sequential()\n",
    "    # Layer 1\n",
    "    model.add(Conv2D(32, (3,3), activation='relu', input_shape=INPUT_SHAPE, data_format='channels_last'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    # Layer 2\n",
    "    model.add(Conv2D(32, (3,3), activation='relu')) \n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    # Layer 3    \n",
    "    model.add(Conv2D(32, (3,3), activation='relu'))  \n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    # Layer 4     \n",
    "    model.add(Conv2D(32, (3,3), activation='relu'))   \n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))    \n",
    "    # Layer 5     \n",
    "    model.add(Conv2D(32, (3,3), activation='relu'))   \n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    # Layer 6\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1024, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(2, activation='softmax'))  \n",
    "    return model\n",
    "    \n",
    "def bigCNN():\n",
    "    model = Sequential()\n",
    "    # Layer 1\n",
    "    model.add(Conv2D(32, (3,3), activation='relu', input_shape=INPUT_SHAPE, data_format='channels_last'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    # Layer 2\n",
    "    model.add(Conv2D(64, (3,3), activation='relu')) \n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    # Layer 3    \n",
    "    model.add(Conv2D(124, (3,3), activation='relu'))  \n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    # Layer 4     \n",
    "    model.add(Conv2D(256, (3,3), activation='relu'))   \n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))    \n",
    "    # Layer 5     \n",
    "    model.add(Conv2D(512, (3,3), activation='relu'))   \n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    # Layer 6\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1024, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(2, activation='softmax'))  \n",
    "    return model\n",
    "\n",
    "def vgg():\n",
    "    vggModel = applications.VGG19(weights = 'imagenet', include_top=False, input_shape = INPUT_SHAPE)\n",
    "    # Add custom final layer\n",
    "    model = vggModel.output\n",
    "    model = Flatten()(model)\n",
    "    model = Dense(2, activation='softmax')(model)\n",
    "    model = keras.models.Model(inputs=vggModel.input, outputs=model)\n",
    "    return model\n",
    "\n",
    "def tlVGG(train_data, val_data):\n",
    "    print('Compute bottleneck features...')\n",
    "    vggModel = applications.VGG19(weights = \"imagenet\", include_top=False, input_shape = INPUT_SHAPE)\n",
    "    # Freeze all layers\n",
    "    for layer in vggModel.layers:\n",
    "        layer.trainable = False\n",
    "    # Add custom final layer\n",
    "    bNModel = vggModel.output\n",
    "    bNModel = Flatten()(bNModel)\n",
    "    final_model = keras.models.Model(inputs=vggModel.input, outputs=bNModel)\n",
    "    train_bNFeatures = {'img': 0, 'label': train_data['label']}\n",
    "    val_bNFeatures = {'img': 0, 'label': val_data['label']}\n",
    "    train_bNFeatures['img'] = final_model.predict(train_data['img'], batch_size=16)\n",
    "    val_bNFeatures['img'] = final_model.predict(val_data['img'], batch_size=16)\n",
    "    #Undo one hot - ROC does not work with onehot\n",
    "    val_bNFeatures.update({'labelIndex': np.where(val_data['label']==1)[1]})\n",
    "    print('train_bNFeatures[img].shape = ', train_bNFeatures['img'].shape)\n",
    "    print('val_bNFeatures[img].shape = ', val_bNFeatures['img'].shape)\n",
    "\n",
    "    print('Train head...')\n",
    "    head = Sequential()\n",
    "    #head.add(Dense(32, input_dim=train_bNFeatures['img'].shape[1], activation='relu'))\n",
    "    head.add(Dense(2, activation='softmax'))    \n",
    "    return head, train_bNFeatures, val_bNFeatures\n",
    "\n",
    "    # Why oh why are they in a directory structure like this\n",
    "def getPremFiles(imgPath, dataSpecs):\n",
    "    import pydicom\n",
    "    from fnmatch import fnmatch\n",
    "    # First get all the 6mm lesions\n",
    "    fileList = []\n",
    "    for path, subdirs, files in os.walk(imgPath):\n",
    "        for name in files:\n",
    "            if fnmatch(name, '2D_dim2d.dcm'):\n",
    "                fileList.append(os.path.join(path, name))\n",
    "    # I can't remember why I thought dataSpecs was a good idea\n",
    "    # I suppose this means that class 0 needs to be loaded in first\n",
    "    dataSpecs['classLength'].append(len(fileList))\n",
    "    \n",
    "    # Load the files from filelist into an array\n",
    "    print(len(fileList), ' Files found')\n",
    "    print('Loading images...')\n",
    "    dicomImg = np.asarray([])\n",
    "    count = 0\n",
    "    for f in fileList:\n",
    "        dicomImg = np.append(dicomImg, pydicom.dcmread(f).pixel_array)\n",
    "        count += 1\n",
    "        print(count, '/', len(fileList))\n",
    "    return dicomImg\n",
    "\n",
    "def getDicomImages(data, paths, strMatch = '*.dcm', verbose = True):  \n",
    "    print('Getting dicom images')\n",
    "    import pydicom\n",
    "    from fnmatch import fnmatch\n",
    "    # Get file paths of images\n",
    "    tmp = [[],[]]\n",
    "    for index, p in enumerate(paths):\n",
    "        fileList = []\n",
    "        print(p)\n",
    "        for path, subdirs, files in os.walk(p):\n",
    "            for name in files:\n",
    "                if fnmatch(name, strMatch): # '2D_dim2d.dcm'\n",
    "                    fileList.append(os.path.join(path, name))\n",
    "        data['classLength'].append(len(fileList))\n",
    "        if len(fileList) == 0:\n",
    "            print('MY_ERROR: NO FILES FOUND')\n",
    "        # Load the files from filelist into an array\n",
    "        print(len(fileList), ' Files found')\n",
    "        print('Loading images...')\n",
    "        data['img'] = np.asarray([])\n",
    "        count = 0\n",
    "        for f in fileList:\n",
    "            tmp[index] = np.append(tmp[index], pydicom.dcmread(f).pixel_array)\n",
    "            count += 1\n",
    "            if verbose == True:\n",
    "                print(count, '/', len(fileList))\n",
    "    # Reshape the images\n",
    "    tmp[0] = tmp[0].reshape((-1, INPUT_SHAPE[0], INPUT_SHAPE[1], 1))\n",
    "    tmp[0] = tmp[0][0:data['classLength'][1],:,:,:] # Balance the dataset\n",
    "    tmp[1] = tmp[1].reshape((-1, INPUT_SHAPE[0], INPUT_SHAPE[1], 1))\n",
    "    \n",
    "    # Update class length\n",
    "    data['classLength'][0] = tmp[0].shape[0]\n",
    "    data['classLength'][1] = tmp[1].shape[0]\n",
    "    \n",
    "    # Concatenate the classes\n",
    "    print('tmp[0].shape: ', tmp[0].shape)\n",
    "    print('tmp[1].shape: ', tmp[1].shape)\n",
    "    data['img'] = np.concatenate((tmp[0],tmp[1]))\n",
    "    # Add the channels\n",
    "    print('data[Img].shape = ', data['img'].shape)\n",
    "    data['img'] = np.concatenate((data['img'], data['img'], data['img']), axis = 3)\n",
    "    print('data[Img].shape = ', data['img'].shape)\n",
    "    return data\n",
    "\n",
    "# For non dicom images\n",
    "def getImages(data, paths):    \n",
    "    print('Getting non-dicom images')\n",
    "    tmp = [[],[]]\n",
    "    for index, p in enumerate(paths):\n",
    "        fileList = glob.glob(p) #'BengaliBMPConvert/*.bmp' \n",
    "        data['classLength'].append(len(fileList))\n",
    "        tmp[index] = np.array([(cv2.imread(fname)) for fname in fileList])\n",
    "    print('tmp[0].shape: ', tmp[0].shape)\n",
    "    print('tmp[1].shape: ', tmp[1].shape)\n",
    "    data['img'] = np.concatenate((tmp[0], tmp[1]))\n",
    "    return data\n",
    "\n",
    "def getImagesOld(path, dataSpecs):\n",
    "    fileList = glob.glob(path) #'BengaliBMPConvert/*.bmp'   \n",
    "    num = len(fileList)\n",
    "    dataSpecs['classLength'].append(len(fileList))\n",
    "    x = np.array([(cv2.imread(fname)) for fname in fileList])\n",
    "    return x\n",
    "\n",
    "    # Comment out for prem images\n",
    "#     data['img'] = np.concatenate((\n",
    "#             get_images(CLASSDIR_0, dataSpecs), # Class 0 (backgrounds)\n",
    "#             get_images(CLASSDIR_1, dataSpecs) # Class 1 \n",
    "#     ))         \n",
    "\n",
    "\n",
    "def colourDrop3to1(data):   \n",
    "    data['img'] = data['img'][:,:,:,0]\n",
    "    data['img'] = np.reshape(data['img'], (data['img'].shape[0],data['img'].shape[1],data['img'].shape[2],1))\n",
    "    print('new data shape = ', data['img'].shape)\n",
    "    return data\n",
    "\n",
    "def getSensitivity(y_true, y_score):\n",
    "    y_score = np.rint(y_score)\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true, y_score, labels=[0,1]).ravel()\n",
    "    #print('Sensitivity:\\ny_true:\\n', y_true, '\\ny_score:\\n', y_score)\n",
    "    #print(' tn: ', tn, ' fp: ', fp, ' fn: ', fn, ' tp: ', tp)\n",
    "    return tp/(tp+fn)\n",
    "def getSpecificity(y_true, y_score):\n",
    "    y_score = np.rint(y_score)\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true, y_score, labels=[0,1]).ravel()\n",
    "    #print('Specificity:\\ny_true:\\n', y_true, '\\ny_score:\\n', y_score)\n",
    "    #print(' tn: ', tn, ' fp: ', fp, ' fn: ', fn, ' tp: ', tp)\n",
    "    return tn/(tn+fp)\n",
    "\n",
    "def splitDataset(data, seed = None, includeTestSet = True):\n",
    "    if includeTestSet == True:\n",
    "        # Shuffle data\n",
    "        if seed != None:\n",
    "            np.random.seed(seed) # Has to be set before each use of random\n",
    "        shuffleMask = np.random.permutation(data['img'].shape[0]) \n",
    "        data['img'] = data['img'][shuffleMask, :, :, :]\n",
    "        data['label'] = data['label'][shuffleMask, :]\n",
    "        # Split traing and validation data        \n",
    "        splitRatio = TRAIN_RATIO\n",
    "        splitPointVal = math.floor(data['img'].shape[0]*(1-splitRatio)/2)\n",
    "        splitPointTest = math.floor(data['img'].shape[0]*(1-splitRatio))\n",
    "        val_data = {'img': data['img'][0:splitPointVal], 'label': data['label'][0:splitPointVal]}\n",
    "        test_data = {'img': data['img'][splitPointVal:splitPointTest], 'label': data['label'][splitPointVal:splitPointTest]}\n",
    "        train_data = {'img': data['img'][splitPointTest:], 'label': data['label'][splitPointTest:]}\n",
    "\n",
    "        print('val_data[label].shape: ', val_data['label'].shape)\n",
    "        print('test_data[label].shape: ', test_data['label'].shape)        \n",
    "        print('train_data[label].shape: ', train_data['label'].shape)\n",
    "        #Undo one hot - ROC does not work with onehot\n",
    "        val_data.update({'labelIndex': np.where(val_data['label']==1)[1]})\n",
    "        test_data.update({'labelIndex': np.where(test_data['label']==1)[1]})\n",
    "        return train_data, val_data, test_data\n",
    "    else:\n",
    "        # Shuffle data\n",
    "        if setSeed != None:\n",
    "            np.random.seed(seed) # Has to be set before each use of random\n",
    "        shuffleMask = np.random.permutation(data['img'].shape[0]) \n",
    "        data['img'] = data['img'][shuffleMask, :, :, :]\n",
    "        data['label'] = data['label'][shuffleMask, :]\n",
    "        # Split traing and validation data        \n",
    "        splitRatio = TRAIN_RATIO\n",
    "        splitPoint = math.floor(data['img'].shape[0]*splitRatio)\n",
    "        train_data = {'img': data['img'][0:splitPoint], 'label': data['label'][0:splitPoint]}\n",
    "        val_data = {'img': data['img'][splitPoint:], 'label': data['label'][splitPoint:]}\n",
    "        print('TrainLabels.shape: ', train_data['label'].shape)\n",
    "        print('val_data.shape: ', val_data['label'].shape)\n",
    "        #Undo one hot - ROC does not work with onehot\n",
    "        val_data.update({'labelIndex': np.where(val_data['label']==1)[1]})\n",
    "        return train_data, val_data\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "def main():\n",
    "    import keras\n",
    "    print('keras version: ', keras.__version__)\n",
    "    print('TensorFlow version: ', tf.__version__)\n",
    "    print('\\nLoading images...')\n",
    "    \n",
    "    # Get images\n",
    "    data = {'img': 0, 'label': 0, 'classLength':[]}\n",
    "    #data = getImages(data, (CLASSDIR_0, CLASSDIR_1))\n",
    "    #data = getDicomImages(data, (CLASSDIR_0, CLASSDIR_1))\n",
    "    data = getDicomImages(data, (CLASSDIR_0, CLASSDIR_1), strMatch = '2D_dim2d.dcm', verbose = False)\n",
    "    \n",
    "    # Create one hot labels\n",
    "    labels0 = get_labels_one_hot(2, 0, data['classLength'][0])\n",
    "    labels1 = get_labels_one_hot(2, 1, data['classLength'][1])\n",
    "    print('labels0.shape: ', labels0.shape)\n",
    "    print('labels1.shape: ', labels1.shape)\n",
    "    data['label'] = np.concatenate((labels0, labels1))\n",
    "    \n",
    "    print('data[label].shape: ', data['label'].shape)\n",
    "    # Get bit depth\n",
    "#     print('Bit depth: ', getBitDepth(data['img']))\n",
    "#     return\n",
    "    # Normalise\n",
    "    print('data[img].dtype: ', data['img'].dtype)\n",
    "    data['img'] = data['img']/NORMALISE \n",
    "    print('data[img].dtype: ', data['img'].dtype)\n",
    "    \n",
    "    #data = colourDrop3to1(data)\n",
    "     \n",
    "    # After this things get a bit messy\n",
    "    #___________________________________________________\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    valStats = {'score':[], 'specificity':[], 'sensitivity':[]}\n",
    "    for crossVal in range(FOLDS):\n",
    "\n",
    "        train_data, val_data, test_data = splitDataset(data, seed = None)\n",
    "        \n",
    "#         # Shuffle data\n",
    "#         seed = 33\n",
    "#         #np.random.seed(seed) # Has to be set before each use of random\n",
    "#         shuffleMask = np.random.permutation(data['img'].shape[0]) \n",
    "#         data['img'] = data['img'][shuffleMask, :, :, :]\n",
    "#         data['label'] = data['label'][shuffleMask, :]\n",
    "#         # Split traing and validation data        \n",
    "#         splitRatio = TRAIN_RATIO\n",
    "#         splitPoint = math.floor(data['img'].shape[0]*splitRatio)\n",
    "#         train_data = {'img': data['img'][0:splitPoint], 'label': data['label'][0:splitPoint]}\n",
    "#         val_data = {'img': data['img'][splitPoint:], 'label': data['label'][splitPoint:]}\n",
    "#         print('TrainLabels.shape: ', train_data['label'].shape)\n",
    "#         print('val_data.shape: ', val_data['label'].shape)\n",
    "#         #Undo one hot - ROC does not work with onehot\n",
    "#         val_data.update({'labelIndex': np.where(val_data['label']==1)[1]})\n",
    "\n",
    "        \n",
    "\n",
    "        #model, train_data, val_data = tlVGG(train_data, val_data)\n",
    "        model = fiveCNN()\n",
    "        model = multi_gpu_model(model, gpus=2)\n",
    "        if ARCHITECTURE != 0:\n",
    "            model.summary()  \n",
    "        \n",
    "        sgd = optimizers.SGD(lr=5, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "        adam = optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False) #0.001\n",
    "        model.compile(loss='binary_crossentropy',\n",
    "                    optimizer=adam,\n",
    "                     metrics=['accuracy'])#, getSensitivityCallback, getSpecificityCallback])\n",
    "        tensorboard = TensorBoard(log_dir='/vol/vssp/mammo2/will/logs/new'.format(time()), write_images=True)\n",
    "\n",
    "        # Data augmentation settings\n",
    "        if (1 == 2):\n",
    "            from keras.preprocessing.image import ImageDataGenerator\n",
    "            trainDatagen = ImageDataGenerator(\n",
    "                featurewise_center=True,\n",
    "                featurewise_std_normalization=True,\n",
    "                rotation_range=20,\n",
    "                width_shift_range=0.2,\n",
    "                height_shift_range=0.2,\n",
    "                horizontal_flip=True)\n",
    "            trainDatagen.fit(train_data['img'])\n",
    "            valDatagen = ImageDataGenerator(\n",
    "                featurewise_center=True,\n",
    "                featurewise_std_normalization=True,\n",
    "                #rotation_range=20,\n",
    "                #width_shift_range=0.2,\n",
    "                #height_shift_range=0.2,\n",
    "                #horizontal_flip=True\n",
    "                )\n",
    "            valDatagen.fit(val_data['img'])\n",
    "        \n",
    "#         # Normalise myself\n",
    "#         mean_data = np.mean(train_data['img'])\n",
    "#         std_data = np.std(train_data['img'])\n",
    "#         train_data['img'] = (train_data['img']-mean_data)/std_data\n",
    "#         val_data['img'] = (val_data['img']-mean_data/std_data)\n",
    "        \n",
    "#        # Train, with data augmentation\n",
    "#         print('Train...')\n",
    "#         model.fit_generator(trainDatagen.flow(train_data['img'], train_data['label'], batch_size=32),\n",
    "#                     steps_per_epoch=len(train_data['img']) / 32, epochs=EPOCHS, verbose=VERBOSE,\n",
    "#                            callbacks=[\n",
    "#                                TrainValTensorBoard(write_graph=False),\n",
    "#                                EarlyStopping(monitor='val_loss', patience=PATIENCE, verbose=1),\n",
    "#                                ModelCheckpoint(filepath=MODEL_SAVE, monitor='val_accuracy', save_best_only=True)],\n",
    "#                            validation_data=valDatagen.flow(x = val_data['img'], y = val_data['label']))\n",
    "        \n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "        # Train\n",
    "        print('Train...')\n",
    "        model.fit(train_data['img'], train_data['label'], \n",
    "                batch_size=BATCH_SIZE, epochs=EPOCHS, verbose=VERBOSE,\n",
    "                callbacks=[\n",
    "                    TrainValTensorBoard(write_graph=False),\n",
    "                    EarlyStopping(monitor='val_loss', patience=PATIENCE, verbose=1),\n",
    "                    ModelCheckpoint(filepath=MODEL_SAVE, monitor='val_accuracy', save_best_only=True)],\n",
    "                validation_data=(val_data['img'], val_data['label']))\n",
    "        \n",
    "        # Restore best model\n",
    "        #model.load_weights(MODEL_SAVE)\n",
    "        \n",
    "        # Produce ROC curve\n",
    "        \n",
    "        y_pred_keras = model.predict(val_data['img'])  \n",
    "        y_true = val_data['labelIndex']\n",
    "        y_score = y_pred_keras[:,1]\n",
    "        fpr_keras, tpr_keras, thresholds_keras = roc_curve(y_true, y_score)\n",
    "        from sklearn.metrics import auc\n",
    "        auc_keras = auc(fpr_keras, tpr_keras)\n",
    "        plt.figure(1)\n",
    "        plt.plot([0, 1], [0, 1], 'k--')\n",
    "        plt.plot(fpr_keras, tpr_keras, label='DLMO (area = {:.3f})'.format(auc_keras))\n",
    "        plt.xlabel('False positive rate')\n",
    "        plt.ylabel('True positive rate')\n",
    "        plt.title('ROC curve')\n",
    "        plt.legend(loc='best')\n",
    "        plt.show()\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "        # Evaluate\n",
    "        score = model.evaluate(val_data['img'], val_data['label'], verbose=0)\n",
    "        valStats['score'].append(score)\n",
    "        print('The score is......\\n', score)\n",
    "        valStats['sensitivity'].append(getSensitivity(y_true, y_score))\n",
    "        valStats['specificity'].append(getSpecificity(y_true, y_score))\n",
    "        print('Sensitivity: ', valStats['sensitivity'][-1])\n",
    "        print('Specificity: ', valStats['specificity'][-1])\n",
    "  \n",
    "\n",
    "    valStatsScore = np.asarray(valStats['score'])\n",
    "    print('Validations: \\n', valStatsScore[:, 1])\n",
    "    print('Average loss: ', sum(valStatsScore[:, 0])/FOLDS)\n",
    "    print('Average validation: ', sum(valStatsScore[:, 1])/FOLDS)\n",
    "    print('\\n\\nSensitivities: \\n', valStats['sensitivity'])\n",
    "    print('\\nSpecificities: \\n', valStats['specificity'])\n",
    "    print('\\n\\nAverage sensitivity: ', sum(valStats['sensitivity'])/len(valStats['sensitivity']))\n",
    "    print('Average specificity: ', sum(valStats['specificity'])/len(valStats['specificity']))\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-05T16:34:48.948581Z",
     "start_time": "2018-08-05T16:34:48.943230Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello world\n"
     ]
    }
   ],
   "source": [
    "print('hello world')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-06T19:11:41.780687Z",
     "start_time": "2018-08-06T19:11:41.771524Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/vol/vssp/cvpwrkspc01/scratch/wm0015/download/prem/Segments\n",
      "/vol/vssp/cvpwrkspc01/scratch/wm0015/download/prem/2D/6mm\n"
     ]
    }
   ],
   "source": [
    "CLASSDIR_0 = '/vol/vssp/cvpwrkspc01/scratch/wm0015/download/prem/Segments'\n",
    "CLASSDIR_1 = '/vol/vssp/cvpwrkspc01/scratch/wm0015/download/prem/2D/6mm'\n",
    "\n",
    "def test(x):\n",
    "    for _ in x:\n",
    "        print(_)\n",
    "test((CLASSDIR_0, CLASSDIR_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-13T13:06:34.579475Z",
     "start_time": "2018-07-13T13:06:34.562536Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[6.53083827 0.59259259]\n",
      " [0.16470135 0.94444444]\n",
      " [0.15422182 0.94444444]\n",
      " [0.19875195 0.9382716 ]] \n",
      "\n",
      "6.5308382717179665\n",
      "[6.53083827 0.16470135 0.15422182 0.19875195]\n",
      "(4, 2)\n"
     ]
    }
   ],
   "source": [
    "x = [[6.5308382717179665, 0.5925925925925926], [0.16470135086112553, 0.9444444444444444], [0.15422181794304907, 0.9444444444444444], [0.19875195217721256, 0.9382716049382716]] \n",
    "x = np.asarray(x)\n",
    "print(x, '\\n')\n",
    "print(x[0][0])\n",
    "print(x[:, 0])\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "144px",
    "left": "1504px",
    "right": "20px",
    "top": "140px",
    "width": "350px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
