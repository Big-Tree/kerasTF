{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-31T18:21:50.948683Z",
     "start_time": "2018-07-31T18:20:42.149780Z"
    },
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keras version:  2.2.0\n",
      "TensorFlow version:  1.7.1\n",
      "\n",
      "Load images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compute bottleneck features...\n",
      "train_bNFeatures[img].shape =  (2673, 32768)\n",
      "val_bNFeatures[img].shape =  (297, 32768)\n",
      "Train head...\n",
      "Train on 2673 samples, validate on 297 samples\n",
      "Epoch 1/150\n",
      "2673/2673 [==============================] - 1s 438us/step - loss: 0.6842 - acc: 0.6693 - val_loss: 0.5394 - val_acc: 0.7475\n",
      "Epoch 2/150\n",
      "2673/2673 [==============================] - 0s 183us/step - loss: 0.4294 - acc: 0.8058 - val_loss: 0.4429 - val_acc: 0.7980\n",
      "Epoch 3/150\n",
      "2673/2673 [==============================] - 0s 183us/step - loss: 0.3547 - acc: 0.8459 - val_loss: 0.4021 - val_acc: 0.8047\n",
      "Epoch 4/150\n",
      "2673/2673 [==============================] - 0s 155us/step - loss: 0.3111 - acc: 0.8683 - val_loss: 0.5747 - val_acc: 0.7508\n",
      "Epoch 5/150\n",
      "2673/2673 [==============================] - 0s 143us/step - loss: 0.3017 - acc: 0.8736 - val_loss: 0.4416 - val_acc: 0.8047\n",
      "Epoch 6/150\n",
      "2673/2673 [==============================] - 0s 147us/step - loss: 0.2601 - acc: 0.8971 - val_loss: 0.3913 - val_acc: 0.8384\n",
      "Epoch 7/150\n",
      "2673/2673 [==============================] - 0s 140us/step - loss: 0.2447 - acc: 0.9072 - val_loss: 0.4273 - val_acc: 0.8148\n",
      "Epoch 8/150\n",
      "2673/2673 [==============================] - 0s 145us/step - loss: 0.2319 - acc: 0.9076 - val_loss: 0.3967 - val_acc: 0.8316\n",
      "Epoch 9/150\n",
      "2673/2673 [==============================] - 0s 116us/step - loss: 0.2203 - acc: 0.9181 - val_loss: 0.4437 - val_acc: 0.8047\n",
      "Epoch 10/150\n",
      "2673/2673 [==============================] - 0s 131us/step - loss: 0.2053 - acc: 0.9274 - val_loss: 0.4635 - val_acc: 0.8081\n",
      "Epoch 11/150\n",
      "2673/2673 [==============================] - 0s 120us/step - loss: 0.1898 - acc: 0.9312 - val_loss: 0.4307 - val_acc: 0.8114\n",
      "Epoch 12/150\n",
      "2673/2673 [==============================] - 0s 140us/step - loss: 0.1991 - acc: 0.9244 - val_loss: 0.4954 - val_acc: 0.8047\n",
      "Epoch 13/150\n",
      "2673/2673 [==============================] - 0s 149us/step - loss: 0.1870 - acc: 0.9293 - val_loss: 0.4096 - val_acc: 0.8249\n",
      "Epoch 14/150\n",
      "2673/2673 [==============================] - 1s 254us/step - loss: 0.1760 - acc: 0.9413 - val_loss: 0.4167 - val_acc: 0.8249\n",
      "Epoch 15/150\n",
      "2673/2673 [==============================] - 0s 156us/step - loss: 0.1663 - acc: 0.9413 - val_loss: 0.4058 - val_acc: 0.8384\n",
      "Epoch 16/150\n",
      "2673/2673 [==============================] - 0s 142us/step - loss: 0.1689 - acc: 0.9424 - val_loss: 0.4070 - val_acc: 0.8418\n",
      "Epoch 17/150\n",
      "2673/2673 [==============================] - 0s 121us/step - loss: 0.1681 - acc: 0.9420 - val_loss: 0.4835 - val_acc: 0.8081\n",
      "Epoch 18/150\n",
      "2673/2673 [==============================] - 0s 118us/step - loss: 0.1664 - acc: 0.9413 - val_loss: 0.4257 - val_acc: 0.8215\n",
      "Epoch 19/150\n",
      "2673/2673 [==============================] - 0s 138us/step - loss: 0.1436 - acc: 0.9521 - val_loss: 0.4108 - val_acc: 0.8384\n",
      "Epoch 20/150\n",
      "2673/2673 [==============================] - 0s 146us/step - loss: 0.1454 - acc: 0.9514 - val_loss: 0.4484 - val_acc: 0.8249\n",
      "Epoch 21/150\n",
      "2673/2673 [==============================] - 0s 125us/step - loss: 0.1577 - acc: 0.9420 - val_loss: 0.4335 - val_acc: 0.8384\n",
      "Epoch 22/150\n",
      "2673/2673 [==============================] - 0s 99us/step - loss: 0.1394 - acc: 0.9510 - val_loss: 0.4858 - val_acc: 0.8148\n",
      "Epoch 23/150\n",
      "2673/2673 [==============================] - 0s 142us/step - loss: 0.1314 - acc: 0.9521 - val_loss: 0.4342 - val_acc: 0.8316\n",
      "Epoch 24/150\n",
      "2673/2673 [==============================] - 1s 224us/step - loss: 0.1317 - acc: 0.9581 - val_loss: 0.4967 - val_acc: 0.8182\n",
      "Epoch 25/150\n",
      "2673/2673 [==============================] - 0s 152us/step - loss: 0.1277 - acc: 0.9562 - val_loss: 0.4668 - val_acc: 0.8249\n",
      "Epoch 26/150\n",
      "2673/2673 [==============================] - 0s 151us/step - loss: 0.1548 - acc: 0.9458 - val_loss: 0.5343 - val_acc: 0.7980\n",
      "Epoch 27/150\n",
      "2673/2673 [==============================] - 0s 139us/step - loss: 0.1564 - acc: 0.9480 - val_loss: 0.4481 - val_acc: 0.8384\n",
      "Epoch 28/150\n",
      "2673/2673 [==============================] - 0s 136us/step - loss: 0.1148 - acc: 0.9600 - val_loss: 0.5437 - val_acc: 0.7946\n",
      "Epoch 29/150\n",
      "2673/2673 [==============================] - 0s 143us/step - loss: 0.1257 - acc: 0.9499 - val_loss: 0.4599 - val_acc: 0.8215\n",
      "Epoch 30/150\n",
      "2673/2673 [==============================] - 0s 119us/step - loss: 0.1234 - acc: 0.9570 - val_loss: 0.5724 - val_acc: 0.7980\n",
      "Epoch 31/150\n",
      "2673/2673 [==============================] - 0s 134us/step - loss: 0.1139 - acc: 0.9630 - val_loss: 0.5429 - val_acc: 0.8148\n",
      "Epoch 32/150\n",
      "2673/2673 [==============================] - 0s 139us/step - loss: 0.1254 - acc: 0.9577 - val_loss: 0.5844 - val_acc: 0.7946\n",
      "Epoch 33/150\n",
      "2673/2673 [==============================] - 0s 132us/step - loss: 0.1320 - acc: 0.9532 - val_loss: 0.4642 - val_acc: 0.8215\n",
      "Epoch 34/150\n",
      "2673/2673 [==============================] - 0s 120us/step - loss: 0.1075 - acc: 0.9611 - val_loss: 0.4984 - val_acc: 0.8283\n",
      "Epoch 35/150\n",
      "2673/2673 [==============================] - 0s 142us/step - loss: 0.1159 - acc: 0.9596 - val_loss: 0.4572 - val_acc: 0.8249\n",
      "Epoch 36/150\n",
      "2673/2673 [==============================] - 0s 158us/step - loss: 0.1064 - acc: 0.9615 - val_loss: 0.7180 - val_acc: 0.7744\n",
      "Epoch 37/150\n",
      "2673/2673 [==============================] - 0s 132us/step - loss: 0.1078 - acc: 0.9592 - val_loss: 0.5247 - val_acc: 0.8215\n",
      "Epoch 38/150\n",
      "2673/2673 [==============================] - 0s 111us/step - loss: 0.1057 - acc: 0.9588 - val_loss: 0.5622 - val_acc: 0.8148\n",
      "Epoch 39/150\n",
      "2673/2673 [==============================] - 0s 113us/step - loss: 0.1135 - acc: 0.9607 - val_loss: 0.5492 - val_acc: 0.8047\n",
      "Epoch 40/150\n",
      "2673/2673 [==============================] - 0s 131us/step - loss: 0.1062 - acc: 0.9637 - val_loss: 0.4639 - val_acc: 0.8249\n",
      "Epoch 41/150\n",
      "2673/2673 [==============================] - 0s 109us/step - loss: 0.1039 - acc: 0.9633 - val_loss: 0.5244 - val_acc: 0.8215\n",
      "Epoch 42/150\n",
      "2673/2673 [==============================] - 0s 119us/step - loss: 0.1316 - acc: 0.9506 - val_loss: 0.4836 - val_acc: 0.8114\n",
      "Epoch 43/150\n",
      "2673/2673 [==============================] - 0s 115us/step - loss: 0.1033 - acc: 0.9637 - val_loss: 0.4895 - val_acc: 0.8215\n",
      "Epoch 44/150\n",
      "2673/2673 [==============================] - 0s 121us/step - loss: 0.0945 - acc: 0.9693 - val_loss: 0.5861 - val_acc: 0.8081\n",
      "Epoch 45/150\n",
      "2673/2673 [==============================] - 0s 114us/step - loss: 0.1102 - acc: 0.9581 - val_loss: 0.5207 - val_acc: 0.8283\n",
      "Epoch 46/150\n",
      "2673/2673 [==============================] - 0s 106us/step - loss: 0.1079 - acc: 0.9585 - val_loss: 0.5234 - val_acc: 0.8215\n",
      "Epoch 47/150\n",
      "2673/2673 [==============================] - 0s 121us/step - loss: 0.1445 - acc: 0.9480 - val_loss: 0.4958 - val_acc: 0.8215\n",
      "Epoch 48/150\n",
      "2673/2673 [==============================] - 0s 123us/step - loss: 0.0984 - acc: 0.9645 - val_loss: 0.6530 - val_acc: 0.7879\n",
      "Epoch 49/150\n",
      "2673/2673 [==============================] - 0s 112us/step - loss: 0.0908 - acc: 0.9652 - val_loss: 0.5000 - val_acc: 0.8283\n",
      "Epoch 50/150\n",
      "2673/2673 [==============================] - 0s 136us/step - loss: 0.0888 - acc: 0.9667 - val_loss: 0.5037 - val_acc: 0.8215\n",
      "Epoch 51/150\n",
      "2673/2673 [==============================] - 0s 122us/step - loss: 0.1039 - acc: 0.9592 - val_loss: 0.5280 - val_acc: 0.8249\n",
      "Epoch 52/150\n",
      "2673/2673 [==============================] - 0s 145us/step - loss: 0.1001 - acc: 0.9645 - val_loss: 0.6160 - val_acc: 0.8081\n",
      "Epoch 53/150\n",
      "2673/2673 [==============================] - 0s 134us/step - loss: 0.0910 - acc: 0.9663 - val_loss: 0.5102 - val_acc: 0.8249\n",
      "Epoch 54/150\n",
      "2673/2673 [==============================] - 0s 124us/step - loss: 0.0933 - acc: 0.9645 - val_loss: 0.5383 - val_acc: 0.8114\n",
      "Epoch 55/150\n",
      "2673/2673 [==============================] - 0s 139us/step - loss: 0.0931 - acc: 0.9652 - val_loss: 0.5854 - val_acc: 0.8148\n",
      "Epoch 56/150\n",
      "2673/2673 [==============================] - 0s 129us/step - loss: 0.0897 - acc: 0.9660 - val_loss: 0.5078 - val_acc: 0.8316\n",
      "Epoch 57/150\n",
      "2673/2673 [==============================] - 0s 124us/step - loss: 0.0879 - acc: 0.9686 - val_loss: 0.5164 - val_acc: 0.8215\n",
      "Epoch 58/150\n",
      "2673/2673 [==============================] - 0s 136us/step - loss: 0.0948 - acc: 0.9671 - val_loss: 0.5961 - val_acc: 0.8215\n",
      "Epoch 59/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2673/2673 [==============================] - 0s 138us/step - loss: 0.0827 - acc: 0.9660 - val_loss: 0.5668 - val_acc: 0.8215\n",
      "Epoch 60/150\n",
      "2673/2673 [==============================] - 0s 130us/step - loss: 0.0944 - acc: 0.9671 - val_loss: 0.7992 - val_acc: 0.7845\n",
      "Epoch 61/150\n",
      "2673/2673 [==============================] - 0s 153us/step - loss: 0.1087 - acc: 0.9588 - val_loss: 0.6595 - val_acc: 0.8047\n",
      "Epoch 62/150\n",
      "2673/2673 [==============================] - 0s 149us/step - loss: 0.0929 - acc: 0.9622 - val_loss: 0.5402 - val_acc: 0.8249\n",
      "Epoch 63/150\n",
      "2673/2673 [==============================] - 0s 137us/step - loss: 0.0899 - acc: 0.9660 - val_loss: 0.6531 - val_acc: 0.8114\n",
      "Epoch 64/150\n",
      "2673/2673 [==============================] - 0s 186us/step - loss: 0.0846 - acc: 0.9686 - val_loss: 0.5305 - val_acc: 0.8215\n",
      "Epoch 65/150\n",
      "2673/2673 [==============================] - 0s 181us/step - loss: 0.0928 - acc: 0.9678 - val_loss: 0.6391 - val_acc: 0.8148\n",
      "Epoch 66/150\n",
      "2673/2673 [==============================] - 0s 147us/step - loss: 0.0901 - acc: 0.9697 - val_loss: 0.6693 - val_acc: 0.8081\n",
      "Epoch 67/150\n",
      "2673/2673 [==============================] - 0s 123us/step - loss: 0.0943 - acc: 0.9645 - val_loss: 0.5796 - val_acc: 0.8215\n",
      "Epoch 68/150\n",
      "2673/2673 [==============================] - 0s 129us/step - loss: 0.0988 - acc: 0.9678 - val_loss: 0.5567 - val_acc: 0.8182\n",
      "Epoch 69/150\n",
      "2673/2673 [==============================] - 0s 138us/step - loss: 0.0825 - acc: 0.9652 - val_loss: 0.5978 - val_acc: 0.8081\n",
      "Epoch 70/150\n",
      "2673/2673 [==============================] - 0s 131us/step - loss: 0.0822 - acc: 0.9663 - val_loss: 0.5528 - val_acc: 0.8182\n",
      "Epoch 71/150\n",
      "2673/2673 [==============================] - 0s 122us/step - loss: 0.0813 - acc: 0.9667 - val_loss: 0.5976 - val_acc: 0.8148\n",
      "Epoch 72/150\n",
      "2673/2673 [==============================] - 0s 148us/step - loss: 0.0904 - acc: 0.9637 - val_loss: 0.5487 - val_acc: 0.8215\n",
      "Epoch 73/150\n",
      "2673/2673 [==============================] - 0s 150us/step - loss: 0.0926 - acc: 0.9645 - val_loss: 0.5707 - val_acc: 0.8081\n",
      "Epoch 74/150\n",
      "2673/2673 [==============================] - 0s 126us/step - loss: 0.0907 - acc: 0.9637 - val_loss: 0.5719 - val_acc: 0.8182\n",
      "Epoch 75/150\n",
      "2673/2673 [==============================] - 0s 118us/step - loss: 0.0911 - acc: 0.9637 - val_loss: 0.5722 - val_acc: 0.8215\n",
      "Epoch 76/150\n",
      "2673/2673 [==============================] - 0s 116us/step - loss: 0.0847 - acc: 0.9682 - val_loss: 0.5620 - val_acc: 0.8182\n",
      "Epoch 77/150\n",
      "2673/2673 [==============================] - 0s 171us/step - loss: 0.0854 - acc: 0.9641 - val_loss: 0.5898 - val_acc: 0.8249\n",
      "Epoch 78/150\n",
      "2673/2673 [==============================] - 0s 164us/step - loss: 0.0786 - acc: 0.9686 - val_loss: 0.5805 - val_acc: 0.8182\n",
      "Epoch 79/150\n",
      "2673/2673 [==============================] - 0s 120us/step - loss: 0.0977 - acc: 0.9660 - val_loss: 0.7190 - val_acc: 0.7407\n",
      "Epoch 80/150\n",
      "2673/2673 [==============================] - 0s 111us/step - loss: 0.0904 - acc: 0.9652 - val_loss: 0.6394 - val_acc: 0.8114\n",
      "Epoch 81/150\n",
      "2673/2673 [==============================] - 0s 131us/step - loss: 0.0823 - acc: 0.9675 - val_loss: 0.6031 - val_acc: 0.8215\n",
      "Epoch 82/150\n",
      "2673/2673 [==============================] - 0s 131us/step - loss: 0.0808 - acc: 0.9701 - val_loss: 0.6771 - val_acc: 0.8215\n",
      "Epoch 83/150\n",
      "2673/2673 [==============================] - 0s 124us/step - loss: 0.0771 - acc: 0.9708 - val_loss: 0.6568 - val_acc: 0.8182\n",
      "Epoch 84/150\n",
      "2673/2673 [==============================] - 0s 127us/step - loss: 0.0754 - acc: 0.9678 - val_loss: 0.6316 - val_acc: 0.8114\n",
      "Epoch 85/150\n",
      "2673/2673 [==============================] - 0s 112us/step - loss: 0.0819 - acc: 0.9708 - val_loss: 0.5928 - val_acc: 0.8148\n",
      "Epoch 86/150\n",
      "2673/2673 [==============================] - 0s 120us/step - loss: 0.0810 - acc: 0.9704 - val_loss: 0.7795 - val_acc: 0.8013\n",
      "Epoch 87/150\n",
      "2673/2673 [==============================] - 0s 140us/step - loss: 0.0979 - acc: 0.9656 - val_loss: 0.6884 - val_acc: 0.8081\n",
      "Epoch 88/150\n",
      "2673/2673 [==============================] - 0s 142us/step - loss: 0.0851 - acc: 0.9663 - val_loss: 0.7633 - val_acc: 0.8114\n",
      "Epoch 89/150\n",
      "2673/2673 [==============================] - 0s 145us/step - loss: 0.1255 - acc: 0.9525 - val_loss: 0.7605 - val_acc: 0.8047\n",
      "Epoch 90/150\n",
      "2673/2673 [==============================] - 0s 136us/step - loss: 0.0754 - acc: 0.9723 - val_loss: 0.6997 - val_acc: 0.8114\n",
      "Epoch 91/150\n",
      "2673/2673 [==============================] - 0s 153us/step - loss: 0.0726 - acc: 0.9689 - val_loss: 0.6140 - val_acc: 0.8047\n",
      "Epoch 92/150\n",
      "2432/2673 [==========================>...] - ETA: 0s - loss: 0.0726 - acc: 0.9716"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m-----------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-4b784cd6f875>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    261\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 263\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-13-4b784cd6f875>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    240\u001b[0m                 \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    241\u001b[0m                 \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTrainValTensorBoard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrite_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 242\u001b[0;31m                 validation_data=(val_bNFeatures['img'], val_bNFeatures['label']))\n\u001b[0m\u001b[1;32m    243\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m         \u001b[0;31m# Evaluate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1040\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1042\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1043\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1044\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.6/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    211\u001b[0m                         val_outs = test_loop(model, val_f, val_ins,\n\u001b[1;32m    212\u001b[0m                                              \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 213\u001b[0;31m                                              verbose=0)\n\u001b[0m\u001b[1;32m    214\u001b[0m                         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m                             \u001b[0mval_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mval_outs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.6/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mtest_loop\u001b[0;34m(model, f, ins, batch_size, verbose, steps)\u001b[0m\n\u001b[1;32m    392\u001b[0m                 \u001b[0mins_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mslice_arrays\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 394\u001b[0;31m                 \u001b[0mins_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mslice_arrays\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    395\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices_for_conversion_to_dense\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    396\u001b[0m                 \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.6/site-packages/keras/utils/generic_utils.py\u001b[0m in \u001b[0;36mslice_arrays\u001b[0;34m(arrays, start, stop)\u001b[0m\n\u001b[1;32m    505\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'shape'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m                 \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 507\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    508\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    509\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.6/site-packages/keras/utils/generic_utils.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    505\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'shape'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m                 \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 507\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    508\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    509\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# fold\n",
    "import cv2\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "from keras.models import Sequential\n",
    "import keras\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.utils import np_utils\n",
    "from keras import optimizers\n",
    "# For some reason I have to tell it to use TensorFlows dimension ordering\n",
    "from keras import backend as K\n",
    "K.set_image_dim_ordering('tf')\n",
    "from keras.callbacks import TensorBoard\n",
    "from time import time\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from keras import applications\n",
    "from keras.utils import multi_gpu_model\n",
    "\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "config = tf.ConfigProto()\n",
    "#config.gpu_options.per_process_gpu_memory_fraction = 0.5\n",
    "config.gpu_options.visible_device_list = \"2,3\"\n",
    "config.gpu_options.allow_growth = True\n",
    "set_session(tf.Session(config=config))\n",
    "\n",
    "# Globals\n",
    "\n",
    "NORMALISE = 1\n",
    "CLASSDIR_0 = '/vol/vssp/cvpwrkspc01/scratch/wm0015/crops256/normal/*'\n",
    "CLASSDIR_1 = '/vol/vssp/cvpwrkspc01/scratch/wm0015/crops256/malignant/*'\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 150\n",
    "INPUT_SHAPE = [256, 256, 3]\n",
    "FOLDS = 1\n",
    "\n",
    "class TrainValTensorBoard(TensorBoard):\n",
    "    def __init__(self, log_dir='/vol/vssp/mammo2/will/logs/new', **kwargs):\n",
    "        # Make the original `TensorBoard` log to a subdirectory 'training'\n",
    "        fCount=0\n",
    "        while os.path.exists(os.path.join(log_dir, 'training' + '_' + str(fCount))):\n",
    "            fCount+=1\n",
    "        training_log_dir = os.path.join(log_dir, 'training' + '_' + str(fCount))\n",
    "        super(TrainValTensorBoard, self).__init__(training_log_dir, **kwargs)\n",
    "\n",
    "        # Log the validation metrics to a separate subdirectory\n",
    "        self.val_log_dir = os.path.join(log_dir, 'validation' + '_' + str(fCount))\n",
    "\n",
    "    def set_model(self, model):\n",
    "        # Setup writer for validation metrics\n",
    "        self.val_writer = tf.summary.FileWriter(self.val_log_dir)\n",
    "        super(TrainValTensorBoard, self).set_model(model)\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        # Pop the validation logs and handle them separately with\n",
    "        # `self.val_writer`. Also rename the keys so that they can\n",
    "        # be plotted on the same figure with the training metrics\n",
    "        logs = logs or {}\n",
    "        val_logs = {k.replace('val_', ''): v for k, v in logs.items() if k.startswith('val_')}\n",
    "        for name, value in val_logs.items():\n",
    "            summary = tf.Summary()\n",
    "            summary_value = summary.value.add()\n",
    "            summary_value.simple_value = value.item()\n",
    "            summary_value.tag = name\n",
    "            self.val_writer.add_summary(summary, epoch)\n",
    "        self.val_writer.flush()\n",
    "\n",
    "        # Pass the remaining logs to `TensorBoard.on_epoch_end`\n",
    "        logs = {k: v for k, v in logs.items() if not k.startswith('val_')}\n",
    "        super(TrainValTensorBoard, self).on_epoch_end(epoch, logs)\n",
    "\n",
    "    def on_train_end(self, logs=None):\n",
    "        super(TrainValTensorBoard, self).on_train_end(logs)\n",
    "        self.val_writer.close()\n",
    "\n",
    "\n",
    "def get_images(path, dataSpecs):\n",
    "    fileList = glob.glob(path) #'BengaliBMPConvert/*.bmp'   \n",
    "    num = len(fileList)\n",
    "    dataSpecs['classLength'].append(len(fileList))\n",
    "    x = np.array([(cv2.imread(fname)) for fname in fileList])\n",
    "    return x\n",
    "\n",
    "def get_labels_one_hot(num_classes, class_id, num_samples):\n",
    "    x = np.zeros((num_samples, num_classes))\n",
    "    x[np.arange(num_samples),class_id] = 1\n",
    "    return x\n",
    "\n",
    "def fourCNN():\n",
    "    model = Sequential()\n",
    "    # Layer 1\n",
    "    model.add(Conv2D(32, (3,3), activation='relu', input_shape=INPUT_SHAPE, data_format='channels_last'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    # Layer 2\n",
    "    model.add(Conv2D(32, (3,3), activation='relu')) \n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    # Layer 3    \n",
    "    model.add(Conv2D(32, (3,3), activation='relu'))  \n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    # Layer 4     \n",
    "    model.add(Conv2D(32, (3,3), activation='relu'))   \n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))    \n",
    "    # Layer 5     \n",
    "    #model.add(Conv2D(32, (3,3), activation='relu'))   \n",
    "    #model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    # Layer 6\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1024, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(2, activation='softmax'))\n",
    "    return model\n",
    "    \n",
    "def fiveCNN():\n",
    "    model = Sequential()\n",
    "    # Layer 1\n",
    "    model.add(Conv2D(32, (3,3), activation='relu', input_shape=INPUT_SHAPE, data_format='channels_last'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    # Layer 2\n",
    "    model.add(Conv2D(32, (3,3), activation='relu')) \n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    # Layer 3    \n",
    "    model.add(Conv2D(32, (3,3), activation='relu'))  \n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    # Layer 4     \n",
    "    model.add(Conv2D(32, (3,3), activation='relu'))   \n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))    \n",
    "    # Layer 5     \n",
    "    model.add(Conv2D(32, (3,3), activation='relu'))   \n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    # Layer 6\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1024, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(2, activation='softmax'))  \n",
    "    return model\n",
    "\n",
    "def VGG():\n",
    "    vggModel = applications.VGG19(weights = 'None', include_top=False, input_shape = INPUT_SHAPE)\n",
    "    # Add custom final layer\n",
    "    model = vggModel.output\n",
    "    model = Flatten()(model)\n",
    "    model = keras.models.Model(inputs=vggModel.input, outputs=model)\n",
    "    return model\n",
    "\n",
    "def tlVGG(train_data, val_data):\n",
    "    print('Compute bottleneck features...')\n",
    "    vggModel = applications.VGG19(weights = \"imagenet\", include_top=False, input_shape = INPUT_SHAPE)\n",
    "    # Freeze all layers\n",
    "    for layer in vggModel.layers:\n",
    "        layer.trainable = False\n",
    "    # Add custom final layer\n",
    "    bNModel = vggModel.output\n",
    "    bNModel = Flatten()(bNModel)\n",
    "    final_model = keras.models.Model(inputs=vggModel.input, outputs=bNModel)\n",
    "    train_bNFeatures = {'img': 0, 'label': train_data['label']}\n",
    "    val_bNFeatures = {'img': 0, 'label': val_data['label']}\n",
    "    train_bNFeatures['img'] = final_model.predict(train_data['img'], batch_size=16)\n",
    "    val_bNFeatures['img'] = final_model.predict(val_data['img'], batch_size=16)\n",
    "    print('train_bNFeatures[img].shape = ', train_bNFeatures['img'].shape)\n",
    "    print('val_bNFeatures[img].shape = ', val_bNFeatures['img'].shape)\n",
    "\n",
    "    print('Train head...')\n",
    "    head = Sequential()\n",
    "    #head.add(Dense(32, input_dim=train_bNFeatures['img'].shape[1], activation='relu'))\n",
    "    head.add(Dense(2, activation='softmax'))    \n",
    "    return head, train_bNFeatures, val_bNFeatures\n",
    "\n",
    "def tl(train_data, val_data):\n",
    "    \n",
    "    \n",
    "    \n",
    "def main():\n",
    "    import keras\n",
    "    print('keras version: ', keras.__version__)\n",
    "    print('TensorFlow version: ', tf.__version__)\n",
    "    print('\\nLoad images...')\n",
    "    \n",
    "    # Get images and labels\n",
    "    data = {'img': 0, 'label': 0}\n",
    "    dataSpecs = {'classLength': []}\n",
    "    dataSpecs['classLength'] = []\n",
    "    data['img'] = np.concatenate((\n",
    "            #get_images('/vol/vssp/mammo2/will/data/simulated/calcs/small_sample/0/*', dataSpecs), # Class 0\n",
    "            #get_images('/vol/vssp/mammo2/will/data/simulated/calcs/small_sample/1/*', dataSpecs) # Class 1\n",
    "#             get_images('/user/HS204/wm0015/student/allCalcs/0/*', dataSpecs), # Class 0\n",
    "#             get_images('/user/HS204/wm0015/student/allCalcs/1/*', dataSpecs) # Class 1\n",
    "            get_images(CLASSDIR_0, dataSpecs), # Class 0\n",
    "            get_images(CLASSDIR_1, dataSpecs) # Class 1\n",
    "    ))      \n",
    "\n",
    "    # Normalise\n",
    "    data['img'] = data['img']/NORMALISE   \n",
    "    # Print image    \n",
    "    img_calc = data['img']   \n",
    "    plt.imshow(img_calc[0], cmap='gray')\n",
    "    plt.show()\n",
    "    \n",
    "    # Create one hot labels\n",
    "    labels_bg = get_labels_one_hot(2, 0, dataSpecs['classLength'][0])  \n",
    "    labels_calc = get_labels_one_hot(2, 1, dataSpecs['classLength'][1])\n",
    "    data['label'] = np.concatenate((\n",
    "            get_labels_one_hot(2, 0, dataSpecs['classLength'][0]), # Class 0 \n",
    "            get_labels_one_hot(2, 1, dataSpecs['classLength'][1]) # Class 1\n",
    "    ))\n",
    "    # Drop from 3 colour channels to 1 (greyscale)\n",
    "    if 1==0:\n",
    "        data['img'] = data['img'][:,:,:,0]\n",
    "        data['img'] = np.reshape(data['img'], (data['img'].shape[0],data['img'].shape[1],data['img'].shape[2],1))\n",
    "        print('new data shape = ', data['img'].shape)\n",
    "    \n",
    "    valStats = []\n",
    "    for crossVal in range(FOLDS):\n",
    "\n",
    "        # Shuffle data\n",
    "        seed = 33\n",
    "    #     np.random.seed(seed) # Has to be set before each use of random\n",
    "        shuffleMask = np.random.permutation(data['img'].shape[0])    \n",
    "        data['img'] = data['img'][shuffleMask, :, :, :]\n",
    "        data['label'] = data['label'][shuffleMask, :]\n",
    "\n",
    "        # Split traing and validation data        \n",
    "        splitRatio = 0.9\n",
    "        splitPoint = math.floor(data['img'].shape[0]*splitRatio)\n",
    "        train_data = {'img': data['img'][0:splitPoint], 'label': data['label'][0:splitPoint]}\n",
    "        val_data = {'img': data['img'][splitPoint:], 'label': data['label'][splitPoint:]}\n",
    "\n",
    "        model, train_bNFeatures, val_bNFeatures = tlVGG(train_data, val_data)\n",
    "        #model = multi_gpu_model(model, gpus=2)\n",
    "        \n",
    "        sgd = optimizers.SGD(lr=5, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "        adam = optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False) #0.001\n",
    "        model.compile(loss='binary_crossentropy',\n",
    "                    optimizer=adam,\n",
    "                     metrics=['accuracy'])\n",
    "        tensorboard = TensorBoard(log_dir='/vol/vssp/mammo2/will/logs/new'.format(time()), write_images=True)\n",
    "#         if FOLDS == 1:\n",
    "#             model.summary()  \n",
    "\n",
    "        # Train\n",
    "        model.fit(train_bNFeatures['img'], train_data['label'], \n",
    "                batch_size=BATCH_SIZE, epochs=EPOCHS, verbose=1,\n",
    "                callbacks=[TrainValTensorBoard(write_graph=False)],\n",
    "                validation_data=(val_bNFeatures['img'], val_bNFeatures['label']))\n",
    "\n",
    "        # Evaluate\n",
    "        score = model.evaluate(val_bNFeatures['img'], val_bNFeatures['label'], verbose=0)\n",
    "        valStats.append(score)\n",
    "        print('The score is......\\n', score)\n",
    "        \n",
    "#         model_final = keras.Model(input = model.input, output = customVgg)\n",
    "        \n",
    "\n",
    "# #         model.compile(loss='binary_crossentropy',\n",
    "# #                 optimizer=adam,\n",
    "# #                 metrics=['accuracy']) \n",
    "  \n",
    "\n",
    "    valStats = np.asarray(valStats)\n",
    "    print('Validations: \\n', valStats[:, 1])\n",
    "    print('Average loss: ', sum(valStats[:, 0])/FOLDS)\n",
    "    print('Average validation: ', sum(valStats[:, 1])/FOLDS)\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-13T13:58:18.045957Z",
     "start_time": "2018-07-13T13:58:18.042237Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello world\n"
     ]
    }
   ],
   "source": [
    "print('hello world')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-31T18:09:00.228920Z",
     "start_time": "2018-07-31T18:09:00.221319Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "def test():\n",
    "    return 1, 2, 3\n",
    "\n",
    "x, y, z = test()\n",
    "print(x)\n",
    "print(y)\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-13T13:06:34.579475Z",
     "start_time": "2018-07-13T13:06:34.562536Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[6.53083827 0.59259259]\n",
      " [0.16470135 0.94444444]\n",
      " [0.15422182 0.94444444]\n",
      " [0.19875195 0.9382716 ]] \n",
      "\n",
      "6.5308382717179665\n",
      "[6.53083827 0.16470135 0.15422182 0.19875195]\n",
      "(4, 2)\n"
     ]
    }
   ],
   "source": [
    "x = [[6.5308382717179665, 0.5925925925925926], [0.16470135086112553, 0.9444444444444444], [0.15422181794304907, 0.9444444444444444], [0.19875195217721256, 0.9382716049382716]] \n",
    "x = np.asarray(x)\n",
    "print(x, '\\n')\n",
    "print(x[0][0])\n",
    "print(x[:, 0])\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "144px",
    "left": "1504px",
    "right": "20px",
    "top": "140px",
    "width": "350px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
