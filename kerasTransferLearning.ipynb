{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-10T18:30:57.365710Z",
     "start_time": "2018-07-10T18:30:57.357016Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "/vol/vssp/mammo2/will/logs/newhello\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "log_dir = '/vol/vssp/mammo2/will/logs/new'\n",
    "fCount = 0\n",
    "while os.path.exists(os.path.join(log_dir, 'training', str(fCount))):\n",
    "    fCount+=1\n",
    "    \n",
    "print(os.path.exists(os.path.join(log_dir, 'training')))\n",
    "print(log_dir + 'hello')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-13T14:14:01.894532Z",
     "start_time": "2018-07-13T13:59:02.644951Z"
    },
    "code_folding": [
     71,
     95
    ]
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keras version:  2.2.0\n",
      "TensorFlow version:  1.7.1\n",
      "\n",
      "Load images...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compute bottleneck features...\n",
      "train_bNFeatures[img].shape =  (1458, 73728)\n",
      "val_bNFeatures[img].shape =  (162, 73728)\n",
      "Train head...\n",
      "Train on 1458 samples, validate on 162 samples\n",
      "Epoch 1/150\n",
      "1458/1458 [==============================] - 1s 879us/step - loss: 1.5988 - acc: 0.4492 - val_loss: 0.6937 - val_acc: 0.3827\n",
      "Epoch 2/150\n",
      "1458/1458 [==============================] - 1s 347us/step - loss: 0.6933 - acc: 0.4506 - val_loss: 0.6931 - val_acc: 0.6173\n",
      "Epoch 3/150\n",
      "1458/1458 [==============================] - 0s 307us/step - loss: 0.6930 - acc: 0.5494 - val_loss: 0.6921 - val_acc: 0.6173\n",
      "Epoch 4/150\n",
      "1458/1458 [==============================] - 0s 326us/step - loss: 0.6925 - acc: 0.5494 - val_loss: 0.6910 - val_acc: 0.6173\n",
      "Epoch 5/150\n",
      "1458/1458 [==============================] - 0s 275us/step - loss: 0.6921 - acc: 0.5494 - val_loss: 0.6897 - val_acc: 0.6173\n",
      "Epoch 6/150\n",
      "1458/1458 [==============================] - 0s 330us/step - loss: 0.6916 - acc: 0.5494 - val_loss: 0.6887 - val_acc: 0.6173\n",
      "Epoch 7/150\n",
      "1458/1458 [==============================] - 1s 348us/step - loss: 0.6912 - acc: 0.5494 - val_loss: 0.6874 - val_acc: 0.6173\n",
      "Epoch 8/150\n",
      "1458/1458 [==============================] - 0s 321us/step - loss: 0.6907 - acc: 0.5494 - val_loss: 0.6865 - val_acc: 0.6173\n",
      "Epoch 9/150\n",
      "1458/1458 [==============================] - 1s 440us/step - loss: 0.6904 - acc: 0.5494 - val_loss: 0.6854 - val_acc: 0.6173\n",
      "Epoch 10/150\n",
      "1458/1458 [==============================] - 1s 437us/step - loss: 0.6901 - acc: 0.5494 - val_loss: 0.6846 - val_acc: 0.6173\n",
      "Epoch 11/150\n",
      "1458/1458 [==============================] - 1s 344us/step - loss: 0.6899 - acc: 0.5494 - val_loss: 0.6834 - val_acc: 0.6173\n",
      "Epoch 12/150\n",
      "1458/1458 [==============================] - 0s 320us/step - loss: 0.6895 - acc: 0.5494 - val_loss: 0.6826 - val_acc: 0.6173\n",
      "Epoch 13/150\n",
      "1458/1458 [==============================] - 0s 332us/step - loss: 0.6893 - acc: 0.5494 - val_loss: 0.6817 - val_acc: 0.6173\n",
      "Epoch 14/150\n",
      "1458/1458 [==============================] - 0s 309us/step - loss: 0.6891 - acc: 0.5494 - val_loss: 0.6811 - val_acc: 0.6173\n",
      "Epoch 15/150\n",
      "1458/1458 [==============================] - 1s 344us/step - loss: 0.6890 - acc: 0.5494 - val_loss: 0.6803 - val_acc: 0.6173\n",
      "Epoch 16/150\n",
      "1458/1458 [==============================] - 0s 328us/step - loss: 0.6888 - acc: 0.5494 - val_loss: 0.6797 - val_acc: 0.6173\n",
      "Epoch 17/150\n",
      "1458/1458 [==============================] - 0s 322us/step - loss: 0.6887 - acc: 0.5494 - val_loss: 0.6793 - val_acc: 0.6173\n",
      "Epoch 18/150\n",
      "1458/1458 [==============================] - 1s 402us/step - loss: 0.6887 - acc: 0.5494 - val_loss: 0.6788 - val_acc: 0.6173\n",
      "Epoch 19/150\n",
      "1458/1458 [==============================] - 1s 429us/step - loss: 0.6886 - acc: 0.5494 - val_loss: 0.6783 - val_acc: 0.6173\n",
      "Epoch 20/150\n",
      "1458/1458 [==============================] - 1s 360us/step - loss: 0.6885 - acc: 0.5494 - val_loss: 0.6782 - val_acc: 0.6173\n",
      "Epoch 21/150\n",
      "1458/1458 [==============================] - 0s 333us/step - loss: 0.6885 - acc: 0.5494 - val_loss: 0.6776 - val_acc: 0.6173\n",
      "Epoch 22/150\n",
      "1458/1458 [==============================] - 1s 363us/step - loss: 0.6885 - acc: 0.5494 - val_loss: 0.6774 - val_acc: 0.6173\n",
      "Epoch 23/150\n",
      "1458/1458 [==============================] - 1s 472us/step - loss: 0.6884 - acc: 0.5494 - val_loss: 0.6772 - val_acc: 0.6173\n",
      "Epoch 24/150\n",
      "1458/1458 [==============================] - 1s 347us/step - loss: 0.6884 - acc: 0.5494 - val_loss: 0.6770 - val_acc: 0.6173\n",
      "Epoch 25/150\n",
      "1458/1458 [==============================] - 0s 331us/step - loss: 0.6884 - acc: 0.5494 - val_loss: 0.6769 - val_acc: 0.6173\n",
      "Epoch 26/150\n",
      "1458/1458 [==============================] - 1s 371us/step - loss: 0.6884 - acc: 0.5494 - val_loss: 0.6765 - val_acc: 0.6173\n",
      "Epoch 27/150\n",
      "1458/1458 [==============================] - 1s 451us/step - loss: 0.6883 - acc: 0.5494 - val_loss: 0.6765 - val_acc: 0.6173\n",
      "Epoch 28/150\n",
      "1458/1458 [==============================] - 1s 363us/step - loss: 0.6883 - acc: 0.5494 - val_loss: 0.6762 - val_acc: 0.6173\n",
      "Epoch 29/150\n",
      "1458/1458 [==============================] - 0s 316us/step - loss: 0.6883 - acc: 0.5494 - val_loss: 0.6762 - val_acc: 0.6173\n",
      "Epoch 30/150\n",
      "1458/1458 [==============================] - 0s 312us/step - loss: 0.6883 - acc: 0.5494 - val_loss: 0.6762 - val_acc: 0.6173\n",
      "Epoch 31/150\n",
      "1458/1458 [==============================] - 0s 331us/step - loss: 0.6883 - acc: 0.5494 - val_loss: 0.6760 - val_acc: 0.6173\n",
      "Epoch 32/150\n",
      "1458/1458 [==============================] - 1s 357us/step - loss: 0.6883 - acc: 0.5494 - val_loss: 0.6756 - val_acc: 0.6173\n",
      "Epoch 33/150\n",
      "1458/1458 [==============================] - 1s 427us/step - loss: 0.6883 - acc: 0.5494 - val_loss: 0.6755 - val_acc: 0.6173\n",
      "Epoch 34/150\n",
      "1458/1458 [==============================] - 1s 357us/step - loss: 0.6883 - acc: 0.5494 - val_loss: 0.6754 - val_acc: 0.6173\n",
      "Epoch 35/150\n",
      "1458/1458 [==============================] - 0s 322us/step - loss: 0.6883 - acc: 0.5494 - val_loss: 0.6755 - val_acc: 0.6173\n",
      "Epoch 36/150\n",
      "1458/1458 [==============================] - 0s 301us/step - loss: 0.6883 - acc: 0.5494 - val_loss: 0.6752 - val_acc: 0.6173\n",
      "Epoch 37/150\n",
      "1458/1458 [==============================] - 0s 327us/step - loss: 0.6883 - acc: 0.5494 - val_loss: 0.6753 - val_acc: 0.6173\n",
      "Epoch 38/150\n",
      "1458/1458 [==============================] - 0s 337us/step - loss: 0.6883 - acc: 0.5494 - val_loss: 0.6752 - val_acc: 0.6173\n",
      "Epoch 39/150\n",
      "1458/1458 [==============================] - 1s 374us/step - loss: 0.6883 - acc: 0.5494 - val_loss: 0.6752 - val_acc: 0.6173\n",
      "Epoch 40/150\n",
      "1458/1458 [==============================] - 1s 418us/step - loss: 0.6883 - acc: 0.5494 - val_loss: 0.6750 - val_acc: 0.6173\n",
      "Epoch 41/150\n",
      "1458/1458 [==============================] - 1s 371us/step - loss: 0.6883 - acc: 0.5494 - val_loss: 0.6750 - val_acc: 0.6173\n",
      "Epoch 42/150\n",
      "1458/1458 [==============================] - 0s 343us/step - loss: 0.6883 - acc: 0.5494 - val_loss: 0.6751 - val_acc: 0.6173\n",
      "Epoch 43/150\n",
      "1458/1458 [==============================] - 0s 329us/step - loss: 0.6883 - acc: 0.5494 - val_loss: 0.6752 - val_acc: 0.6173\n",
      "Epoch 44/150\n",
      "1458/1458 [==============================] - 1s 352us/step - loss: 0.6883 - acc: 0.5494 - val_loss: 0.6750 - val_acc: 0.6173\n",
      "Epoch 45/150\n",
      "1458/1458 [==============================] - 1s 433us/step - loss: 0.6883 - acc: 0.5494 - val_loss: 0.6747 - val_acc: 0.6173\n",
      "Epoch 46/150\n",
      "1458/1458 [==============================] - 1s 381us/step - loss: 0.6883 - acc: 0.5494 - val_loss: 0.6750 - val_acc: 0.6173\n",
      "Epoch 47/150\n",
      "1458/1458 [==============================] - 1s 349us/step - loss: 0.6883 - acc: 0.5494 - val_loss: 0.6749 - val_acc: 0.6173\n",
      "Epoch 48/150\n",
      "1458/1458 [==============================] - 0s 323us/step - loss: 0.6883 - acc: 0.5494 - val_loss: 0.6748 - val_acc: 0.6173\n",
      "Epoch 49/150\n",
      "1458/1458 [==============================] - 0s 322us/step - loss: 0.6883 - acc: 0.5494 - val_loss: 0.6747 - val_acc: 0.6173\n",
      "Epoch 50/150\n",
      "1458/1458 [==============================] - 0s 343us/step - loss: 0.6883 - acc: 0.5494 - val_loss: 0.6749 - val_acc: 0.6173\n",
      "Epoch 51/150\n",
      "1458/1458 [==============================] - 1s 351us/step - loss: 0.6883 - acc: 0.5494 - val_loss: 0.6750 - val_acc: 0.6173\n",
      "Epoch 52/150\n",
      "1458/1458 [==============================] - 1s 435us/step - loss: 0.6883 - acc: 0.5494 - val_loss: 0.6751 - val_acc: 0.6173\n",
      "Epoch 53/150\n",
      "1458/1458 [==============================] - 1s 362us/step - loss: 0.6883 - acc: 0.5494 - val_loss: 0.6750 - val_acc: 0.6173\n",
      "Epoch 54/150\n",
      "1458/1458 [==============================] - 0s 287us/step - loss: 0.6883 - acc: 0.5494 - val_loss: 0.6749 - val_acc: 0.6173\n",
      "Epoch 55/150\n",
      "1458/1458 [==============================] - 0s 250us/step - loss: 0.6883 - acc: 0.5494 - val_loss: 0.6748 - val_acc: 0.6173\n",
      "Epoch 56/150\n",
      "1458/1458 [==============================] - 0s 275us/step - loss: 0.6883 - acc: 0.5494 - val_loss: 0.6747 - val_acc: 0.6173\n",
      "Epoch 57/150\n",
      "1458/1458 [==============================] - 0s 329us/step - loss: 0.6883 - acc: 0.5494 - val_loss: 0.6749 - val_acc: 0.6173\n",
      "Epoch 58/150\n",
      "1458/1458 [==============================] - 0s 288us/step - loss: 0.6883 - acc: 0.5494 - val_loss: 0.6749 - val_acc: 0.6173\n",
      "Epoch 59/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1458/1458 [==============================] - 1s 456us/step - loss: 0.6883 - acc: 0.5494 - val_loss: 0.6748 - val_acc: 0.6173\n",
      "Epoch 60/150\n",
      "1458/1458 [==============================] - 0s 327us/step - loss: 0.6883 - acc: 0.5494 - val_loss: 0.6747 - val_acc: 0.6173\n",
      "Epoch 61/150\n",
      "1458/1458 [==============================] - 0s 287us/step - loss: 0.6883 - acc: 0.5494 - val_loss: 0.6747 - val_acc: 0.6173\n",
      "Epoch 62/150\n",
      "1458/1458 [==============================] - 0s 306us/step - loss: 0.6883 - acc: 0.5494 - val_loss: 0.6748 - val_acc: 0.6173\n",
      "Epoch 63/150\n",
      "1458/1458 [==============================] - 1s 350us/step - loss: 0.6883 - acc: 0.5494 - val_loss: 0.6748 - val_acc: 0.6173\n",
      "Epoch 64/150\n",
      "1458/1458 [==============================] - 0s 286us/step - loss: 0.6883 - acc: 0.5494 - val_loss: 0.6747 - val_acc: 0.6173\n",
      "Epoch 65/150\n",
      "1458/1458 [==============================] - 1s 345us/step - loss: 0.6883 - acc: 0.5494 - val_loss: 0.6750 - val_acc: 0.6173\n",
      "Epoch 66/150\n",
      "1458/1458 [==============================] - 1s 453us/step - loss: 0.6883 - acc: 0.5494 - val_loss: 0.6750 - val_acc: 0.6173\n",
      "Epoch 67/150\n",
      "1458/1458 [==============================] - 1s 386us/step - loss: 0.6883 - acc: 0.5494 - val_loss: 0.6752 - val_acc: 0.6173\n",
      "Epoch 68/150\n",
      "1458/1458 [==============================] - 1s 343us/step - loss: 0.6883 - acc: 0.5494 - val_loss: 0.6753 - val_acc: 0.6173\n",
      "Epoch 69/150\n",
      "1458/1458 [==============================] - 1s 374us/step - loss: 0.6883 - acc: 0.5494 - val_loss: 0.6753 - val_acc: 0.6173\n",
      "Epoch 70/150\n",
      "1458/1458 [==============================] - 1s 462us/step - loss: 0.6883 - acc: 0.5494 - val_loss: 0.6752 - val_acc: 0.6173\n",
      "Epoch 71/150\n",
      "1458/1458 [==============================] - 0s 329us/step - loss: 0.6883 - acc: 0.5494 - val_loss: 0.6752 - val_acc: 0.6173\n",
      "Epoch 72/150\n",
      "1458/1458 [==============================] - 1s 352us/step - loss: 0.6883 - acc: 0.5494 - val_loss: 0.6751 - val_acc: 0.6173\n",
      "Epoch 73/150\n",
      "1458/1458 [==============================] - 1s 346us/step - loss: 0.6883 - acc: 0.5494 - val_loss: 0.6749 - val_acc: 0.6173\n",
      "Epoch 74/150\n",
      "1458/1458 [==============================] - 1s 414us/step - loss: 0.6883 - acc: 0.5494 - val_loss: 0.6751 - val_acc: 0.6173\n",
      "Epoch 75/150\n",
      "1458/1458 [==============================] - 1s 423us/step - loss: 0.6883 - acc: 0.5494 - val_loss: 0.6749 - val_acc: 0.6173\n",
      "Epoch 76/150\n",
      "1458/1458 [==============================] - 0s 334us/step - loss: 0.6883 - acc: 0.5494 - val_loss: 0.6748 - val_acc: 0.6173\n",
      "Epoch 77/150\n",
      "1458/1458 [==============================] - 1s 385us/step - loss: 0.6883 - acc: 0.5494 - val_loss: 0.6746 - val_acc: 0.6173\n",
      "Epoch 78/150\n",
      "1458/1458 [==============================] - 1s 389us/step - loss: 0.6883 - acc: 0.5494 - val_loss: 0.6747 - val_acc: 0.6173\n",
      "Epoch 79/150\n",
      "1458/1458 [==============================] - 0s 337us/step - loss: 0.6883 - acc: 0.5494 - val_loss: 0.6747 - val_acc: 0.6173\n",
      "Epoch 80/150\n",
      "1458/1458 [==============================] - 0s 334us/step - loss: 0.6883 - acc: 0.5494 - val_loss: 0.6744 - val_acc: 0.6173\n",
      "Epoch 81/150\n",
      "1458/1458 [==============================] - 0s 343us/step - loss: 0.6883 - acc: 0.5494 - val_loss: 0.6744 - val_acc: 0.6173\n",
      "Epoch 82/150\n",
      "1458/1458 [==============================] - 0s 315us/step - loss: 0.6883 - acc: 0.5494 - val_loss: 0.6745 - val_acc: 0.6173\n",
      "Epoch 83/150\n",
      "1458/1458 [==============================] - 0s 292us/step - loss: 0.6883 - acc: 0.5494 - val_loss: 0.6744 - val_acc: 0.6173\n",
      "Epoch 84/150\n",
      "1458/1458 [==============================] - 0s 308us/step - loss: 0.6883 - acc: 0.5494 - val_loss: 0.6747 - val_acc: 0.6173\n",
      "Epoch 85/150\n",
      "1458/1458 [==============================] - 1s 354us/step - loss: 0.6883 - acc: 0.5494 - val_loss: 0.6747 - val_acc: 0.6173\n",
      "Epoch 86/150\n",
      "1458/1458 [==============================] - 1s 421us/step - loss: 0.6883 - acc: 0.5494 - val_loss: 0.6747 - val_acc: 0.6173\n",
      "Epoch 87/150\n",
      "1458/1458 [==============================] - 1s 372us/step - loss: 0.6883 - acc: 0.5494 - val_loss: 0.6747 - val_acc: 0.6173\n",
      "Epoch 88/150\n",
      "1458/1458 [==============================] - 0s 332us/step - loss: 0.6883 - acc: 0.5494 - val_loss: 0.6750 - val_acc: 0.6173\n",
      "Epoch 89/150\n",
      "1458/1458 [==============================] - 1s 345us/step - loss: 0.6883 - acc: 0.5494 - val_loss: 0.6749 - val_acc: 0.6173\n",
      "Epoch 90/150\n",
      "1458/1458 [==============================] - 1s 421us/step - loss: 0.6883 - acc: 0.5494 - val_loss: 0.6749 - val_acc: 0.6173\n",
      "Epoch 91/150\n",
      "1458/1458 [==============================] - 0s 302us/step - loss: 0.6883 - acc: 0.5494 - val_loss: 0.6748 - val_acc: 0.6173\n",
      "Epoch 92/150\n",
      "1458/1458 [==============================] - 0s 307us/step - loss: 0.6883 - acc: 0.5494 - val_loss: 0.6750 - val_acc: 0.6173\n",
      "Epoch 93/150\n",
      "1458/1458 [==============================] - 1s 384us/step - loss: 0.6883 - acc: 0.5494 - val_loss: 0.6750 - val_acc: 0.6173\n",
      "Epoch 94/150\n",
      "1458/1458 [==============================] - 0s 328us/step - loss: 0.6883 - acc: 0.5494 - val_loss: 0.6748 - val_acc: 0.6173\n",
      "Epoch 95/150\n",
      "1458/1458 [==============================] - 0s 316us/step - loss: 0.6883 - acc: 0.5494 - val_loss: 0.6750 - val_acc: 0.6173\n",
      "Epoch 96/150\n",
      "1458/1458 [==============================] - 0s 305us/step - loss: 0.6883 - acc: 0.5494 - val_loss: 0.6751 - val_acc: 0.6173\n",
      "Epoch 97/150\n",
      "1458/1458 [==============================] - 1s 390us/step - loss: 0.6883 - acc: 0.5494 - val_loss: 0.6748 - val_acc: 0.6173\n",
      "Epoch 98/150\n",
      "1458/1458 [==============================] - 1s 443us/step - loss: 0.6883 - acc: 0.5494 - val_loss: 0.6749 - val_acc: 0.6173\n",
      "Epoch 99/150\n",
      "1458/1458 [==============================] - 0s 321us/step - loss: 0.6883 - acc: 0.5494 - val_loss: 0.6749 - val_acc: 0.6173\n",
      "Epoch 100/150\n",
      "1458/1458 [==============================] - 1s 346us/step - loss: 0.6883 - acc: 0.5494 - val_loss: 0.6749 - val_acc: 0.6173\n",
      "Epoch 101/150\n",
      "1458/1458 [==============================] - 0s 314us/step - loss: 0.6883 - acc: 0.5494 - val_loss: 0.6748 - val_acc: 0.6173\n",
      "Epoch 102/150\n",
      "1458/1458 [==============================] - 0s 322us/step - loss: 0.6883 - acc: 0.5494 - val_loss: 0.6751 - val_acc: 0.6173\n",
      "Epoch 103/150\n",
      "1458/1458 [==============================] - 1s 379us/step - loss: 0.6883 - acc: 0.5494 - val_loss: 0.6750 - val_acc: 0.6173\n",
      "Epoch 104/150\n",
      "1458/1458 [==============================] - 1s 405us/step - loss: 0.6883 - acc: 0.5494 - val_loss: 0.6748 - val_acc: 0.6173\n",
      "Epoch 105/150\n",
      "1458/1458 [==============================] - 0s 343us/step - loss: 0.6883 - acc: 0.5494 - val_loss: 0.6749 - val_acc: 0.6173\n",
      "Epoch 106/150\n",
      "1458/1458 [==============================] - 1s 348us/step - loss: 0.6883 - acc: 0.5494 - val_loss: 0.6749 - val_acc: 0.6173\n",
      "Epoch 107/150\n",
      "1458/1458 [==============================] - 0s 333us/step - loss: 0.6883 - acc: 0.5494 - val_loss: 0.6750 - val_acc: 0.6173\n",
      "Epoch 108/150\n",
      "1458/1458 [==============================] - 0s 311us/step - loss: 0.6883 - acc: 0.5494 - val_loss: 0.6750 - val_acc: 0.6173\n",
      "Epoch 109/150\n",
      "1458/1458 [==============================] - 0s 296us/step - loss: 0.6883 - acc: 0.5494 - val_loss: 0.6752 - val_acc: 0.6173\n",
      "Epoch 110/150\n",
      "1458/1458 [==============================] - 1s 379us/step - loss: 0.6883 - acc: 0.5494 - val_loss: 0.6752 - val_acc: 0.6173\n",
      "Epoch 111/150\n",
      "1458/1458 [==============================] - 1s 454us/step - loss: 0.6883 - acc: 0.5494 - val_loss: 0.6751 - val_acc: 0.6173\n",
      "Epoch 112/150\n",
      "1458/1458 [==============================] - 0s 322us/step - loss: 0.6883 - acc: 0.5494 - val_loss: 0.6750 - val_acc: 0.6173\n",
      "Epoch 113/150\n",
      "1458/1458 [==============================] - 0s 331us/step - loss: 0.6883 - acc: 0.5494 - val_loss: 0.6749 - val_acc: 0.6173\n",
      "Epoch 114/150\n",
      "1458/1458 [==============================] - 0s 323us/step - loss: 0.6883 - acc: 0.5494 - val_loss: 0.6748 - val_acc: 0.6173\n",
      "Epoch 115/150\n",
      "1458/1458 [==============================] - 0s 309us/step - loss: 0.6883 - acc: 0.5494 - val_loss: 0.6749 - val_acc: 0.6173\n",
      "Epoch 116/150\n",
      "1458/1458 [==============================] - 0s 329us/step - loss: 0.6883 - acc: 0.5494 - val_loss: 0.6750 - val_acc: 0.6173\n",
      "Epoch 117/150\n",
      "1458/1458 [==============================] - 0s 319us/step - loss: 0.6883 - acc: 0.5494 - val_loss: 0.6748 - val_acc: 0.6173\n",
      "Epoch 118/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1458/1458 [==============================] - 1s 380us/step - loss: 0.6883 - acc: 0.5494 - val_loss: 0.6748 - val_acc: 0.6173\n",
      "Epoch 119/150\n",
      "1458/1458 [==============================] - 1s 344us/step - loss: 0.6883 - acc: 0.5494 - val_loss: 0.6748 - val_acc: 0.6173\n",
      "Epoch 120/150\n",
      "1458/1458 [==============================] - 1s 343us/step - loss: 0.6883 - acc: 0.5494 - val_loss: 0.6748 - val_acc: 0.6173\n",
      "Epoch 121/150\n",
      "1458/1458 [==============================] - 0s 341us/step - loss: 0.6883 - acc: 0.5494 - val_loss: 0.6748 - val_acc: 0.6173\n",
      "Epoch 122/150\n",
      "1458/1458 [==============================] - 0s 328us/step - loss: 0.6883 - acc: 0.5494 - val_loss: 0.6748 - val_acc: 0.6173\n",
      "Epoch 123/150\n",
      "1458/1458 [==============================] - 1s 356us/step - loss: 0.6883 - acc: 0.5494 - val_loss: 0.6746 - val_acc: 0.6173\n",
      "Epoch 124/150\n",
      "1458/1458 [==============================] - 1s 418us/step - loss: 0.6883 - acc: 0.5494 - val_loss: 0.6746 - val_acc: 0.6173\n",
      "Epoch 125/150\n",
      "1458/1458 [==============================] - 1s 387us/step - loss: 0.6883 - acc: 0.5494 - val_loss: 0.6747 - val_acc: 0.6173\n",
      "Epoch 126/150\n",
      "1458/1458 [==============================] - 0s 330us/step - loss: 0.6883 - acc: 0.5494 - val_loss: 0.6748 - val_acc: 0.6173\n",
      "Epoch 127/150\n",
      "1458/1458 [==============================] - 0s 315us/step - loss: 0.6883 - acc: 0.5494 - val_loss: 0.6747 - val_acc: 0.6173\n",
      "Epoch 128/150\n",
      "1458/1458 [==============================] - 0s 327us/step - loss: 0.6883 - acc: 0.5494 - val_loss: 0.6749 - val_acc: 0.6173\n",
      "Epoch 129/150\n",
      "1458/1458 [==============================] - 0s 313us/step - loss: 0.6883 - acc: 0.5494 - val_loss: 0.6749 - val_acc: 0.6173\n",
      "Epoch 130/150\n",
      "1458/1458 [==============================] - 0s 320us/step - loss: 0.6883 - acc: 0.5494 - val_loss: 0.6750 - val_acc: 0.6173\n",
      "Epoch 131/150\n",
      "1458/1458 [==============================] - 1s 373us/step - loss: 0.6883 - acc: 0.5494 - val_loss: 0.6747 - val_acc: 0.6173\n",
      "Epoch 132/150\n",
      "1458/1458 [==============================] - 1s 350us/step - loss: 0.6883 - acc: 0.5494 - val_loss: 0.6748 - val_acc: 0.6173\n",
      "Epoch 133/150\n",
      "1458/1458 [==============================] - 0s 315us/step - loss: 0.6883 - acc: 0.5494 - val_loss: 0.6749 - val_acc: 0.6173\n",
      "Epoch 134/150\n",
      "1458/1458 [==============================] - 0s 311us/step - loss: 0.6883 - acc: 0.5494 - val_loss: 0.6750 - val_acc: 0.6173\n",
      "Epoch 135/150\n",
      "1458/1458 [==============================] - 1s 347us/step - loss: 0.6883 - acc: 0.5494 - val_loss: 0.6748 - val_acc: 0.6173\n",
      "Epoch 136/150\n",
      "1458/1458 [==============================] - 0s 331us/step - loss: 0.6883 - acc: 0.5494 - val_loss: 0.6748 - val_acc: 0.6173\n",
      "Epoch 137/150\n",
      "1458/1458 [==============================] - 0s 301us/step - loss: 0.6883 - acc: 0.5494 - val_loss: 0.6748 - val_acc: 0.6173\n",
      "Epoch 138/150\n",
      "1458/1458 [==============================] - 1s 388us/step - loss: 0.6883 - acc: 0.5494 - val_loss: 0.6747 - val_acc: 0.6173\n",
      "Epoch 139/150\n",
      "1458/1458 [==============================] - 1s 401us/step - loss: 0.6883 - acc: 0.5494 - val_loss: 0.6747 - val_acc: 0.6173\n",
      "Epoch 140/150\n",
      "1458/1458 [==============================] - 0s 333us/step - loss: 0.6883 - acc: 0.5494 - val_loss: 0.6747 - val_acc: 0.6173\n",
      "Epoch 141/150\n",
      "1458/1458 [==============================] - 0s 322us/step - loss: 0.6883 - acc: 0.5494 - val_loss: 0.6749 - val_acc: 0.6173\n",
      "Epoch 142/150\n",
      "1458/1458 [==============================] - 0s 276us/step - loss: 0.6884 - acc: 0.5494 - val_loss: 0.6746 - val_acc: 0.6173\n",
      "Epoch 143/150\n",
      "1458/1458 [==============================] - 0s 249us/step - loss: 0.6883 - acc: 0.5494 - val_loss: 0.6749 - val_acc: 0.6173\n",
      "Epoch 144/150\n",
      "1458/1458 [==============================] - 0s 276us/step - loss: 0.6883 - acc: 0.5494 - val_loss: 0.6750 - val_acc: 0.6173\n",
      "Epoch 145/150\n",
      "1458/1458 [==============================] - 1s 431us/step - loss: 0.6883 - acc: 0.5494 - val_loss: 0.6750 - val_acc: 0.6173\n",
      "Epoch 146/150\n",
      "1458/1458 [==============================] - 1s 385us/step - loss: 0.6883 - acc: 0.5494 - val_loss: 0.6749 - val_acc: 0.6173\n",
      "Epoch 147/150\n",
      "1458/1458 [==============================] - 1s 352us/step - loss: 0.6883 - acc: 0.5494 - val_loss: 0.6748 - val_acc: 0.6173\n",
      "Epoch 148/150\n",
      "1458/1458 [==============================] - 0s 336us/step - loss: 0.6883 - acc: 0.5494 - val_loss: 0.6750 - val_acc: 0.6173\n",
      "Epoch 149/150\n",
      "1458/1458 [==============================] - 0s 327us/step - loss: 0.6883 - acc: 0.5494 - val_loss: 0.6751 - val_acc: 0.6173\n",
      "Epoch 150/150\n",
      "1458/1458 [==============================] - 0s 319us/step - loss: 0.6883 - acc: 0.5494 - val_loss: 0.6749 - val_acc: 0.6173\n",
      "The score is......\n",
      " [0.6749211557117509, 0.6172839506172839]\n",
      "Compute bottleneck features...\n",
      "train_bNFeatures[img].shape =  (1458, 73728)\n",
      "val_bNFeatures[img].shape =  (162, 73728)\n",
      "Train head...\n",
      "Train on 1458 samples, validate on 162 samples\n",
      "Epoch 1/150\n",
      "1458/1458 [==============================] - 1s 556us/step - loss: 2.8978 - acc: 0.5192 - val_loss: 1.4847 - val_acc: 0.4630\n",
      "Epoch 2/150\n",
      "1458/1458 [==============================] - 0s 321us/step - loss: 0.9968 - acc: 0.6783 - val_loss: 0.6785 - val_acc: 0.7346\n",
      "Epoch 3/150\n",
      "1458/1458 [==============================] - 0s 333us/step - loss: 0.5235 - acc: 0.7613 - val_loss: 0.4151 - val_acc: 0.7963\n",
      "Epoch 4/150\n",
      "1458/1458 [==============================] - 1s 486us/step - loss: 0.3586 - acc: 0.8477 - val_loss: 0.3299 - val_acc: 0.8889\n",
      "Epoch 5/150\n",
      "1458/1458 [==============================] - 1s 440us/step - loss: 0.3016 - acc: 0.8937 - val_loss: 0.3157 - val_acc: 0.8827\n",
      "Epoch 6/150\n",
      "1458/1458 [==============================] - 0s 324us/step - loss: 0.2594 - acc: 0.9122 - val_loss: 0.2934 - val_acc: 0.8827\n",
      "Epoch 7/150\n",
      "1458/1458 [==============================] - 1s 344us/step - loss: 0.2549 - acc: 0.9074 - val_loss: 0.2913 - val_acc: 0.8889\n",
      "Epoch 8/150\n",
      "1458/1458 [==============================] - 1s 402us/step - loss: 0.2162 - acc: 0.9403 - val_loss: 0.2398 - val_acc: 0.9136\n",
      "Epoch 9/150\n",
      "1458/1458 [==============================] - 1s 441us/step - loss: 0.1913 - acc: 0.9568 - val_loss: 0.2762 - val_acc: 0.8889\n",
      "Epoch 10/150\n",
      "1458/1458 [==============================] - 1s 376us/step - loss: 0.1826 - acc: 0.9499 - val_loss: 0.2141 - val_acc: 0.9259\n",
      "Epoch 11/150\n",
      "1458/1458 [==============================] - 0s 336us/step - loss: 0.1580 - acc: 0.9712 - val_loss: 0.2024 - val_acc: 0.9198\n",
      "Epoch 12/150\n",
      "1458/1458 [==============================] - 0s 324us/step - loss: 0.1443 - acc: 0.9753 - val_loss: 0.1921 - val_acc: 0.9198\n",
      "Epoch 13/150\n",
      "1458/1458 [==============================] - ETA: 0s - loss: 0.1373 - acc: 0.976 - 0s 342us/step - loss: 0.1355 - acc: 0.9760 - val_loss: 0.1819 - val_acc: 0.9383\n",
      "Epoch 14/150\n",
      "1458/1458 [==============================] - 1s 363us/step - loss: 0.1293 - acc: 0.9739 - val_loss: 0.1833 - val_acc: 0.9506\n",
      "Epoch 15/150\n",
      "1458/1458 [==============================] - 1s 475us/step - loss: 0.1174 - acc: 0.9794 - val_loss: 0.1662 - val_acc: 0.9383\n",
      "Epoch 16/150\n",
      "1458/1458 [==============================] - 1s 395us/step - loss: 0.1060 - acc: 0.9856 - val_loss: 0.1606 - val_acc: 0.9259\n",
      "Epoch 17/150\n",
      "1458/1458 [==============================] - 0s 309us/step - loss: 0.1021 - acc: 0.9829 - val_loss: 0.1556 - val_acc: 0.9259\n",
      "Epoch 18/150\n",
      "1458/1458 [==============================] - 0s 297us/step - loss: 0.0985 - acc: 0.9829 - val_loss: 0.1613 - val_acc: 0.9321\n",
      "Epoch 19/150\n",
      "1458/1458 [==============================] - 0s 293us/step - loss: 0.0884 - acc: 0.9863 - val_loss: 0.1434 - val_acc: 0.9506\n",
      "Epoch 20/150\n",
      "1458/1458 [==============================] - 0s 340us/step - loss: 0.0805 - acc: 0.9890 - val_loss: 0.1505 - val_acc: 0.9383\n",
      "Epoch 21/150\n",
      "1458/1458 [==============================] - 0s 313us/step - loss: 0.0775 - acc: 0.9911 - val_loss: 0.1438 - val_acc: 0.9383\n",
      "Epoch 22/150\n",
      "1458/1458 [==============================] - 1s 352us/step - loss: 0.0822 - acc: 0.9863 - val_loss: 0.1475 - val_acc: 0.9321\n",
      "Epoch 23/150\n",
      "1458/1458 [==============================] - 0s 323us/step - loss: 0.0684 - acc: 0.9911 - val_loss: 0.1196 - val_acc: 0.9568\n",
      "Epoch 24/150\n",
      "1458/1458 [==============================] - 0s 317us/step - loss: 0.0623 - acc: 0.9931 - val_loss: 0.1144 - val_acc: 0.9815\n",
      "Epoch 25/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1458/1458 [==============================] - 0s 267us/step - loss: 0.0594 - acc: 0.9945 - val_loss: 0.1101 - val_acc: 0.9568\n",
      "Epoch 26/150\n",
      "1458/1458 [==============================] - 1s 361us/step - loss: 0.0586 - acc: 0.9925 - val_loss: 0.1164 - val_acc: 0.9506\n",
      "Epoch 27/150\n",
      "1458/1458 [==============================] - 1s 363us/step - loss: 0.0542 - acc: 0.9945 - val_loss: 0.1037 - val_acc: 0.9506\n",
      "Epoch 28/150\n",
      "1458/1458 [==============================] - 1s 496us/step - loss: 0.0488 - acc: 0.9959 - val_loss: 0.0996 - val_acc: 0.9753\n",
      "Epoch 29/150\n",
      "1458/1458 [==============================] - 0s 300us/step - loss: 0.0471 - acc: 0.9979 - val_loss: 0.0993 - val_acc: 0.9506\n",
      "Epoch 30/150\n",
      "1458/1458 [==============================] - 0s 334us/step - loss: 0.0447 - acc: 0.9973 - val_loss: 0.0943 - val_acc: 0.9568\n",
      "Epoch 31/150\n",
      "1458/1458 [==============================] - 0s 317us/step - loss: 0.0414 - acc: 0.9973 - val_loss: 0.0899 - val_acc: 0.9753\n",
      "Epoch 32/150\n",
      "1458/1458 [==============================] - 0s 318us/step - loss: 0.0396 - acc: 0.9979 - val_loss: 0.0883 - val_acc: 0.9691\n",
      "Epoch 33/150\n",
      "1458/1458 [==============================] - 1s 346us/step - loss: 0.0389 - acc: 0.9993 - val_loss: 0.0869 - val_acc: 0.9691\n",
      "Epoch 34/150\n",
      "1458/1458 [==============================] - 1s 371us/step - loss: 0.0373 - acc: 0.9986 - val_loss: 0.0831 - val_acc: 0.9753\n",
      "Epoch 35/150\n",
      "1458/1458 [==============================] - 1s 411us/step - loss: 0.0366 - acc: 0.9973 - val_loss: 0.0915 - val_acc: 0.9568\n",
      "Epoch 36/150\n",
      "1458/1458 [==============================] - 0s 306us/step - loss: 0.0330 - acc: 0.9979 - val_loss: 0.0792 - val_acc: 0.9815\n",
      "Epoch 37/150\n",
      "1458/1458 [==============================] - 0s 286us/step - loss: 0.0318 - acc: 0.9986 - val_loss: 0.0782 - val_acc: 0.9815\n",
      "Epoch 38/150\n",
      "1458/1458 [==============================] - 0s 323us/step - loss: 0.0309 - acc: 0.9986 - val_loss: 0.0824 - val_acc: 0.9568\n",
      "Epoch 39/150\n",
      "1458/1458 [==============================] - 0s 336us/step - loss: 0.0279 - acc: 0.9986 - val_loss: 0.0772 - val_acc: 0.9753\n",
      "Epoch 40/150\n",
      "1458/1458 [==============================] - 1s 413us/step - loss: 0.0268 - acc: 0.9986 - val_loss: 0.0718 - val_acc: 0.9815\n",
      "Epoch 41/150\n",
      "1458/1458 [==============================] - 1s 383us/step - loss: 0.0255 - acc: 0.9993 - val_loss: 0.0714 - val_acc: 0.9815\n",
      "Epoch 42/150\n",
      "1458/1458 [==============================] - 1s 344us/step - loss: 0.0242 - acc: 1.0000 - val_loss: 0.0801 - val_acc: 0.9568\n",
      "Epoch 43/150\n",
      "1458/1458 [==============================] - 0s 324us/step - loss: 0.0240 - acc: 0.9993 - val_loss: 0.0678 - val_acc: 0.9815\n",
      "Epoch 44/150\n",
      "1458/1458 [==============================] - 1s 348us/step - loss: 0.0228 - acc: 1.0000 - val_loss: 0.0660 - val_acc: 0.9815\n",
      "Epoch 45/150\n",
      "1458/1458 [==============================] - 0s 343us/step - loss: 0.0224 - acc: 0.9993 - val_loss: 0.0666 - val_acc: 0.9877\n",
      "Epoch 46/150\n",
      "1458/1458 [==============================] - 1s 406us/step - loss: 0.0227 - acc: 0.9993 - val_loss: 0.0696 - val_acc: 0.9691\n",
      "Epoch 47/150\n",
      "1458/1458 [==============================] - 0s 340us/step - loss: 0.0216 - acc: 0.9993 - val_loss: 0.0917 - val_acc: 0.9630\n",
      "Epoch 48/150\n",
      "1458/1458 [==============================] - 0s 333us/step - loss: 0.0200 - acc: 1.0000 - val_loss: 0.0611 - val_acc: 0.9815\n",
      "Epoch 49/150\n",
      "1458/1458 [==============================] - 0s 317us/step - loss: 0.0184 - acc: 1.0000 - val_loss: 0.0667 - val_acc: 0.9753\n",
      "Epoch 50/150\n",
      "1458/1458 [==============================] - 0s 339us/step - loss: 0.0174 - acc: 1.0000 - val_loss: 0.0620 - val_acc: 0.9815\n",
      "Epoch 51/150\n",
      "1458/1458 [==============================] - 0s 296us/step - loss: 0.0176 - acc: 1.0000 - val_loss: 0.0581 - val_acc: 0.9815\n",
      "Epoch 52/150\n",
      "1458/1458 [==============================] - 1s 412us/step - loss: 0.0166 - acc: 1.0000 - val_loss: 0.0721 - val_acc: 0.9630\n",
      "Epoch 53/150\n",
      "1458/1458 [==============================] - 1s 374us/step - loss: 0.0171 - acc: 1.0000 - val_loss: 0.0580 - val_acc: 0.9815\n",
      "Epoch 54/150\n",
      "1458/1458 [==============================] - 1s 344us/step - loss: 0.0168 - acc: 1.0000 - val_loss: 0.0689 - val_acc: 0.9630\n",
      "Epoch 55/150\n",
      "1458/1458 [==============================] - 1s 380us/step - loss: 0.0154 - acc: 1.0000 - val_loss: 0.0542 - val_acc: 0.9815\n",
      "Epoch 56/150\n",
      "1458/1458 [==============================] - 1s 348us/step - loss: 0.0158 - acc: 1.0000 - val_loss: 0.0528 - val_acc: 0.9815\n",
      "Epoch 57/150\n",
      "1458/1458 [==============================] - 1s 500us/step - loss: 0.0137 - acc: 1.0000 - val_loss: 0.0543 - val_acc: 0.9815\n",
      "Epoch 58/150\n",
      "1458/1458 [==============================] - 0s 300us/step - loss: 0.0131 - acc: 1.0000 - val_loss: 0.0527 - val_acc: 0.9815\n",
      "Epoch 59/150\n",
      "1458/1458 [==============================] - 0s 287us/step - loss: 0.0126 - acc: 1.0000 - val_loss: 0.0595 - val_acc: 0.9815\n",
      "Epoch 60/150\n",
      "1458/1458 [==============================] - 0s 314us/step - loss: 0.0121 - acc: 1.0000 - val_loss: 0.0566 - val_acc: 0.9815\n",
      "Epoch 61/150\n",
      "1458/1458 [==============================] - 1s 355us/step - loss: 0.0119 - acc: 1.0000 - val_loss: 0.0512 - val_acc: 0.9938\n",
      "Epoch 62/150\n",
      "1458/1458 [==============================] - 0s 329us/step - loss: 0.0125 - acc: 1.0000 - val_loss: 0.0659 - val_acc: 0.9691\n",
      "Epoch 63/150\n",
      "1458/1458 [==============================] - 1s 524us/step - loss: 0.0112 - acc: 1.0000 - val_loss: 0.0482 - val_acc: 0.9815\n",
      "Epoch 64/150\n",
      "1458/1458 [==============================] - 0s 291us/step - loss: 0.0114 - acc: 1.0000 - val_loss: 0.0589 - val_acc: 0.9753\n",
      "Epoch 65/150\n",
      "1458/1458 [==============================] - 0s 302us/step - loss: 0.0105 - acc: 1.0000 - val_loss: 0.0493 - val_acc: 0.9815\n",
      "Epoch 66/150\n",
      "1458/1458 [==============================] - 0s 240us/step - loss: 0.0102 - acc: 1.0000 - val_loss: 0.0489 - val_acc: 0.9815\n",
      "Epoch 67/150\n",
      "1458/1458 [==============================] - 0s 265us/step - loss: 0.0103 - acc: 1.0000 - val_loss: 0.0645 - val_acc: 0.9691\n",
      "Epoch 68/150\n",
      "1458/1458 [==============================] - 0s 280us/step - loss: 0.0094 - acc: 1.0000 - val_loss: 0.0490 - val_acc: 0.9815\n",
      "Epoch 69/150\n",
      "1458/1458 [==============================] - 0s 262us/step - loss: 0.0093 - acc: 1.0000 - val_loss: 0.0475 - val_acc: 0.9815\n",
      "Epoch 70/150\n",
      "1458/1458 [==============================] - 0s 309us/step - loss: 0.0092 - acc: 1.0000 - val_loss: 0.0449 - val_acc: 0.9815\n",
      "Epoch 71/150\n",
      "1458/1458 [==============================] - 0s 326us/step - loss: 0.0086 - acc: 1.0000 - val_loss: 0.0485 - val_acc: 0.9815\n",
      "Epoch 72/150\n",
      "1458/1458 [==============================] - 1s 389us/step - loss: 0.0084 - acc: 1.0000 - val_loss: 0.0511 - val_acc: 0.9877\n",
      "Epoch 73/150\n",
      "1458/1458 [==============================] - 0s 264us/step - loss: 0.0082 - acc: 1.0000 - val_loss: 0.0456 - val_acc: 0.9815\n",
      "Epoch 74/150\n",
      "1458/1458 [==============================] - 0s 281us/step - loss: 0.0080 - acc: 1.0000 - val_loss: 0.0426 - val_acc: 0.9815\n",
      "Epoch 75/150\n",
      "1458/1458 [==============================] - 0s 276us/step - loss: 0.0082 - acc: 1.0000 - val_loss: 0.0519 - val_acc: 0.9815\n",
      "Epoch 76/150\n",
      "1458/1458 [==============================] - 0s 257us/step - loss: 0.0078 - acc: 1.0000 - val_loss: 0.0421 - val_acc: 0.9815\n",
      "Epoch 77/150\n",
      "1458/1458 [==============================] - 1s 344us/step - loss: 0.0072 - acc: 1.0000 - val_loss: 0.0446 - val_acc: 0.9815\n",
      "Epoch 78/150\n",
      "1458/1458 [==============================] - 0s 326us/step - loss: 0.0070 - acc: 1.0000 - val_loss: 0.0462 - val_acc: 0.9877\n",
      "Epoch 79/150\n",
      "1458/1458 [==============================] - 1s 428us/step - loss: 0.0070 - acc: 1.0000 - val_loss: 0.0542 - val_acc: 0.9753\n",
      "Epoch 80/150\n",
      "1458/1458 [==============================] - 0s 339us/step - loss: 0.0068 - acc: 1.0000 - val_loss: 0.0420 - val_acc: 0.9815\n",
      "Epoch 81/150\n",
      "1458/1458 [==============================] - 0s 339us/step - loss: 0.0069 - acc: 1.0000 - val_loss: 0.0393 - val_acc: 0.9877\n",
      "Epoch 82/150\n",
      "1458/1458 [==============================] - 0s 336us/step - loss: 0.0064 - acc: 1.0000 - val_loss: 0.0417 - val_acc: 0.9815\n",
      "Epoch 83/150\n",
      "1458/1458 [==============================] - 0s 337us/step - loss: 0.0063 - acc: 1.0000 - val_loss: 0.0429 - val_acc: 0.9815\n",
      "Epoch 84/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1458/1458 [==============================] - 0s 326us/step - loss: 0.0061 - acc: 1.0000 - val_loss: 0.0496 - val_acc: 0.9877\n",
      "Epoch 85/150\n",
      "1458/1458 [==============================] - 1s 363us/step - loss: 0.0059 - acc: 1.0000 - val_loss: 0.0416 - val_acc: 0.9815\n",
      "Epoch 86/150\n",
      "1458/1458 [==============================] - 1s 419us/step - loss: 0.0057 - acc: 1.0000 - val_loss: 0.0421 - val_acc: 0.9815\n",
      "Epoch 87/150\n",
      "1458/1458 [==============================] - 1s 384us/step - loss: 0.0057 - acc: 1.0000 - val_loss: 0.0390 - val_acc: 0.9815\n",
      "Epoch 88/150\n",
      "1458/1458 [==============================] - 0s 286us/step - loss: 0.0057 - acc: 1.0000 - val_loss: 0.0388 - val_acc: 0.9815\n",
      "Epoch 89/150\n",
      "1458/1458 [==============================] - 0s 319us/step - loss: 0.0053 - acc: 1.0000 - val_loss: 0.0417 - val_acc: 0.9815\n",
      "Epoch 90/150\n",
      "1458/1458 [==============================] - 0s 277us/step - loss: 0.0052 - acc: 1.0000 - val_loss: 0.0412 - val_acc: 0.9815\n",
      "Epoch 91/150\n",
      "1458/1458 [==============================] - 0s 304us/step - loss: 0.0050 - acc: 1.0000 - val_loss: 0.0372 - val_acc: 0.9815\n",
      "Epoch 92/150\n",
      "1458/1458 [==============================] - 0s 266us/step - loss: 0.0050 - acc: 1.0000 - val_loss: 0.0376 - val_acc: 0.9815\n",
      "Epoch 93/150\n",
      "1458/1458 [==============================] - 0s 324us/step - loss: 0.0050 - acc: 1.0000 - val_loss: 0.0383 - val_acc: 0.9815\n",
      "Epoch 94/150\n",
      "1458/1458 [==============================] - 1s 509us/step - loss: 0.0048 - acc: 1.0000 - val_loss: 0.0380 - val_acc: 0.9815\n",
      "Epoch 95/150\n",
      "1458/1458 [==============================] - 0s 339us/step - loss: 0.0046 - acc: 1.0000 - val_loss: 0.0494 - val_acc: 0.9877\n",
      "Epoch 96/150\n",
      "1458/1458 [==============================] - 0s 288us/step - loss: 0.0046 - acc: 1.0000 - val_loss: 0.0439 - val_acc: 0.9877\n",
      "Epoch 97/150\n",
      "1458/1458 [==============================] - 1s 359us/step - loss: 0.0045 - acc: 1.0000 - val_loss: 0.0366 - val_acc: 0.9815\n",
      "Epoch 98/150\n",
      "1458/1458 [==============================] - 0s 262us/step - loss: 0.0046 - acc: 1.0000 - val_loss: 0.0411 - val_acc: 0.9877\n",
      "Epoch 99/150\n",
      "1458/1458 [==============================] - 0s 305us/step - loss: 0.0046 - acc: 1.0000 - val_loss: 0.0466 - val_acc: 0.9877\n",
      "Epoch 100/150\n",
      "1458/1458 [==============================] - 0s 311us/step - loss: 0.0045 - acc: 1.0000 - val_loss: 0.0409 - val_acc: 0.9877\n",
      "Epoch 101/150\n",
      "1458/1458 [==============================] - 0s 290us/step - loss: 0.0040 - acc: 1.0000 - val_loss: 0.0404 - val_acc: 0.9877\n",
      "Epoch 102/150\n",
      "1458/1458 [==============================] - 0s 267us/step - loss: 0.0041 - acc: 1.0000 - val_loss: 0.0378 - val_acc: 0.9877\n",
      "Epoch 103/150\n",
      "1458/1458 [==============================] - 0s 296us/step - loss: 0.0039 - acc: 1.0000 - val_loss: 0.0397 - val_acc: 0.9877\n",
      "Epoch 104/150\n",
      "1458/1458 [==============================] - 0s 284us/step - loss: 0.0038 - acc: 1.0000 - val_loss: 0.0396 - val_acc: 0.9877\n",
      "Epoch 105/150\n",
      "1458/1458 [==============================] - 0s 268us/step - loss: 0.0038 - acc: 1.0000 - val_loss: 0.0337 - val_acc: 0.9877\n",
      "Epoch 106/150\n",
      "1458/1458 [==============================] - 0s 284us/step - loss: 0.0039 - acc: 1.0000 - val_loss: 0.0349 - val_acc: 0.9815\n",
      "Epoch 107/150\n",
      "1458/1458 [==============================] - 0s 276us/step - loss: 0.0036 - acc: 1.0000 - val_loss: 0.0366 - val_acc: 0.9815\n",
      "Epoch 108/150\n",
      "1458/1458 [==============================] - 0s 276us/step - loss: 0.0035 - acc: 1.0000 - val_loss: 0.0378 - val_acc: 0.9877\n",
      "Epoch 109/150\n",
      "1458/1458 [==============================] - 1s 357us/step - loss: 0.0034 - acc: 1.0000 - val_loss: 0.0354 - val_acc: 0.9815\n",
      "Epoch 110/150\n",
      "1458/1458 [==============================] - 0s 296us/step - loss: 0.0034 - acc: 1.0000 - val_loss: 0.0357 - val_acc: 0.9877\n",
      "Epoch 111/150\n",
      "1458/1458 [==============================] - 0s 302us/step - loss: 0.0033 - acc: 1.0000 - val_loss: 0.0381 - val_acc: 0.9877\n",
      "Epoch 112/150\n",
      "1458/1458 [==============================] - 0s 252us/step - loss: 0.0033 - acc: 1.0000 - val_loss: 0.0377 - val_acc: 0.9877\n",
      "Epoch 113/150\n",
      "1458/1458 [==============================] - 0s 242us/step - loss: 0.0031 - acc: 1.0000 - val_loss: 0.0377 - val_acc: 0.9877\n",
      "Epoch 114/150\n",
      "1458/1458 [==============================] - 0s 240us/step - loss: 0.0031 - acc: 1.0000 - val_loss: 0.0350 - val_acc: 0.9877\n",
      "Epoch 115/150\n",
      "1458/1458 [==============================] - 0s 238us/step - loss: 0.0030 - acc: 1.0000 - val_loss: 0.0338 - val_acc: 0.9815\n",
      "Epoch 116/150\n",
      "1458/1458 [==============================] - 0s 290us/step - loss: 0.0030 - acc: 1.0000 - val_loss: 0.0339 - val_acc: 0.9877\n",
      "Epoch 117/150\n",
      "1458/1458 [==============================] - 0s 251us/step - loss: 0.0030 - acc: 1.0000 - val_loss: 0.0356 - val_acc: 0.9877\n",
      "Epoch 118/150\n",
      "1458/1458 [==============================] - 0s 277us/step - loss: 0.0029 - acc: 1.0000 - val_loss: 0.0346 - val_acc: 0.9877\n",
      "Epoch 119/150\n",
      "1458/1458 [==============================] - 0s 266us/step - loss: 0.0029 - acc: 1.0000 - val_loss: 0.0397 - val_acc: 0.9877\n",
      "Epoch 120/150\n",
      "1458/1458 [==============================] - 0s 265us/step - loss: 0.0029 - acc: 1.0000 - val_loss: 0.0397 - val_acc: 0.9877\n",
      "Epoch 121/150\n",
      "1458/1458 [==============================] - 0s 301us/step - loss: 0.0029 - acc: 1.0000 - val_loss: 0.0326 - val_acc: 0.9877\n",
      "Epoch 122/150\n",
      "1458/1458 [==============================] - 0s 302us/step - loss: 0.0027 - acc: 1.0000 - val_loss: 0.0335 - val_acc: 0.9877\n",
      "Epoch 123/150\n",
      "1458/1458 [==============================] - 0s 269us/step - loss: 0.0026 - acc: 1.0000 - val_loss: 0.0333 - val_acc: 0.9877\n",
      "Epoch 124/150\n",
      "1458/1458 [==============================] - 0s 330us/step - loss: 0.0026 - acc: 1.0000 - val_loss: 0.0307 - val_acc: 0.9877\n",
      "Epoch 125/150\n",
      "1458/1458 [==============================] - 0s 251us/step - loss: 0.0026 - acc: 1.0000 - val_loss: 0.0326 - val_acc: 0.9877\n",
      "Epoch 126/150\n",
      "1458/1458 [==============================] - 0s 272us/step - loss: 0.0026 - acc: 1.0000 - val_loss: 0.0315 - val_acc: 0.9815\n",
      "Epoch 127/150\n",
      "1458/1458 [==============================] - 0s 265us/step - loss: 0.0027 - acc: 1.0000 - val_loss: 0.0358 - val_acc: 0.9877\n",
      "Epoch 128/150\n",
      "1458/1458 [==============================] - 0s 293us/step - loss: 0.0026 - acc: 1.0000 - val_loss: 0.0380 - val_acc: 0.9877\n",
      "Epoch 129/150\n",
      "1458/1458 [==============================] - 0s 302us/step - loss: 0.0024 - acc: 1.0000 - val_loss: 0.0378 - val_acc: 0.9877\n",
      "Epoch 130/150\n",
      "1458/1458 [==============================] - 0s 233us/step - loss: 0.0023 - acc: 1.0000 - val_loss: 0.0363 - val_acc: 0.9877\n",
      "Epoch 131/150\n",
      "1458/1458 [==============================] - 0s 294us/step - loss: 0.0022 - acc: 1.0000 - val_loss: 0.0319 - val_acc: 0.9877\n",
      "Epoch 132/150\n",
      "1458/1458 [==============================] - 0s 239us/step - loss: 0.0023 - acc: 1.0000 - val_loss: 0.0335 - val_acc: 0.9877\n",
      "Epoch 133/150\n",
      "1458/1458 [==============================] - 0s 238us/step - loss: 0.0022 - acc: 1.0000 - val_loss: 0.0323 - val_acc: 0.9877\n",
      "Epoch 134/150\n",
      "1458/1458 [==============================] - 0s 257us/step - loss: 0.0021 - acc: 1.0000 - val_loss: 0.0339 - val_acc: 0.9877\n",
      "Epoch 135/150\n",
      "1458/1458 [==============================] - 0s 296us/step - loss: 0.0021 - acc: 1.0000 - val_loss: 0.0322 - val_acc: 0.9877\n",
      "Epoch 136/150\n",
      "1458/1458 [==============================] - 0s 267us/step - loss: 0.0021 - acc: 1.0000 - val_loss: 0.0323 - val_acc: 0.9877\n",
      "Epoch 137/150\n",
      "1458/1458 [==============================] - 0s 296us/step - loss: 0.0020 - acc: 1.0000 - val_loss: 0.0334 - val_acc: 0.9877\n",
      "Epoch 138/150\n",
      "1458/1458 [==============================] - 0s 266us/step - loss: 0.0020 - acc: 1.0000 - val_loss: 0.0361 - val_acc: 0.9877\n",
      "Epoch 139/150\n",
      "1458/1458 [==============================] - 0s 269us/step - loss: 0.0020 - acc: 1.0000 - val_loss: 0.0338 - val_acc: 0.9877\n",
      "Epoch 140/150\n",
      "1458/1458 [==============================] - 0s 305us/step - loss: 0.0019 - acc: 1.0000 - val_loss: 0.0324 - val_acc: 0.9877\n",
      "Epoch 141/150\n",
      "1458/1458 [==============================] - 0s 265us/step - loss: 0.0019 - acc: 1.0000 - val_loss: 0.0452 - val_acc: 0.9877\n",
      "Epoch 142/150\n",
      "1458/1458 [==============================] - 0s 293us/step - loss: 0.0020 - acc: 1.0000 - val_loss: 0.0359 - val_acc: 0.9877\n",
      "Epoch 143/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1458/1458 [==============================] - 0s 283us/step - loss: 0.0018 - acc: 1.0000 - val_loss: 0.0329 - val_acc: 0.9877\n",
      "Epoch 144/150\n",
      "1458/1458 [==============================] - 0s 262us/step - loss: 0.0018 - acc: 1.0000 - val_loss: 0.0331 - val_acc: 0.9877\n",
      "Epoch 145/150\n",
      "1458/1458 [==============================] - 0s 238us/step - loss: 0.0018 - acc: 1.0000 - val_loss: 0.0341 - val_acc: 0.9877\n",
      "Epoch 146/150\n",
      "1458/1458 [==============================] - 0s 251us/step - loss: 0.0017 - acc: 1.0000 - val_loss: 0.0279 - val_acc: 0.9877\n",
      "Epoch 147/150\n",
      "1458/1458 [==============================] - 0s 283us/step - loss: 0.0018 - acc: 1.0000 - val_loss: 0.0296 - val_acc: 0.9877\n",
      "Epoch 148/150\n",
      "1458/1458 [==============================] - 0s 254us/step - loss: 0.0017 - acc: 1.0000 - val_loss: 0.0298 - val_acc: 0.9877\n",
      "Epoch 149/150\n",
      "1458/1458 [==============================] - 0s 296us/step - loss: 0.0017 - acc: 1.0000 - val_loss: 0.0295 - val_acc: 0.9877\n",
      "Epoch 150/150\n",
      "1458/1458 [==============================] - 0s 308us/step - loss: 0.0017 - acc: 1.0000 - val_loss: 0.0286 - val_acc: 0.9815\n",
      "The score is......\n",
      " [0.028649131573426228, 0.9814814814814815]\n",
      "Compute bottleneck features...\n",
      "train_bNFeatures[img].shape =  (1458, 73728)\n",
      "val_bNFeatures[img].shape =  (162, 73728)\n",
      "Train head...\n",
      "Train on 1458 samples, validate on 162 samples\n",
      "Epoch 1/150\n",
      "1458/1458 [==============================] - 1s 579us/step - loss: 6.7623 - acc: 0.5425 - val_loss: 6.5308 - val_acc: 0.5926\n",
      "Epoch 2/150\n",
      "1458/1458 [==============================] - 1s 347us/step - loss: 7.1795 - acc: 0.5521 - val_loss: 6.5308 - val_acc: 0.5926\n",
      "Epoch 3/150\n",
      "1458/1458 [==============================] - 1s 343us/step - loss: 7.1795 - acc: 0.5521 - val_loss: 6.5308 - val_acc: 0.5926\n",
      "Epoch 4/150\n",
      "1458/1458 [==============================] - 1s 631us/step - loss: 7.1795 - acc: 0.5521 - val_loss: 6.5308 - val_acc: 0.5926\n",
      "Epoch 5/150\n",
      "1458/1458 [==============================] - 1s 346us/step - loss: 7.1795 - acc: 0.5521 - val_loss: 6.5308 - val_acc: 0.5926\n",
      "Epoch 6/150\n",
      "1458/1458 [==============================] - 0s 307us/step - loss: 7.1795 - acc: 0.5521 - val_loss: 6.5308 - val_acc: 0.5926\n",
      "Epoch 7/150\n",
      "1458/1458 [==============================] - 0s 322us/step - loss: 7.1795 - acc: 0.5521 - val_loss: 6.5308 - val_acc: 0.5926\n",
      "Epoch 8/150\n",
      "1458/1458 [==============================] - 1s 350us/step - loss: 7.1795 - acc: 0.5521 - val_loss: 6.5308 - val_acc: 0.5926\n",
      "Epoch 9/150\n",
      "1458/1458 [==============================] - 1s 393us/step - loss: 7.1795 - acc: 0.5521 - val_loss: 6.5308 - val_acc: 0.5926\n",
      "Epoch 10/150\n",
      "1458/1458 [==============================] - 0s 331us/step - loss: 7.1795 - acc: 0.5521 - val_loss: 6.5308 - val_acc: 0.5926\n",
      "Epoch 11/150\n",
      "1458/1458 [==============================] - 1s 350us/step - loss: 7.1795 - acc: 0.5521 - val_loss: 6.5308 - val_acc: 0.5926\n",
      "Epoch 12/150\n",
      "1458/1458 [==============================] - 1s 351us/step - loss: 7.1795 - acc: 0.5521 - val_loss: 6.5308 - val_acc: 0.5926\n",
      "Epoch 13/150\n",
      "1458/1458 [==============================] - 1s 453us/step - loss: 7.1795 - acc: 0.5521 - val_loss: 6.5308 - val_acc: 0.5926\n",
      "Epoch 14/150\n",
      "1458/1458 [==============================] - 1s 346us/step - loss: 7.1795 - acc: 0.5521 - val_loss: 6.5308 - val_acc: 0.5926\n",
      "Epoch 15/150\n",
      "1458/1458 [==============================] - 0s 322us/step - loss: 7.1795 - acc: 0.5521 - val_loss: 6.5308 - val_acc: 0.5926\n",
      "Epoch 16/150\n",
      "1458/1458 [==============================] - 0s 332us/step - loss: 7.1795 - acc: 0.5521 - val_loss: 6.5308 - val_acc: 0.5926\n",
      "Epoch 17/150\n",
      "1458/1458 [==============================] - 1s 347us/step - loss: 7.1795 - acc: 0.5521 - val_loss: 6.5308 - val_acc: 0.5926\n",
      "Epoch 18/150\n",
      "1458/1458 [==============================] - 0s 291us/step - loss: 7.1795 - acc: 0.5521 - val_loss: 6.5308 - val_acc: 0.5926\n",
      "Epoch 19/150\n",
      "1458/1458 [==============================] - 1s 472us/step - loss: 7.1795 - acc: 0.5521 - val_loss: 6.5308 - val_acc: 0.5926\n",
      "Epoch 20/150\n",
      "1458/1458 [==============================] - 1s 358us/step - loss: 7.1795 - acc: 0.5521 - val_loss: 6.5308 - val_acc: 0.5926\n",
      "Epoch 21/150\n",
      "1458/1458 [==============================] - 0s 295us/step - loss: 7.1795 - acc: 0.5521 - val_loss: 6.5308 - val_acc: 0.5926\n",
      "Epoch 22/150\n",
      "1458/1458 [==============================] - 0s 269us/step - loss: 7.1795 - acc: 0.5521 - val_loss: 6.5308 - val_acc: 0.5926\n",
      "Epoch 23/150\n",
      "1458/1458 [==============================] - 0s 236us/step - loss: 7.1795 - acc: 0.5521 - val_loss: 6.5308 - val_acc: 0.5926\n",
      "Epoch 24/150\n",
      "1458/1458 [==============================] - 1s 371us/step - loss: 7.1795 - acc: 0.5521 - val_loss: 6.5308 - val_acc: 0.5926\n",
      "Epoch 25/150\n",
      "1458/1458 [==============================] - 1s 406us/step - loss: 7.1795 - acc: 0.5521 - val_loss: 6.5308 - val_acc: 0.5926\n",
      "Epoch 26/150\n",
      "1458/1458 [==============================] - 0s 301us/step - loss: 7.1795 - acc: 0.5521 - val_loss: 6.5308 - val_acc: 0.5926\n",
      "Epoch 27/150\n",
      "1458/1458 [==============================] - 0s 298us/step - loss: 7.1795 - acc: 0.5521 - val_loss: 6.5308 - val_acc: 0.5926\n",
      "Epoch 28/150\n",
      "1458/1458 [==============================] - 1s 348us/step - loss: 7.1795 - acc: 0.5521 - val_loss: 6.5308 - val_acc: 0.5926\n",
      "Epoch 29/150\n",
      "1458/1458 [==============================] - 1s 393us/step - loss: 7.1795 - acc: 0.5521 - val_loss: 6.5308 - val_acc: 0.5926\n",
      "Epoch 30/150\n",
      "1458/1458 [==============================] - 1s 363us/step - loss: 7.1795 - acc: 0.5521 - val_loss: 6.5308 - val_acc: 0.5926\n",
      "Epoch 31/150\n",
      "1458/1458 [==============================] - 1s 347us/step - loss: 7.1795 - acc: 0.5521 - val_loss: 6.5308 - val_acc: 0.5926\n",
      "Epoch 32/150\n",
      "1458/1458 [==============================] - 0s 323us/step - loss: 7.1795 - acc: 0.5521 - val_loss: 6.5308 - val_acc: 0.5926\n",
      "Epoch 33/150\n",
      "1458/1458 [==============================] - 0s 297us/step - loss: 7.1795 - acc: 0.5521 - val_loss: 6.5308 - val_acc: 0.5926\n",
      "Epoch 34/150\n",
      "1458/1458 [==============================] - 1s 373us/step - loss: 7.1795 - acc: 0.5521 - val_loss: 6.5308 - val_acc: 0.5926\n",
      "Epoch 35/150\n",
      "1458/1458 [==============================] - 0s 325us/step - loss: 7.1795 - acc: 0.5521 - val_loss: 6.5308 - val_acc: 0.5926\n",
      "Epoch 36/150\n",
      "1458/1458 [==============================] - 1s 478us/step - loss: 7.1795 - acc: 0.5521 - val_loss: 6.5308 - val_acc: 0.5926\n",
      "Epoch 37/150\n",
      "1458/1458 [==============================] - 0s 338us/step - loss: 7.1795 - acc: 0.5521 - val_loss: 6.5308 - val_acc: 0.5926\n",
      "Epoch 38/150\n",
      "1458/1458 [==============================] - 0s 302us/step - loss: 7.1795 - acc: 0.5521 - val_loss: 6.5308 - val_acc: 0.5926\n",
      "Epoch 39/150\n",
      "1458/1458 [==============================] - 0s 327us/step - loss: 7.1795 - acc: 0.5521 - val_loss: 6.5308 - val_acc: 0.5926\n",
      "Epoch 40/150\n",
      "1458/1458 [==============================] - 0s 271us/step - loss: 7.1795 - acc: 0.5521 - val_loss: 6.5308 - val_acc: 0.5926\n",
      "Epoch 41/150\n",
      "1458/1458 [==============================] - 1s 351us/step - loss: 7.1795 - acc: 0.5521 - val_loss: 6.5308 - val_acc: 0.5926\n",
      "Epoch 42/150\n",
      "1458/1458 [==============================] - 1s 373us/step - loss: 7.1795 - acc: 0.5521 - val_loss: 6.5308 - val_acc: 0.5926\n",
      "Epoch 43/150\n",
      "1458/1458 [==============================] - 1s 464us/step - loss: 7.1795 - acc: 0.5521 - val_loss: 6.5308 - val_acc: 0.5926\n",
      "Epoch 44/150\n",
      "1458/1458 [==============================] - 0s 320us/step - loss: 7.1795 - acc: 0.5521 - val_loss: 6.5308 - val_acc: 0.5926\n",
      "Epoch 45/150\n",
      "1458/1458 [==============================] - 1s 358us/step - loss: 7.1795 - acc: 0.5521 - val_loss: 6.5308 - val_acc: 0.5926\n",
      "Epoch 46/150\n",
      "1458/1458 [==============================] - 1s 375us/step - loss: 7.1795 - acc: 0.5521 - val_loss: 6.5308 - val_acc: 0.5926\n",
      "Epoch 47/150\n",
      "1458/1458 [==============================] - 1s 440us/step - loss: 7.1795 - acc: 0.5521 - val_loss: 6.5308 - val_acc: 0.5926\n",
      "Epoch 48/150\n",
      "1458/1458 [==============================] - 0s 342us/step - loss: 7.1795 - acc: 0.5521 - val_loss: 6.5308 - val_acc: 0.5926\n",
      "Epoch 49/150\n",
      "1458/1458 [==============================] - 0s 328us/step - loss: 7.1795 - acc: 0.5521 - val_loss: 6.5308 - val_acc: 0.5926\n",
      "Epoch 50/150\n",
      "1458/1458 [==============================] - 0s 322us/step - loss: 7.1795 - acc: 0.5521 - val_loss: 6.5308 - val_acc: 0.5926\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 51/150\n",
      "1458/1458 [==============================] - 1s 389us/step - loss: 7.1795 - acc: 0.5521 - val_loss: 6.5308 - val_acc: 0.5926\n",
      "Epoch 52/150\n",
      "1458/1458 [==============================] - 1s 381us/step - loss: 7.1795 - acc: 0.5521 - val_loss: 6.5308 - val_acc: 0.5926\n",
      "Epoch 53/150\n",
      "1458/1458 [==============================] - 1s 451us/step - loss: 7.1795 - acc: 0.5521 - val_loss: 6.5308 - val_acc: 0.5926\n",
      "Epoch 54/150\n",
      "1458/1458 [==============================] - 0s 338us/step - loss: 7.1795 - acc: 0.5521 - val_loss: 6.5308 - val_acc: 0.5926\n",
      "Epoch 55/150\n",
      "1458/1458 [==============================] - 1s 384us/step - loss: 7.1795 - acc: 0.5521 - val_loss: 6.5308 - val_acc: 0.5926\n",
      "Epoch 56/150\n",
      "1458/1458 [==============================] - 1s 370us/step - loss: 7.1795 - acc: 0.5521 - val_loss: 6.5308 - val_acc: 0.5926\n",
      "Epoch 57/150\n",
      "1458/1458 [==============================] - 1s 461us/step - loss: 7.1795 - acc: 0.5521 - val_loss: 6.5308 - val_acc: 0.5926\n",
      "Epoch 58/150\n",
      "1458/1458 [==============================] - 0s 330us/step - loss: 7.1795 - acc: 0.5521 - val_loss: 6.5308 - val_acc: 0.5926\n",
      "Epoch 59/150\n",
      "1458/1458 [==============================] - 0s 317us/step - loss: 7.1795 - acc: 0.5521 - val_loss: 6.5308 - val_acc: 0.5926\n",
      "Epoch 60/150\n",
      "1458/1458 [==============================] - 1s 379us/step - loss: 7.1795 - acc: 0.5521 - val_loss: 6.5308 - val_acc: 0.5926\n",
      "Epoch 61/150\n",
      "1458/1458 [==============================] - 1s 380us/step - loss: 7.1795 - acc: 0.5521 - val_loss: 6.5308 - val_acc: 0.5926\n",
      "Epoch 62/150\n",
      "1458/1458 [==============================] - 1s 407us/step - loss: 7.1795 - acc: 0.5521 - val_loss: 6.5308 - val_acc: 0.5926\n",
      "Epoch 63/150\n",
      "1458/1458 [==============================] - 0s 319us/step - loss: 7.1795 - acc: 0.5521 - val_loss: 6.5308 - val_acc: 0.5926\n",
      "Epoch 64/150\n",
      "1458/1458 [==============================] - 0s 343us/step - loss: 7.1795 - acc: 0.5521 - val_loss: 6.5308 - val_acc: 0.5926\n",
      "Epoch 65/150\n",
      "1458/1458 [==============================] - 0s 289us/step - loss: 7.1795 - acc: 0.5521 - val_loss: 6.5308 - val_acc: 0.5926\n",
      "Epoch 66/150\n",
      "1458/1458 [==============================] - 0s 292us/step - loss: 7.1795 - acc: 0.5521 - val_loss: 6.5308 - val_acc: 0.5926\n",
      "Epoch 67/150\n",
      "1458/1458 [==============================] - 1s 346us/step - loss: 7.1795 - acc: 0.5521 - val_loss: 6.5308 - val_acc: 0.5926\n",
      "Epoch 68/150\n",
      "1458/1458 [==============================] - 1s 369us/step - loss: 7.1795 - acc: 0.5521 - val_loss: 6.5308 - val_acc: 0.5926\n",
      "Epoch 69/150\n",
      "1458/1458 [==============================] - 1s 465us/step - loss: 7.1795 - acc: 0.5521 - val_loss: 6.5308 - val_acc: 0.5926\n",
      "Epoch 70/150\n",
      "1458/1458 [==============================] - 0s 341us/step - loss: 7.1795 - acc: 0.5521 - val_loss: 6.5308 - val_acc: 0.5926\n",
      "Epoch 71/150\n",
      "1458/1458 [==============================] - 1s 350us/step - loss: 7.1795 - acc: 0.5521 - val_loss: 6.5308 - val_acc: 0.5926\n",
      "Epoch 72/150\n",
      "1458/1458 [==============================] - 0s 314us/step - loss: 7.1795 - acc: 0.5521 - val_loss: 6.5308 - val_acc: 0.5926\n",
      "Epoch 73/150\n",
      "1458/1458 [==============================] - 1s 427us/step - loss: 7.1795 - acc: 0.5521 - val_loss: 6.5308 - val_acc: 0.5926\n",
      "Epoch 74/150\n",
      "1458/1458 [==============================] - 0s 258us/step - loss: 7.1795 - acc: 0.5521 - val_loss: 6.5308 - val_acc: 0.5926\n",
      "Epoch 75/150\n",
      "1458/1458 [==============================] - 0s 301us/step - loss: 7.1795 - acc: 0.5521 - val_loss: 6.5308 - val_acc: 0.5926\n",
      "Epoch 76/150\n",
      "1458/1458 [==============================] - 0s 284us/step - loss: 7.1795 - acc: 0.5521 - val_loss: 6.5308 - val_acc: 0.5926\n",
      "Epoch 77/150\n",
      "1458/1458 [==============================] - 0s 308us/step - loss: 7.1795 - acc: 0.5521 - val_loss: 6.5308 - val_acc: 0.5926\n",
      "Epoch 78/150\n",
      "1458/1458 [==============================] - 1s 356us/step - loss: 7.1795 - acc: 0.5521 - val_loss: 6.5308 - val_acc: 0.5926\n",
      "Epoch 79/150\n",
      "1458/1458 [==============================] - 0s 305us/step - loss: 7.1795 - acc: 0.5521 - val_loss: 6.5308 - val_acc: 0.5926\n",
      "Epoch 80/150\n",
      "1458/1458 [==============================] - 1s 393us/step - loss: 7.1795 - acc: 0.5521 - val_loss: 6.5308 - val_acc: 0.5926\n",
      "Epoch 81/150\n",
      "1458/1458 [==============================] - 0s 306us/step - loss: 7.1795 - acc: 0.5521 - val_loss: 6.5308 - val_acc: 0.5926\n",
      "Epoch 82/150\n",
      "1458/1458 [==============================] - 0s 294us/step - loss: 7.1795 - acc: 0.5521 - val_loss: 6.5308 - val_acc: 0.5926\n",
      "Epoch 83/150\n",
      "1458/1458 [==============================] - 0s 286us/step - loss: 7.1795 - acc: 0.5521 - val_loss: 6.5308 - val_acc: 0.5926\n",
      "Epoch 84/150\n",
      "1458/1458 [==============================] - 0s 290us/step - loss: 7.1795 - acc: 0.5521 - val_loss: 6.5308 - val_acc: 0.5926\n",
      "Epoch 85/150\n",
      "1458/1458 [==============================] - 0s 320us/step - loss: 7.1795 - acc: 0.5521 - val_loss: 6.5308 - val_acc: 0.5926\n",
      "Epoch 86/150\n",
      "1458/1458 [==============================] - 1s 377us/step - loss: 7.1795 - acc: 0.5521 - val_loss: 6.5308 - val_acc: 0.5926\n",
      "Epoch 87/150\n",
      "1458/1458 [==============================] - 0s 336us/step - loss: 7.1795 - acc: 0.5521 - val_loss: 6.5308 - val_acc: 0.5926\n",
      "Epoch 88/150\n",
      "1458/1458 [==============================] - 0s 272us/step - loss: 7.1795 - acc: 0.5521 - val_loss: 6.5308 - val_acc: 0.5926\n",
      "Epoch 89/150\n",
      "1458/1458 [==============================] - 0s 284us/step - loss: 7.1795 - acc: 0.5521 - val_loss: 6.5308 - val_acc: 0.5926\n",
      "Epoch 90/150\n",
      "1458/1458 [==============================] - 0s 332us/step - loss: 7.1795 - acc: 0.5521 - val_loss: 6.5308 - val_acc: 0.5926\n",
      "Epoch 91/150\n",
      "1458/1458 [==============================] - 0s 269us/step - loss: 7.1795 - acc: 0.5521 - val_loss: 6.5308 - val_acc: 0.5926\n",
      "Epoch 92/150\n",
      "1458/1458 [==============================] - 0s 257us/step - loss: 7.1795 - acc: 0.5521 - val_loss: 6.5308 - val_acc: 0.5926\n",
      "Epoch 93/150\n",
      "1458/1458 [==============================] - 0s 245us/step - loss: 7.1795 - acc: 0.5521 - val_loss: 6.5308 - val_acc: 0.5926\n",
      "Epoch 94/150\n",
      "1458/1458 [==============================] - 0s 285us/step - loss: 7.1795 - acc: 0.5521 - val_loss: 6.5308 - val_acc: 0.5926\n",
      "Epoch 95/150\n",
      "1458/1458 [==============================] - 1s 425us/step - loss: 7.1795 - acc: 0.5521 - val_loss: 6.5308 - val_acc: 0.5926\n",
      "Epoch 96/150\n",
      "1458/1458 [==============================] - 1s 344us/step - loss: 7.1795 - acc: 0.5521 - val_loss: 6.5308 - val_acc: 0.5926\n",
      "Epoch 97/150\n",
      "1458/1458 [==============================] - 0s 336us/step - loss: 7.1795 - acc: 0.5521 - val_loss: 6.5308 - val_acc: 0.5926\n",
      "Epoch 98/150\n",
      "1458/1458 [==============================] - 0s 326us/step - loss: 7.1795 - acc: 0.5521 - val_loss: 6.5308 - val_acc: 0.5926\n",
      "Epoch 99/150\n",
      "1458/1458 [==============================] - 0s 284us/step - loss: 7.1795 - acc: 0.5521 - val_loss: 6.5308 - val_acc: 0.5926\n",
      "Epoch 100/150\n",
      "1458/1458 [==============================] - 0s 342us/step - loss: 7.1795 - acc: 0.5521 - val_loss: 6.5308 - val_acc: 0.5926\n",
      "Epoch 101/150\n",
      "1458/1458 [==============================] - 1s 377us/step - loss: 7.1795 - acc: 0.5521 - val_loss: 6.5308 - val_acc: 0.5926\n",
      "Epoch 102/150\n",
      "1458/1458 [==============================] - 0s 326us/step - loss: 7.1795 - acc: 0.5521 - val_loss: 6.5308 - val_acc: 0.5926\n",
      "Epoch 103/150\n",
      "1458/1458 [==============================] - 0s 274us/step - loss: 7.1795 - acc: 0.5521 - val_loss: 6.5308 - val_acc: 0.5926\n",
      "Epoch 104/150\n",
      "1458/1458 [==============================] - 0s 292us/step - loss: 7.1795 - acc: 0.5521 - val_loss: 6.5308 - val_acc: 0.5926\n",
      "Epoch 105/150\n",
      "1458/1458 [==============================] - 0s 291us/step - loss: 7.1795 - acc: 0.5521 - val_loss: 6.5308 - val_acc: 0.5926\n",
      "Epoch 106/150\n",
      "1458/1458 [==============================] - 0s 293us/step - loss: 7.1795 - acc: 0.5521 - val_loss: 6.5308 - val_acc: 0.5926\n",
      "Epoch 107/150\n",
      "1458/1458 [==============================] - 0s 299us/step - loss: 7.1795 - acc: 0.5521 - val_loss: 6.5308 - val_acc: 0.5926\n",
      "Epoch 108/150\n",
      "1458/1458 [==============================] - 0s 334us/step - loss: 7.1795 - acc: 0.5521 - val_loss: 6.5308 - val_acc: 0.5926\n",
      "Epoch 109/150\n",
      "1458/1458 [==============================] - 0s 287us/step - loss: 7.1795 - acc: 0.5521 - val_loss: 6.5308 - val_acc: 0.5926\n",
      "Epoch 110/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1458/1458 [==============================] - 1s 394us/step - loss: 7.1795 - acc: 0.5521 - val_loss: 6.5308 - val_acc: 0.5926\n",
      "Epoch 111/150\n",
      "1458/1458 [==============================] - 1s 408us/step - loss: 7.1795 - acc: 0.5521 - val_loss: 6.5308 - val_acc: 0.5926\n",
      "Epoch 112/150\n",
      "1458/1458 [==============================] - 0s 276us/step - loss: 7.1795 - acc: 0.5521 - val_loss: 6.5308 - val_acc: 0.5926\n",
      "Epoch 113/150\n",
      "1458/1458 [==============================] - 0s 236us/step - loss: 7.1795 - acc: 0.5521 - val_loss: 6.5308 - val_acc: 0.5926\n",
      "Epoch 114/150\n",
      "1458/1458 [==============================] - 0s 249us/step - loss: 7.1795 - acc: 0.5521 - val_loss: 6.5308 - val_acc: 0.5926\n",
      "Epoch 115/150\n",
      "1458/1458 [==============================] - 0s 312us/step - loss: 7.1795 - acc: 0.5521 - val_loss: 6.5308 - val_acc: 0.5926\n",
      "Epoch 116/150\n",
      "1458/1458 [==============================] - 0s 289us/step - loss: 7.1795 - acc: 0.5521 - val_loss: 6.5308 - val_acc: 0.5926\n",
      "Epoch 117/150\n",
      "1458/1458 [==============================] - 0s 280us/step - loss: 7.1795 - acc: 0.5521 - val_loss: 6.5308 - val_acc: 0.5926\n",
      "Epoch 118/150\n",
      "1458/1458 [==============================] - 0s 329us/step - loss: 7.1795 - acc: 0.5521 - val_loss: 6.5308 - val_acc: 0.5926\n",
      "Epoch 119/150\n",
      "1458/1458 [==============================] - 0s 285us/step - loss: 7.1795 - acc: 0.5521 - val_loss: 6.5308 - val_acc: 0.5926\n",
      "Epoch 120/150\n",
      "1458/1458 [==============================] - 1s 358us/step - loss: 7.1795 - acc: 0.5521 - val_loss: 6.5308 - val_acc: 0.5926\n",
      "Epoch 121/150\n",
      "1458/1458 [==============================] - 1s 427us/step - loss: 7.1795 - acc: 0.5521 - val_loss: 6.5308 - val_acc: 0.5926\n",
      "Epoch 122/150\n",
      "1458/1458 [==============================] - 0s 301us/step - loss: 7.1795 - acc: 0.5521 - val_loss: 6.5308 - val_acc: 0.5926\n",
      "Epoch 123/150\n",
      "1458/1458 [==============================] - 0s 304us/step - loss: 7.1795 - acc: 0.5521 - val_loss: 6.5308 - val_acc: 0.5926\n",
      "Epoch 124/150\n",
      "1458/1458 [==============================] - 0s 296us/step - loss: 7.1795 - acc: 0.5521 - val_loss: 6.5308 - val_acc: 0.5926\n",
      "Epoch 125/150\n",
      "1458/1458 [==============================] - 0s 283us/step - loss: 7.1795 - acc: 0.5521 - val_loss: 6.5308 - val_acc: 0.5926\n",
      "Epoch 126/150\n",
      "1458/1458 [==============================] - 0s 234us/step - loss: 7.1795 - acc: 0.5521 - val_loss: 6.5308 - val_acc: 0.5926\n",
      "Epoch 127/150\n",
      "1458/1458 [==============================] - 0s 237us/step - loss: 7.1795 - acc: 0.5521 - val_loss: 6.5308 - val_acc: 0.5926\n",
      "Epoch 128/150\n",
      "1458/1458 [==============================] - 0s 274us/step - loss: 7.1795 - acc: 0.5521 - val_loss: 6.5308 - val_acc: 0.5926\n",
      "Epoch 129/150\n",
      "1458/1458 [==============================] - 0s 238us/step - loss: 7.1795 - acc: 0.5521 - val_loss: 6.5308 - val_acc: 0.5926\n",
      "Epoch 130/150\n",
      "1458/1458 [==============================] - 0s 286us/step - loss: 7.1795 - acc: 0.5521 - val_loss: 6.5308 - val_acc: 0.5926\n",
      "Epoch 131/150\n",
      "1458/1458 [==============================] - 0s 262us/step - loss: 7.1795 - acc: 0.5521 - val_loss: 6.5308 - val_acc: 0.5926\n",
      "Epoch 132/150\n",
      "1458/1458 [==============================] - 0s 304us/step - loss: 7.1795 - acc: 0.5521 - val_loss: 6.5308 - val_acc: 0.5926\n",
      "Epoch 133/150\n",
      "1458/1458 [==============================] - 0s 260us/step - loss: 7.1795 - acc: 0.5521 - val_loss: 6.5308 - val_acc: 0.5926\n",
      "Epoch 134/150\n",
      "1458/1458 [==============================] - 0s 265us/step - loss: 7.1795 - acc: 0.5521 - val_loss: 6.5308 - val_acc: 0.5926\n",
      "Epoch 135/150\n",
      "1458/1458 [==============================] - 0s 311us/step - loss: 7.1795 - acc: 0.5521 - val_loss: 6.5308 - val_acc: 0.5926\n",
      "Epoch 136/150\n",
      "1458/1458 [==============================] - 0s 310us/step - loss: 7.1795 - acc: 0.5521 - val_loss: 6.5308 - val_acc: 0.5926\n",
      "Epoch 137/150\n",
      "1458/1458 [==============================] - 0s 336us/step - loss: 7.1795 - acc: 0.5521 - val_loss: 6.5308 - val_acc: 0.5926\n",
      "Epoch 138/150\n",
      "1458/1458 [==============================] - 0s 315us/step - loss: 7.1795 - acc: 0.5521 - val_loss: 6.5308 - val_acc: 0.5926\n",
      "Epoch 139/150\n",
      "1458/1458 [==============================] - 0s 289us/step - loss: 7.1795 - acc: 0.5521 - val_loss: 6.5308 - val_acc: 0.5926\n",
      "Epoch 140/150\n",
      "1458/1458 [==============================] - 0s 283us/step - loss: 7.1795 - acc: 0.5521 - val_loss: 6.5308 - val_acc: 0.5926\n",
      "Epoch 141/150\n",
      "1458/1458 [==============================] - 0s 290us/step - loss: 7.1795 - acc: 0.5521 - val_loss: 6.5308 - val_acc: 0.5926\n",
      "Epoch 142/150\n",
      "1458/1458 [==============================] - 0s 289us/step - loss: 7.1795 - acc: 0.5521 - val_loss: 6.5308 - val_acc: 0.5926\n",
      "Epoch 143/150\n",
      "1458/1458 [==============================] - 0s 302us/step - loss: 7.1795 - acc: 0.5521 - val_loss: 6.5308 - val_acc: 0.5926\n",
      "Epoch 144/150\n",
      "1458/1458 [==============================] - 0s 316us/step - loss: 7.1795 - acc: 0.5521 - val_loss: 6.5308 - val_acc: 0.5926\n",
      "Epoch 145/150\n",
      "1458/1458 [==============================] - 1s 371us/step - loss: 7.1795 - acc: 0.5521 - val_loss: 6.5308 - val_acc: 0.5926\n",
      "Epoch 146/150\n",
      "1458/1458 [==============================] - 1s 420us/step - loss: 7.1795 - acc: 0.5521 - val_loss: 6.5308 - val_acc: 0.5926\n",
      "Epoch 147/150\n",
      "1458/1458 [==============================] - 0s 276us/step - loss: 7.1795 - acc: 0.5521 - val_loss: 6.5308 - val_acc: 0.5926\n",
      "Epoch 148/150\n",
      "1458/1458 [==============================] - 0s 295us/step - loss: 7.1795 - acc: 0.5521 - val_loss: 6.5308 - val_acc: 0.5926\n",
      "Epoch 149/150\n",
      "1458/1458 [==============================] - 0s 301us/step - loss: 7.1795 - acc: 0.5521 - val_loss: 6.5308 - val_acc: 0.5926\n",
      "Epoch 150/150\n",
      "1458/1458 [==============================] - 0s 268us/step - loss: 7.1795 - acc: 0.5521 - val_loss: 6.5308 - val_acc: 0.5926\n",
      "The score is......\n",
      " [6.530838083337854, 0.5925925925925926]\n",
      "Compute bottleneck features...\n",
      "train_bNFeatures[img].shape =  (1458, 73728)\n",
      "val_bNFeatures[img].shape =  (162, 73728)\n",
      "Train head...\n",
      "Train on 1458 samples, validate on 162 samples\n",
      "Epoch 1/150\n",
      "1458/1458 [==============================] - 1s 499us/step - loss: 6.7332 - acc: 0.5460 - val_loss: 6.6298 - val_acc: 0.5864\n",
      "Epoch 2/150\n",
      "1458/1458 [==============================] - 0s 324us/step - loss: 7.1685 - acc: 0.5528 - val_loss: 6.6298 - val_acc: 0.5864\n",
      "Epoch 3/150\n",
      "1458/1458 [==============================] - 1s 377us/step - loss: 7.1685 - acc: 0.5528 - val_loss: 6.6298 - val_acc: 0.5864\n",
      "Epoch 4/150\n",
      "1458/1458 [==============================] - 0s 316us/step - loss: 7.1685 - acc: 0.5528 - val_loss: 6.6298 - val_acc: 0.5864\n",
      "Epoch 5/150\n",
      "1458/1458 [==============================] - 0s 315us/step - loss: 7.1685 - acc: 0.5528 - val_loss: 6.6298 - val_acc: 0.5864\n",
      "Epoch 6/150\n",
      "1458/1458 [==============================] - 1s 639us/step - loss: 7.1685 - acc: 0.5528 - val_loss: 6.6298 - val_acc: 0.5864\n",
      "Epoch 7/150\n",
      "1458/1458 [==============================] - 1s 410us/step - loss: 7.1685 - acc: 0.5528 - val_loss: 6.6298 - val_acc: 0.5864\n",
      "Epoch 8/150\n",
      "1458/1458 [==============================] - 0s 321us/step - loss: 7.1685 - acc: 0.5528 - val_loss: 6.6298 - val_acc: 0.5864\n",
      "Epoch 9/150\n",
      "1458/1458 [==============================] - 1s 488us/step - loss: 7.1685 - acc: 0.5528 - val_loss: 6.6298 - val_acc: 0.5864\n",
      "Epoch 10/150\n",
      "1458/1458 [==============================] - 1s 353us/step - loss: 7.1685 - acc: 0.5528 - val_loss: 6.6298 - val_acc: 0.5864\n",
      "Epoch 11/150\n",
      "1458/1458 [==============================] - 0s 296us/step - loss: 7.1685 - acc: 0.5528 - val_loss: 6.6298 - val_acc: 0.5864\n",
      "Epoch 12/150\n",
      "1458/1458 [==============================] - 0s 244us/step - loss: 7.1685 - acc: 0.5528 - val_loss: 6.6298 - val_acc: 0.5864\n",
      "Epoch 13/150\n",
      "1458/1458 [==============================] - 0s 286us/step - loss: 7.1685 - acc: 0.5528 - val_loss: 6.6298 - val_acc: 0.5864\n",
      "Epoch 14/150\n",
      "1458/1458 [==============================] - 0s 317us/step - loss: 7.1685 - acc: 0.5528 - val_loss: 6.6298 - val_acc: 0.5864\n",
      "Epoch 15/150\n",
      "1458/1458 [==============================] - 1s 347us/step - loss: 7.1685 - acc: 0.5528 - val_loss: 6.6298 - val_acc: 0.5864\n",
      "Epoch 16/150\n",
      "1458/1458 [==============================] - 1s 394us/step - loss: 7.1685 - acc: 0.5528 - val_loss: 6.6298 - val_acc: 0.5864\n",
      "Epoch 17/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1458/1458 [==============================] - 0s 322us/step - loss: 7.1685 - acc: 0.5528 - val_loss: 6.6298 - val_acc: 0.5864\n",
      "Epoch 18/150\n",
      "1458/1458 [==============================] - 0s 265us/step - loss: 7.1685 - acc: 0.5528 - val_loss: 6.6298 - val_acc: 0.5864\n",
      "Epoch 19/150\n",
      "1458/1458 [==============================] - 0s 239us/step - loss: 7.1685 - acc: 0.5528 - val_loss: 6.6298 - val_acc: 0.5864\n",
      "Epoch 20/150\n",
      "1458/1458 [==============================] - 0s 277us/step - loss: 7.1685 - acc: 0.5528 - val_loss: 6.6298 - val_acc: 0.5864\n",
      "Epoch 21/150\n",
      "1458/1458 [==============================] - 0s 338us/step - loss: 7.1685 - acc: 0.5528 - val_loss: 6.6298 - val_acc: 0.5864\n",
      "Epoch 22/150\n",
      "1458/1458 [==============================] - 0s 282us/step - loss: 7.1685 - acc: 0.5528 - val_loss: 6.6298 - val_acc: 0.5864\n",
      "Epoch 23/150\n",
      "1458/1458 [==============================] - 1s 367us/step - loss: 7.1685 - acc: 0.5528 - val_loss: 6.6298 - val_acc: 0.5864\n",
      "Epoch 24/150\n",
      "1458/1458 [==============================] - 1s 347us/step - loss: 7.1685 - acc: 0.5528 - val_loss: 6.6298 - val_acc: 0.5864\n",
      "Epoch 25/150\n",
      "1458/1458 [==============================] - 1s 354us/step - loss: 7.1685 - acc: 0.5528 - val_loss: 6.6298 - val_acc: 0.5864\n",
      "Epoch 26/150\n",
      "1458/1458 [==============================] - 0s 321us/step - loss: 7.1685 - acc: 0.5528 - val_loss: 6.6298 - val_acc: 0.5864\n",
      "Epoch 27/150\n",
      "1458/1458 [==============================] - 0s 318us/step - loss: 7.1685 - acc: 0.5528 - val_loss: 6.6298 - val_acc: 0.5864\n",
      "Epoch 28/150\n",
      "1458/1458 [==============================] - 0s 340us/step - loss: 7.1685 - acc: 0.5528 - val_loss: 6.6298 - val_acc: 0.5864\n",
      "Epoch 29/150\n",
      "1458/1458 [==============================] - 1s 364us/step - loss: 7.1685 - acc: 0.5528 - val_loss: 6.6298 - val_acc: 0.5864\n",
      "Epoch 30/150\n",
      "1458/1458 [==============================] - 1s 451us/step - loss: 7.1685 - acc: 0.5528 - val_loss: 6.6298 - val_acc: 0.5864\n",
      "Epoch 31/150\n",
      "1458/1458 [==============================] - 0s 326us/step - loss: 7.1685 - acc: 0.5528 - val_loss: 6.6298 - val_acc: 0.5864\n",
      "Epoch 32/150\n",
      "1458/1458 [==============================] - 0s 323us/step - loss: 7.1685 - acc: 0.5528 - val_loss: 6.6298 - val_acc: 0.5864\n",
      "Epoch 33/150\n",
      "1458/1458 [==============================] - 0s 334us/step - loss: 7.1685 - acc: 0.5528 - val_loss: 6.6298 - val_acc: 0.5864\n",
      "Epoch 34/150\n",
      "1458/1458 [==============================] - 0s 318us/step - loss: 7.1685 - acc: 0.5528 - val_loss: 6.6298 - val_acc: 0.5864\n",
      "Epoch 35/150\n",
      "1458/1458 [==============================] - 0s 283us/step - loss: 7.1685 - acc: 0.5528 - val_loss: 6.6298 - val_acc: 0.5864\n",
      "Epoch 36/150\n",
      "1458/1458 [==============================] - 1s 413us/step - loss: 7.1685 - acc: 0.5528 - val_loss: 6.6298 - val_acc: 0.5864\n",
      "Epoch 37/150\n",
      "1458/1458 [==============================] - 1s 371us/step - loss: 7.1685 - acc: 0.5528 - val_loss: 6.6298 - val_acc: 0.5864\n",
      "Epoch 38/150\n",
      "1458/1458 [==============================] - 0s 300us/step - loss: 7.1685 - acc: 0.5528 - val_loss: 6.6298 - val_acc: 0.5864\n",
      "Epoch 39/150\n",
      "1458/1458 [==============================] - 0s 303us/step - loss: 7.1685 - acc: 0.5528 - val_loss: 6.6298 - val_acc: 0.5864\n",
      "Epoch 40/150\n",
      "1458/1458 [==============================] - 1s 351us/step - loss: 7.1685 - acc: 0.5528 - val_loss: 6.6298 - val_acc: 0.5864\n",
      "Epoch 41/150\n",
      "1458/1458 [==============================] - 1s 431us/step - loss: 7.1685 - acc: 0.5528 - val_loss: 6.6298 - val_acc: 0.5864\n",
      "Epoch 42/150\n",
      "1458/1458 [==============================] - 1s 425us/step - loss: 7.1685 - acc: 0.5528 - val_loss: 6.6298 - val_acc: 0.5864\n",
      "Epoch 43/150\n",
      "1458/1458 [==============================] - 0s 287us/step - loss: 7.1685 - acc: 0.5528 - val_loss: 6.6298 - val_acc: 0.5864\n",
      "Epoch 44/150\n",
      "1458/1458 [==============================] - 0s 324us/step - loss: 7.1685 - acc: 0.5528 - val_loss: 6.6298 - val_acc: 0.5864\n",
      "Epoch 45/150\n",
      "1458/1458 [==============================] - 0s 305us/step - loss: 7.1685 - acc: 0.5528 - val_loss: 6.6298 - val_acc: 0.5864\n",
      "Epoch 46/150\n",
      "1458/1458 [==============================] - 0s 302us/step - loss: 7.1685 - acc: 0.5528 - val_loss: 6.6298 - val_acc: 0.5864\n",
      "Epoch 47/150\n",
      "1458/1458 [==============================] - 0s 286us/step - loss: 7.1685 - acc: 0.5528 - val_loss: 6.6298 - val_acc: 0.5864\n",
      "Epoch 48/150\n",
      "1458/1458 [==============================] - 0s 272us/step - loss: 7.1685 - acc: 0.5528 - val_loss: 6.6298 - val_acc: 0.5864\n",
      "Epoch 49/150\n",
      "1458/1458 [==============================] - 0s 251us/step - loss: 7.1685 - acc: 0.5528 - val_loss: 6.6298 - val_acc: 0.5864\n",
      "Epoch 50/150\n",
      "1458/1458 [==============================] - 0s 265us/step - loss: 7.1685 - acc: 0.5528 - val_loss: 6.6298 - val_acc: 0.5864\n",
      "Epoch 51/150\n",
      "1458/1458 [==============================] - 0s 297us/step - loss: 7.1685 - acc: 0.5528 - val_loss: 6.6298 - val_acc: 0.5864\n",
      "Epoch 52/150\n",
      "1458/1458 [==============================] - 0s 272us/step - loss: 7.1685 - acc: 0.5528 - val_loss: 6.6298 - val_acc: 0.5864\n",
      "Epoch 53/150\n",
      "1458/1458 [==============================] - 0s 234us/step - loss: 7.1685 - acc: 0.5528 - val_loss: 6.6298 - val_acc: 0.5864\n",
      "Epoch 54/150\n",
      "1458/1458 [==============================] - 0s 249us/step - loss: 7.1685 - acc: 0.5528 - val_loss: 6.6298 - val_acc: 0.5864\n",
      "Epoch 55/150\n",
      "1458/1458 [==============================] - 0s 248us/step - loss: 7.1685 - acc: 0.5528 - val_loss: 6.6298 - val_acc: 0.5864\n",
      "Epoch 56/150\n",
      "1458/1458 [==============================] - 0s 270us/step - loss: 7.1685 - acc: 0.5528 - val_loss: 6.6298 - val_acc: 0.5864\n",
      "Epoch 57/150\n",
      "1458/1458 [==============================] - 0s 258us/step - loss: 7.1685 - acc: 0.5528 - val_loss: 6.6298 - val_acc: 0.5864\n",
      "Epoch 58/150\n",
      "1458/1458 [==============================] - 0s 287us/step - loss: 7.1685 - acc: 0.5528 - val_loss: 6.6298 - val_acc: 0.5864\n",
      "Epoch 59/150\n",
      "1458/1458 [==============================] - 0s 257us/step - loss: 7.1685 - acc: 0.5528 - val_loss: 6.6298 - val_acc: 0.5864\n",
      "Epoch 60/150\n",
      "1458/1458 [==============================] - 0s 323us/step - loss: 7.1685 - acc: 0.5528 - val_loss: 6.6298 - val_acc: 0.5864\n",
      "Epoch 61/150\n",
      "1458/1458 [==============================] - 1s 473us/step - loss: 7.1685 - acc: 0.5528 - val_loss: 6.6298 - val_acc: 0.5864\n",
      "Epoch 62/150\n",
      "1458/1458 [==============================] - 1s 368us/step - loss: 7.1685 - acc: 0.5528 - val_loss: 6.6298 - val_acc: 0.5864\n",
      "Epoch 63/150\n",
      "1458/1458 [==============================] - 1s 345us/step - loss: 7.1685 - acc: 0.5528 - val_loss: 6.6298 - val_acc: 0.5864\n",
      "Epoch 64/150\n",
      "1458/1458 [==============================] - 0s 311us/step - loss: 7.1685 - acc: 0.5528 - val_loss: 6.6298 - val_acc: 0.5864\n",
      "Epoch 65/150\n",
      "1458/1458 [==============================] - 1s 453us/step - loss: 7.1685 - acc: 0.5528 - val_loss: 6.6298 - val_acc: 0.5864\n",
      "Epoch 66/150\n",
      "1458/1458 [==============================] - 0s 265us/step - loss: 7.1685 - acc: 0.5528 - val_loss: 6.6298 - val_acc: 0.5864\n",
      "Epoch 67/150\n",
      "1458/1458 [==============================] - 0s 258us/step - loss: 7.1685 - acc: 0.5528 - val_loss: 6.6298 - val_acc: 0.5864\n",
      "Epoch 68/150\n",
      "1458/1458 [==============================] - 1s 361us/step - loss: 7.1685 - acc: 0.5528 - val_loss: 6.6298 - val_acc: 0.5864\n",
      "Epoch 69/150\n",
      "1458/1458 [==============================] - 0s 286us/step - loss: 7.1685 - acc: 0.5528 - val_loss: 6.6298 - val_acc: 0.5864\n",
      "Epoch 70/150\n",
      "1458/1458 [==============================] - 0s 304us/step - loss: 7.1685 - acc: 0.5528 - val_loss: 6.6298 - val_acc: 0.5864\n",
      "Epoch 71/150\n",
      "1458/1458 [==============================] - 1s 476us/step - loss: 7.1685 - acc: 0.5528 - val_loss: 6.6298 - val_acc: 0.5864\n",
      "Epoch 72/150\n",
      "1458/1458 [==============================] - 0s 319us/step - loss: 7.1685 - acc: 0.5528 - val_loss: 6.6298 - val_acc: 0.5864\n",
      "Epoch 73/150\n",
      "1458/1458 [==============================] - 0s 247us/step - loss: 7.1685 - acc: 0.5528 - val_loss: 6.6298 - val_acc: 0.5864\n",
      "Epoch 74/150\n",
      "1458/1458 [==============================] - 0s 234us/step - loss: 7.1685 - acc: 0.5528 - val_loss: 6.6298 - val_acc: 0.5864\n",
      "Epoch 75/150\n",
      "1458/1458 [==============================] - 0s 287us/step - loss: 7.1685 - acc: 0.5528 - val_loss: 6.6298 - val_acc: 0.5864\n",
      "Epoch 76/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1458/1458 [==============================] - 0s 262us/step - loss: 7.1685 - acc: 0.5528 - val_loss: 6.6298 - val_acc: 0.5864\n",
      "Epoch 77/150\n",
      "1458/1458 [==============================] - 0s 258us/step - loss: 7.1685 - acc: 0.5528 - val_loss: 6.6298 - val_acc: 0.5864\n",
      "Epoch 78/150\n",
      "1458/1458 [==============================] - 0s 241us/step - loss: 7.1685 - acc: 0.5528 - val_loss: 6.6298 - val_acc: 0.5864\n",
      "Epoch 79/150\n",
      "1458/1458 [==============================] - 0s 242us/step - loss: 7.1685 - acc: 0.5528 - val_loss: 6.6298 - val_acc: 0.5864\n",
      "Epoch 80/150\n",
      "1458/1458 [==============================] - 1s 365us/step - loss: 7.1685 - acc: 0.5528 - val_loss: 6.6298 - val_acc: 0.5864\n",
      "Epoch 81/150\n",
      "1458/1458 [==============================] - 0s 315us/step - loss: 7.1685 - acc: 0.5528 - val_loss: 6.6298 - val_acc: 0.5864\n",
      "Epoch 82/150\n",
      "1458/1458 [==============================] - 0s 324us/step - loss: 7.1685 - acc: 0.5528 - val_loss: 6.6298 - val_acc: 0.5864\n",
      "Epoch 83/150\n",
      "1458/1458 [==============================] - 0s 280us/step - loss: 7.1685 - acc: 0.5528 - val_loss: 6.6298 - val_acc: 0.5864\n",
      "Epoch 84/150\n",
      "1458/1458 [==============================] - 0s 286us/step - loss: 7.1685 - acc: 0.5528 - val_loss: 6.6298 - val_acc: 0.5864\n",
      "Epoch 85/150\n",
      "1458/1458 [==============================] - 0s 290us/step - loss: 7.1685 - acc: 0.5528 - val_loss: 6.6298 - val_acc: 0.5864\n",
      "Epoch 86/150\n",
      "1458/1458 [==============================] - 0s 247us/step - loss: 7.1685 - acc: 0.5528 - val_loss: 6.6298 - val_acc: 0.5864\n",
      "Epoch 87/150\n",
      "1458/1458 [==============================] - 0s 240us/step - loss: 7.1685 - acc: 0.5528 - val_loss: 6.6298 - val_acc: 0.5864\n",
      "Epoch 88/150\n",
      "1458/1458 [==============================] - 0s 258us/step - loss: 7.1685 - acc: 0.5528 - val_loss: 6.6298 - val_acc: 0.5864\n",
      "Epoch 89/150\n",
      "1458/1458 [==============================] - 0s 325us/step - loss: 7.1685 - acc: 0.5528 - val_loss: 6.6298 - val_acc: 0.5864\n",
      "Epoch 90/150\n",
      "1458/1458 [==============================] - 0s 286us/step - loss: 7.1685 - acc: 0.5528 - val_loss: 6.6298 - val_acc: 0.5864\n",
      "Epoch 91/150\n",
      "1458/1458 [==============================] - 0s 278us/step - loss: 7.1685 - acc: 0.5528 - val_loss: 6.6298 - val_acc: 0.5864\n",
      "Epoch 92/150\n",
      "1458/1458 [==============================] - 0s 280us/step - loss: 7.1685 - acc: 0.5528 - val_loss: 6.6298 - val_acc: 0.5864\n",
      "Epoch 93/150\n",
      "1458/1458 [==============================] - 0s 285us/step - loss: 7.1685 - acc: 0.5528 - val_loss: 6.6298 - val_acc: 0.5864\n",
      "Epoch 94/150\n",
      "1458/1458 [==============================] - 1s 352us/step - loss: 7.1685 - acc: 0.5528 - val_loss: 6.6298 - val_acc: 0.5864\n",
      "Epoch 95/150\n",
      "1458/1458 [==============================] - 1s 369us/step - loss: 7.1685 - acc: 0.5528 - val_loss: 6.6298 - val_acc: 0.5864\n",
      "Epoch 96/150\n",
      "1458/1458 [==============================] - 0s 328us/step - loss: 7.1685 - acc: 0.5528 - val_loss: 6.6298 - val_acc: 0.5864\n",
      "Epoch 97/150\n",
      "1458/1458 [==============================] - 0s 314us/step - loss: 7.1685 - acc: 0.5528 - val_loss: 6.6298 - val_acc: 0.5864\n",
      "Epoch 98/150\n",
      "1458/1458 [==============================] - 0s 321us/step - loss: 7.1685 - acc: 0.5528 - val_loss: 6.6298 - val_acc: 0.5864\n",
      "Epoch 99/150\n",
      "1458/1458 [==============================] - 0s 338us/step - loss: 7.1685 - acc: 0.5528 - val_loss: 6.6298 - val_acc: 0.5864\n",
      "Epoch 100/150\n",
      "1458/1458 [==============================] - 0s 310us/step - loss: 7.1685 - acc: 0.5528 - val_loss: 6.6298 - val_acc: 0.5864\n",
      "Epoch 101/150\n",
      "1458/1458 [==============================] - 1s 456us/step - loss: 7.1685 - acc: 0.5528 - val_loss: 6.6298 - val_acc: 0.5864\n",
      "Epoch 102/150\n",
      "1458/1458 [==============================] - 0s 302us/step - loss: 7.1685 - acc: 0.5528 - val_loss: 6.6298 - val_acc: 0.5864\n",
      "Epoch 103/150\n",
      "1458/1458 [==============================] - 0s 342us/step - loss: 7.1685 - acc: 0.5528 - val_loss: 6.6298 - val_acc: 0.5864\n",
      "Epoch 104/150\n",
      "1458/1458 [==============================] - 1s 369us/step - loss: 7.1685 - acc: 0.5528 - val_loss: 6.6298 - val_acc: 0.5864\n",
      "Epoch 105/150\n",
      "1458/1458 [==============================] - 0s 289us/step - loss: 7.1685 - acc: 0.5528 - val_loss: 6.6298 - val_acc: 0.5864\n",
      "Epoch 106/150\n",
      "1458/1458 [==============================] - 0s 341us/step - loss: 7.1685 - acc: 0.5528 - val_loss: 6.6298 - val_acc: 0.5864\n",
      "Epoch 107/150\n",
      "1458/1458 [==============================] - 0s 293us/step - loss: 7.1685 - acc: 0.5528 - val_loss: 6.6298 - val_acc: 0.5864\n",
      "Epoch 108/150\n",
      "1458/1458 [==============================] - 1s 345us/step - loss: 7.1685 - acc: 0.5528 - val_loss: 6.6298 - val_acc: 0.5864\n",
      "Epoch 109/150\n",
      "1458/1458 [==============================] - 0s 336us/step - loss: 7.1685 - acc: 0.5528 - val_loss: 6.6298 - val_acc: 0.5864\n",
      "Epoch 110/150\n",
      "1458/1458 [==============================] - 1s 402us/step - loss: 7.1685 - acc: 0.5528 - val_loss: 6.6298 - val_acc: 0.5864\n",
      "Epoch 111/150\n",
      "1458/1458 [==============================] - 1s 412us/step - loss: 7.1685 - acc: 0.5528 - val_loss: 6.6298 - val_acc: 0.5864\n",
      "Epoch 112/150\n",
      "1458/1458 [==============================] - 0s 322us/step - loss: 7.1685 - acc: 0.5528 - val_loss: 6.6298 - val_acc: 0.5864\n",
      "Epoch 113/150\n",
      "1458/1458 [==============================] - 0s 333us/step - loss: 7.1685 - acc: 0.5528 - val_loss: 6.6298 - val_acc: 0.5864\n",
      "Epoch 114/150\n",
      "1458/1458 [==============================] - 1s 360us/step - loss: 7.1685 - acc: 0.5528 - val_loss: 6.6298 - val_acc: 0.5864\n",
      "Epoch 115/150\n",
      "1458/1458 [==============================] - 1s 460us/step - loss: 7.1685 - acc: 0.5528 - val_loss: 6.6298 - val_acc: 0.5864\n",
      "Epoch 116/150\n",
      "1458/1458 [==============================] - 0s 330us/step - loss: 7.1685 - acc: 0.5528 - val_loss: 6.6298 - val_acc: 0.5864\n",
      "Epoch 117/150\n",
      "1458/1458 [==============================] - 0s 339us/step - loss: 7.1685 - acc: 0.5528 - val_loss: 6.6298 - val_acc: 0.5864\n",
      "Epoch 118/150\n",
      "1458/1458 [==============================] - 0s 299us/step - loss: 7.1685 - acc: 0.5528 - val_loss: 6.6298 - val_acc: 0.5864\n",
      "Epoch 119/150\n",
      "1458/1458 [==============================] - 1s 367us/step - loss: 7.1685 - acc: 0.5528 - val_loss: 6.6298 - val_acc: 0.5864\n",
      "Epoch 120/150\n",
      "1458/1458 [==============================] - 1s 359us/step - loss: 7.1685 - acc: 0.5528 - val_loss: 6.6298 - val_acc: 0.5864\n",
      "Epoch 121/150\n",
      "1458/1458 [==============================] - 0s 286us/step - loss: 7.1685 - acc: 0.5528 - val_loss: 6.6298 - val_acc: 0.5864\n",
      "Epoch 122/150\n",
      "1458/1458 [==============================] - 0s 300us/step - loss: 7.1685 - acc: 0.5528 - val_loss: 6.6298 - val_acc: 0.5864\n",
      "Epoch 123/150\n",
      "1458/1458 [==============================] - 0s 284us/step - loss: 7.1685 - acc: 0.5528 - val_loss: 6.6298 - val_acc: 0.5864\n",
      "Epoch 124/150\n",
      "1458/1458 [==============================] - 0s 310us/step - loss: 7.1685 - acc: 0.5528 - val_loss: 6.6298 - val_acc: 0.5864\n",
      "Epoch 125/150\n",
      "1458/1458 [==============================] - 0s 261us/step - loss: 7.1685 - acc: 0.5528 - val_loss: 6.6298 - val_acc: 0.5864\n",
      "Epoch 126/150\n",
      "1458/1458 [==============================] - 0s 279us/step - loss: 7.1685 - acc: 0.5528 - val_loss: 6.6298 - val_acc: 0.5864\n",
      "Epoch 127/150\n",
      "1458/1458 [==============================] - 0s 299us/step - loss: 7.1685 - acc: 0.5528 - val_loss: 6.6298 - val_acc: 0.5864\n",
      "Epoch 128/150\n",
      "1458/1458 [==============================] - 0s 287us/step - loss: 7.1685 - acc: 0.5528 - val_loss: 6.6298 - val_acc: 0.5864\n",
      "Epoch 129/150\n",
      "1458/1458 [==============================] - 0s 293us/step - loss: 7.1685 - acc: 0.5528 - val_loss: 6.6298 - val_acc: 0.5864\n",
      "Epoch 130/150\n",
      "1458/1458 [==============================] - 0s 295us/step - loss: 7.1685 - acc: 0.5528 - val_loss: 6.6298 - val_acc: 0.5864\n",
      "Epoch 131/150\n",
      "1458/1458 [==============================] - 0s 266us/step - loss: 7.1685 - acc: 0.5528 - val_loss: 6.6298 - val_acc: 0.5864\n",
      "Epoch 132/150\n",
      "1458/1458 [==============================] - 0s 242us/step - loss: 7.1685 - acc: 0.5528 - val_loss: 6.6298 - val_acc: 0.5864\n",
      "Epoch 133/150\n",
      "1458/1458 [==============================] - 0s 263us/step - loss: 7.1685 - acc: 0.5528 - val_loss: 6.6298 - val_acc: 0.5864\n",
      "Epoch 134/150\n",
      "1458/1458 [==============================] - 0s 289us/step - loss: 7.1685 - acc: 0.5528 - val_loss: 6.6298 - val_acc: 0.5864\n",
      "Epoch 135/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1458/1458 [==============================] - 0s 268us/step - loss: 7.1685 - acc: 0.5528 - val_loss: 6.6298 - val_acc: 0.5864\n",
      "Epoch 136/150\n",
      "1458/1458 [==============================] - 0s 291us/step - loss: 7.1685 - acc: 0.5528 - val_loss: 6.6298 - val_acc: 0.5864\n",
      "Epoch 137/150\n",
      "1458/1458 [==============================] - 0s 274us/step - loss: 7.1685 - acc: 0.5528 - val_loss: 6.6298 - val_acc: 0.5864\n",
      "Epoch 138/150\n",
      "1458/1458 [==============================] - 0s 255us/step - loss: 7.1685 - acc: 0.5528 - val_loss: 6.6298 - val_acc: 0.5864\n",
      "Epoch 139/150\n",
      "1458/1458 [==============================] - 0s 236us/step - loss: 7.1685 - acc: 0.5528 - val_loss: 6.6298 - val_acc: 0.5864\n",
      "Epoch 140/150\n",
      "1458/1458 [==============================] - 0s 230us/step - loss: 7.1685 - acc: 0.5528 - val_loss: 6.6298 - val_acc: 0.5864\n",
      "Epoch 141/150\n",
      "1458/1458 [==============================] - 0s 249us/step - loss: 7.1685 - acc: 0.5528 - val_loss: 6.6298 - val_acc: 0.5864\n",
      "Epoch 142/150\n",
      "1458/1458 [==============================] - 0s 319us/step - loss: 7.1685 - acc: 0.5528 - val_loss: 6.6298 - val_acc: 0.5864\n",
      "Epoch 143/150\n",
      "1458/1458 [==============================] - 0s 313us/step - loss: 7.1685 - acc: 0.5528 - val_loss: 6.6298 - val_acc: 0.5864\n",
      "Epoch 144/150\n",
      "1458/1458 [==============================] - 0s 228us/step - loss: 7.1685 - acc: 0.5528 - val_loss: 6.6298 - val_acc: 0.5864\n",
      "Epoch 145/150\n",
      "1458/1458 [==============================] - 0s 324us/step - loss: 7.1685 - acc: 0.5528 - val_loss: 6.6298 - val_acc: 0.5864\n",
      "Epoch 146/150\n",
      "1458/1458 [==============================] - 0s 291us/step - loss: 7.1685 - acc: 0.5528 - val_loss: 6.6298 - val_acc: 0.5864\n",
      "Epoch 147/150\n",
      "1458/1458 [==============================] - 0s 291us/step - loss: 7.1685 - acc: 0.5528 - val_loss: 6.6298 - val_acc: 0.5864\n",
      "Epoch 148/150\n",
      "1458/1458 [==============================] - 0s 290us/step - loss: 7.1685 - acc: 0.5528 - val_loss: 6.6298 - val_acc: 0.5864\n",
      "Epoch 149/150\n",
      "1458/1458 [==============================] - 0s 241us/step - loss: 7.1685 - acc: 0.5528 - val_loss: 6.6298 - val_acc: 0.5864\n",
      "Epoch 150/150\n",
      "1458/1458 [==============================] - 0s 274us/step - loss: 7.1685 - acc: 0.5528 - val_loss: 6.6298 - val_acc: 0.5864\n",
      "The score is......\n",
      " [6.6297902943175515, 0.5864197530864198]\n",
      "Compute bottleneck features...\n",
      "train_bNFeatures[img].shape =  (1458, 73728)\n",
      "val_bNFeatures[img].shape =  (162, 73728)\n",
      "Train head...\n",
      "Train on 1458 samples, validate on 162 samples\n",
      "Epoch 1/150\n",
      "1458/1458 [==============================] - 1s 514us/step - loss: 1.2905 - acc: 0.5439 - val_loss: 0.6921 - val_acc: 0.5926\n",
      "Epoch 2/150\n",
      "1458/1458 [==============================] - 0s 315us/step - loss: 0.6923 - acc: 0.5521 - val_loss: 0.6911 - val_acc: 0.5926\n",
      "Epoch 3/150\n",
      "1458/1458 [==============================] - 0s 255us/step - loss: 0.6918 - acc: 0.5521 - val_loss: 0.6902 - val_acc: 0.5926\n",
      "Epoch 4/150\n",
      "1458/1458 [==============================] - 0s 275us/step - loss: 0.6913 - acc: 0.5521 - val_loss: 0.6893 - val_acc: 0.5926\n",
      "Epoch 5/150\n",
      "1458/1458 [==============================] - 0s 294us/step - loss: 0.6909 - acc: 0.5521 - val_loss: 0.6883 - val_acc: 0.5926\n",
      "Epoch 6/150\n",
      "1458/1458 [==============================] - 0s 256us/step - loss: 0.6904 - acc: 0.5521 - val_loss: 0.6873 - val_acc: 0.5926\n",
      "Epoch 7/150\n",
      "1458/1458 [==============================] - 0s 245us/step - loss: 0.6900 - acc: 0.5521 - val_loss: 0.6866 - val_acc: 0.5926\n",
      "Epoch 8/150\n",
      "1458/1458 [==============================] - 0s 239us/step - loss: 0.6896 - acc: 0.5521 - val_loss: 0.6858 - val_acc: 0.5926\n",
      "Epoch 9/150\n",
      "1458/1458 [==============================] - 0s 305us/step - loss: 0.6893 - acc: 0.5521 - val_loss: 0.6850 - val_acc: 0.5926\n",
      "Epoch 10/150\n",
      "1458/1458 [==============================] - 0s 312us/step - loss: 0.6890 - acc: 0.5521 - val_loss: 0.6844 - val_acc: 0.5926\n",
      "Epoch 11/150\n",
      "1458/1458 [==============================] - 0s 279us/step - loss: 0.6888 - acc: 0.5521 - val_loss: 0.6839 - val_acc: 0.5926\n",
      "Epoch 12/150\n",
      "1458/1458 [==============================] - 0s 234us/step - loss: 0.6886 - acc: 0.5521 - val_loss: 0.6834 - val_acc: 0.5926\n",
      "Epoch 13/150\n",
      "1458/1458 [==============================] - 0s 277us/step - loss: 0.6885 - acc: 0.5521 - val_loss: 0.6829 - val_acc: 0.5926\n",
      "Epoch 14/150\n",
      "1458/1458 [==============================] - 0s 295us/step - loss: 0.6883 - acc: 0.5521 - val_loss: 0.6825 - val_acc: 0.5926\n",
      "Epoch 15/150\n",
      "1458/1458 [==============================] - 1s 448us/step - loss: 0.6882 - acc: 0.5521 - val_loss: 0.6821 - val_acc: 0.5926\n",
      "Epoch 16/150\n",
      "1458/1458 [==============================] - 0s 320us/step - loss: 0.6881 - acc: 0.5521 - val_loss: 0.6817 - val_acc: 0.5926\n",
      "Epoch 17/150\n",
      "1458/1458 [==============================] - 0s 299us/step - loss: 0.6880 - acc: 0.5521 - val_loss: 0.6815 - val_acc: 0.5926\n",
      "Epoch 18/150\n",
      "1458/1458 [==============================] - 0s 244us/step - loss: 0.6880 - acc: 0.5521 - val_loss: 0.6812 - val_acc: 0.5926\n",
      "Epoch 19/150\n",
      "1458/1458 [==============================] - 0s 291us/step - loss: 0.6879 - acc: 0.5521 - val_loss: 0.6811 - val_acc: 0.5926\n",
      "Epoch 20/150\n",
      "1458/1458 [==============================] - 0s 265us/step - loss: 0.6879 - acc: 0.5521 - val_loss: 0.6808 - val_acc: 0.5926\n",
      "Epoch 21/150\n",
      "1458/1458 [==============================] - 0s 262us/step - loss: 0.6879 - acc: 0.5521 - val_loss: 0.6807 - val_acc: 0.5926\n",
      "Epoch 22/150\n",
      "1458/1458 [==============================] - 0s 228us/step - loss: 0.6878 - acc: 0.5521 - val_loss: 0.6805 - val_acc: 0.5926\n",
      "Epoch 23/150\n",
      "1458/1458 [==============================] - 0s 231us/step - loss: 0.6878 - acc: 0.5521 - val_loss: 0.6803 - val_acc: 0.5926\n",
      "Epoch 24/150\n",
      "1458/1458 [==============================] - 0s 266us/step - loss: 0.6878 - acc: 0.5521 - val_loss: 0.6803 - val_acc: 0.5926\n",
      "Epoch 25/150\n",
      "1458/1458 [==============================] - 0s 266us/step - loss: 0.6878 - acc: 0.5521 - val_loss: 0.6802 - val_acc: 0.5926\n",
      "Epoch 26/150\n",
      "1458/1458 [==============================] - 0s 225us/step - loss: 0.6878 - acc: 0.5521 - val_loss: 0.6800 - val_acc: 0.5926\n",
      "Epoch 27/150\n",
      "1458/1458 [==============================] - 0s 230us/step - loss: 0.6878 - acc: 0.5521 - val_loss: 0.6800 - val_acc: 0.5926\n",
      "Epoch 28/150\n",
      "1458/1458 [==============================] - 0s 257us/step - loss: 0.6877 - acc: 0.5521 - val_loss: 0.6798 - val_acc: 0.5926\n",
      "Epoch 29/150\n",
      "1458/1458 [==============================] - 0s 264us/step - loss: 0.6877 - acc: 0.5521 - val_loss: 0.6797 - val_acc: 0.5926\n",
      "Epoch 30/150\n",
      "1458/1458 [==============================] - 0s 256us/step - loss: 0.6877 - acc: 0.5521 - val_loss: 0.6796 - val_acc: 0.5926\n",
      "Epoch 31/150\n",
      "1458/1458 [==============================] - 0s 274us/step - loss: 0.6877 - acc: 0.5521 - val_loss: 0.6797 - val_acc: 0.5926\n",
      "Epoch 32/150\n",
      "1458/1458 [==============================] - 0s 280us/step - loss: 0.6877 - acc: 0.5521 - val_loss: 0.6796 - val_acc: 0.5926\n",
      "Epoch 33/150\n",
      "1458/1458 [==============================] - 0s 257us/step - loss: 0.6877 - acc: 0.5521 - val_loss: 0.6795 - val_acc: 0.5926\n",
      "Epoch 34/150\n",
      "1458/1458 [==============================] - 0s 305us/step - loss: 0.6877 - acc: 0.5521 - val_loss: 0.6794 - val_acc: 0.5926\n",
      "Epoch 35/150\n",
      "1458/1458 [==============================] - 0s 340us/step - loss: 0.6877 - acc: 0.5521 - val_loss: 0.6795 - val_acc: 0.5926\n",
      "Epoch 36/150\n",
      "1458/1458 [==============================] - 0s 299us/step - loss: 0.6877 - acc: 0.5521 - val_loss: 0.6794 - val_acc: 0.5926\n",
      "Epoch 37/150\n",
      "1458/1458 [==============================] - 0s 279us/step - loss: 0.6877 - acc: 0.5521 - val_loss: 0.6795 - val_acc: 0.5926\n",
      "Epoch 38/150\n",
      "1458/1458 [==============================] - 0s 234us/step - loss: 0.6877 - acc: 0.5521 - val_loss: 0.6795 - val_acc: 0.5926\n",
      "Epoch 39/150\n",
      "1458/1458 [==============================] - 0s 258us/step - loss: 0.6877 - acc: 0.5521 - val_loss: 0.6795 - val_acc: 0.5926\n",
      "Epoch 40/150\n",
      "1458/1458 [==============================] - 0s 234us/step - loss: 0.6877 - acc: 0.5521 - val_loss: 0.6794 - val_acc: 0.5926\n",
      "Epoch 41/150\n",
      "1458/1458 [==============================] - 0s 229us/step - loss: 0.6877 - acc: 0.5521 - val_loss: 0.6795 - val_acc: 0.5926\n",
      "Epoch 42/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1458/1458 [==============================] - 0s 260us/step - loss: 0.6877 - acc: 0.5521 - val_loss: 0.6793 - val_acc: 0.5926\n",
      "Epoch 43/150\n",
      "1458/1458 [==============================] - 0s 273us/step - loss: 0.6877 - acc: 0.5521 - val_loss: 0.6794 - val_acc: 0.5926\n",
      "Epoch 44/150\n",
      "1458/1458 [==============================] - 0s 259us/step - loss: 0.6877 - acc: 0.5521 - val_loss: 0.6794 - val_acc: 0.5926\n",
      "Epoch 45/150\n",
      "1458/1458 [==============================] - 0s 260us/step - loss: 0.6877 - acc: 0.5521 - val_loss: 0.6794 - val_acc: 0.5926\n",
      "Epoch 46/150\n",
      "1458/1458 [==============================] - 0s 267us/step - loss: 0.6877 - acc: 0.5521 - val_loss: 0.6794 - val_acc: 0.5926\n",
      "Epoch 47/150\n",
      "1458/1458 [==============================] - 0s 283us/step - loss: 0.6877 - acc: 0.5521 - val_loss: 0.6793 - val_acc: 0.5926\n",
      "Epoch 48/150\n",
      "1458/1458 [==============================] - 0s 273us/step - loss: 0.6877 - acc: 0.5521 - val_loss: 0.6793 - val_acc: 0.5926\n",
      "Epoch 49/150\n",
      "1458/1458 [==============================] - 0s 272us/step - loss: 0.6877 - acc: 0.5521 - val_loss: 0.6792 - val_acc: 0.5926\n",
      "Epoch 50/150\n",
      "1458/1458 [==============================] - 0s 282us/step - loss: 0.6877 - acc: 0.5521 - val_loss: 0.6792 - val_acc: 0.5926\n",
      "Epoch 51/150\n",
      "1458/1458 [==============================] - 0s 248us/step - loss: 0.6877 - acc: 0.5521 - val_loss: 0.6792 - val_acc: 0.5926\n",
      "Epoch 52/150\n",
      "1458/1458 [==============================] - 0s 231us/step - loss: 0.6877 - acc: 0.5521 - val_loss: 0.6793 - val_acc: 0.5926\n",
      "Epoch 53/150\n",
      "1458/1458 [==============================] - 0s 271us/step - loss: 0.6877 - acc: 0.5521 - val_loss: 0.6793 - val_acc: 0.5926\n",
      "Epoch 54/150\n",
      "1458/1458 [==============================] - 0s 244us/step - loss: 0.6877 - acc: 0.5521 - val_loss: 0.6792 - val_acc: 0.5926\n",
      "Epoch 55/150\n",
      "1458/1458 [==============================] - 0s 302us/step - loss: 0.6877 - acc: 0.5521 - val_loss: 0.6792 - val_acc: 0.5926\n",
      "Epoch 56/150\n",
      "1458/1458 [==============================] - 0s 263us/step - loss: 0.6877 - acc: 0.5521 - val_loss: 0.6793 - val_acc: 0.5926\n",
      "Epoch 57/150\n",
      "1458/1458 [==============================] - 0s 245us/step - loss: 0.6877 - acc: 0.5521 - val_loss: 0.6792 - val_acc: 0.5926\n",
      "Epoch 58/150\n",
      "1458/1458 [==============================] - 0s 285us/step - loss: 0.6877 - acc: 0.5521 - val_loss: 0.6791 - val_acc: 0.5926\n",
      "Epoch 59/150\n",
      "1458/1458 [==============================] - 0s 272us/step - loss: 0.6877 - acc: 0.5521 - val_loss: 0.6791 - val_acc: 0.5926\n",
      "Epoch 60/150\n",
      "1458/1458 [==============================] - 0s 279us/step - loss: 0.6877 - acc: 0.5521 - val_loss: 0.6790 - val_acc: 0.5926\n",
      "Epoch 61/150\n",
      "1458/1458 [==============================] - 0s 243us/step - loss: 0.6877 - acc: 0.5521 - val_loss: 0.6790 - val_acc: 0.5926\n",
      "Epoch 62/150\n",
      "1458/1458 [==============================] - 0s 235us/step - loss: 0.6877 - acc: 0.5521 - val_loss: 0.6790 - val_acc: 0.5926\n",
      "Epoch 63/150\n",
      "1458/1458 [==============================] - 0s 242us/step - loss: 0.6877 - acc: 0.5521 - val_loss: 0.6790 - val_acc: 0.5926\n",
      "Epoch 64/150\n",
      "1458/1458 [==============================] - 0s 258us/step - loss: 0.6877 - acc: 0.5521 - val_loss: 0.6791 - val_acc: 0.5926\n",
      "Epoch 65/150\n",
      "1458/1458 [==============================] - 0s 256us/step - loss: 0.6877 - acc: 0.5521 - val_loss: 0.6791 - val_acc: 0.5926\n",
      "Epoch 66/150\n",
      "1458/1458 [==============================] - 0s 299us/step - loss: 0.6877 - acc: 0.5521 - val_loss: 0.6792 - val_acc: 0.5926\n",
      "Epoch 67/150\n",
      "1458/1458 [==============================] - 0s 282us/step - loss: 0.6877 - acc: 0.5521 - val_loss: 0.6792 - val_acc: 0.5926\n",
      "Epoch 68/150\n",
      "1458/1458 [==============================] - 0s 285us/step - loss: 0.6877 - acc: 0.5521 - val_loss: 0.6793 - val_acc: 0.5926\n",
      "Epoch 69/150\n",
      "1458/1458 [==============================] - 0s 298us/step - loss: 0.6877 - acc: 0.5521 - val_loss: 0.6792 - val_acc: 0.5926\n",
      "Epoch 70/150\n",
      "1458/1458 [==============================] - 0s 239us/step - loss: 0.6877 - acc: 0.5521 - val_loss: 0.6794 - val_acc: 0.5926\n",
      "Epoch 71/150\n",
      "1458/1458 [==============================] - 0s 235us/step - loss: 0.6877 - acc: 0.5521 - val_loss: 0.6793 - val_acc: 0.5926\n",
      "Epoch 72/150\n",
      "1458/1458 [==============================] - 0s 255us/step - loss: 0.6877 - acc: 0.5521 - val_loss: 0.6794 - val_acc: 0.5926\n",
      "Epoch 73/150\n",
      "1458/1458 [==============================] - 0s 234us/step - loss: 0.6877 - acc: 0.5521 - val_loss: 0.6794 - val_acc: 0.5926\n",
      "Epoch 74/150\n",
      "1458/1458 [==============================] - 0s 233us/step - loss: 0.6877 - acc: 0.5521 - val_loss: 0.6794 - val_acc: 0.5926\n",
      "Epoch 75/150\n",
      "1458/1458 [==============================] - 0s 230us/step - loss: 0.6877 - acc: 0.5521 - val_loss: 0.6794 - val_acc: 0.5926\n",
      "Epoch 76/150\n",
      "1458/1458 [==============================] - 0s 236us/step - loss: 0.6877 - acc: 0.5521 - val_loss: 0.6793 - val_acc: 0.5926\n",
      "Epoch 77/150\n",
      "1458/1458 [==============================] - 0s 272us/step - loss: 0.6877 - acc: 0.5521 - val_loss: 0.6795 - val_acc: 0.5926\n",
      "Epoch 78/150\n",
      "1458/1458 [==============================] - 0s 283us/step - loss: 0.6877 - acc: 0.5521 - val_loss: 0.6794 - val_acc: 0.5926\n",
      "Epoch 79/150\n",
      "1458/1458 [==============================] - 0s 296us/step - loss: 0.6877 - acc: 0.5521 - val_loss: 0.6793 - val_acc: 0.5926\n",
      "Epoch 80/150\n",
      "1458/1458 [==============================] - 0s 288us/step - loss: 0.6877 - acc: 0.5521 - val_loss: 0.6792 - val_acc: 0.5926\n",
      "Epoch 81/150\n",
      "1458/1458 [==============================] - 0s 277us/step - loss: 0.6877 - acc: 0.5521 - val_loss: 0.6792 - val_acc: 0.5926\n",
      "Epoch 82/150\n",
      "1458/1458 [==============================] - 0s 312us/step - loss: 0.6877 - acc: 0.5521 - val_loss: 0.6791 - val_acc: 0.5926\n",
      "Epoch 83/150\n",
      "1458/1458 [==============================] - 0s 310us/step - loss: 0.6877 - acc: 0.5521 - val_loss: 0.6791 - val_acc: 0.5926\n",
      "Epoch 84/150\n",
      "1458/1458 [==============================] - 0s 307us/step - loss: 0.6877 - acc: 0.5521 - val_loss: 0.6793 - val_acc: 0.5926\n",
      "Epoch 85/150\n",
      "1458/1458 [==============================] - 0s 295us/step - loss: 0.6877 - acc: 0.5521 - val_loss: 0.6793 - val_acc: 0.5926\n",
      "Epoch 86/150\n",
      "1458/1458 [==============================] - 0s 262us/step - loss: 0.6877 - acc: 0.5521 - val_loss: 0.6793 - val_acc: 0.5926\n",
      "Epoch 87/150\n",
      "1458/1458 [==============================] - 0s 276us/step - loss: 0.6877 - acc: 0.5521 - val_loss: 0.6794 - val_acc: 0.5926\n",
      "Epoch 88/150\n",
      "1458/1458 [==============================] - 0s 289us/step - loss: 0.6878 - acc: 0.5521 - val_loss: 0.6795 - val_acc: 0.5926\n",
      "Epoch 89/150\n",
      "1458/1458 [==============================] - 0s 296us/step - loss: 0.6877 - acc: 0.5521 - val_loss: 0.6795 - val_acc: 0.5926\n",
      "Epoch 90/150\n",
      "1458/1458 [==============================] - 0s 301us/step - loss: 0.6877 - acc: 0.5521 - val_loss: 0.6794 - val_acc: 0.5926\n",
      "Epoch 91/150\n",
      "1458/1458 [==============================] - 1s 409us/step - loss: 0.6877 - acc: 0.5521 - val_loss: 0.6794 - val_acc: 0.5926\n",
      "Epoch 92/150\n",
      "1458/1458 [==============================] - 0s 291us/step - loss: 0.6877 - acc: 0.5521 - val_loss: 0.6794 - val_acc: 0.5926\n",
      "Epoch 93/150\n",
      "1458/1458 [==============================] - 0s 233us/step - loss: 0.6877 - acc: 0.5521 - val_loss: 0.6792 - val_acc: 0.5926\n",
      "Epoch 94/150\n",
      "1458/1458 [==============================] - 0s 286us/step - loss: 0.6877 - acc: 0.5521 - val_loss: 0.6793 - val_acc: 0.5926\n",
      "Epoch 95/150\n",
      "1458/1458 [==============================] - 0s 297us/step - loss: 0.6877 - acc: 0.5521 - val_loss: 0.6792 - val_acc: 0.5926\n",
      "Epoch 96/150\n",
      "1458/1458 [==============================] - 0s 240us/step - loss: 0.6877 - acc: 0.5521 - val_loss: 0.6791 - val_acc: 0.5926\n",
      "Epoch 97/150\n",
      "1458/1458 [==============================] - 0s 261us/step - loss: 0.6878 - acc: 0.5521 - val_loss: 0.6793 - val_acc: 0.5926\n",
      "Epoch 98/150\n",
      "1458/1458 [==============================] - 0s 247us/step - loss: 0.6877 - acc: 0.5521 - val_loss: 0.6793 - val_acc: 0.5926\n",
      "Epoch 99/150\n",
      "1458/1458 [==============================] - 0s 291us/step - loss: 0.6877 - acc: 0.5521 - val_loss: 0.6793 - val_acc: 0.5926\n",
      "Epoch 100/150\n",
      "1458/1458 [==============================] - 0s 294us/step - loss: 0.6877 - acc: 0.5521 - val_loss: 0.6793 - val_acc: 0.5926\n",
      "Epoch 101/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1458/1458 [==============================] - 0s 273us/step - loss: 0.6877 - acc: 0.5521 - val_loss: 0.6792 - val_acc: 0.5926\n",
      "Epoch 102/150\n",
      "1458/1458 [==============================] - 0s 268us/step - loss: 0.6877 - acc: 0.5521 - val_loss: 0.6793 - val_acc: 0.5926\n",
      "Epoch 103/150\n",
      "1458/1458 [==============================] - 0s 270us/step - loss: 0.6877 - acc: 0.5521 - val_loss: 0.6794 - val_acc: 0.5926\n",
      "Epoch 104/150\n",
      "1458/1458 [==============================] - 0s 273us/step - loss: 0.6877 - acc: 0.5521 - val_loss: 0.6794 - val_acc: 0.5926\n",
      "Epoch 105/150\n",
      "1458/1458 [==============================] - 0s 231us/step - loss: 0.6877 - acc: 0.5521 - val_loss: 0.6792 - val_acc: 0.5926\n",
      "Epoch 106/150\n",
      "1458/1458 [==============================] - 0s 234us/step - loss: 0.6877 - acc: 0.5521 - val_loss: 0.6793 - val_acc: 0.5926\n",
      "Epoch 107/150\n",
      "1458/1458 [==============================] - 0s 292us/step - loss: 0.6877 - acc: 0.5521 - val_loss: 0.6793 - val_acc: 0.5926\n",
      "Epoch 108/150\n",
      "1458/1458 [==============================] - 0s 280us/step - loss: 0.6877 - acc: 0.5521 - val_loss: 0.6794 - val_acc: 0.5926\n",
      "Epoch 109/150\n",
      "1458/1458 [==============================] - 0s 291us/step - loss: 0.6877 - acc: 0.5521 - val_loss: 0.6794 - val_acc: 0.5926\n",
      "Epoch 110/150\n",
      "1458/1458 [==============================] - 0s 244us/step - loss: 0.6877 - acc: 0.5521 - val_loss: 0.6793 - val_acc: 0.5926\n",
      "Epoch 111/150\n",
      "1458/1458 [==============================] - 0s 259us/step - loss: 0.6877 - acc: 0.5521 - val_loss: 0.6793 - val_acc: 0.5926\n",
      "Epoch 112/150\n",
      "1458/1458 [==============================] - 0s 295us/step - loss: 0.6877 - acc: 0.5521 - val_loss: 0.6793 - val_acc: 0.5926\n",
      "Epoch 113/150\n",
      "1458/1458 [==============================] - 0s 232us/step - loss: 0.6877 - acc: 0.5521 - val_loss: 0.6793 - val_acc: 0.5926\n",
      "Epoch 114/150\n",
      "1458/1458 [==============================] - 0s 231us/step - loss: 0.6877 - acc: 0.5521 - val_loss: 0.6792 - val_acc: 0.5926\n",
      "Epoch 115/150\n",
      "1458/1458 [==============================] - 0s 290us/step - loss: 0.6877 - acc: 0.5521 - val_loss: 0.6793 - val_acc: 0.5926\n",
      "Epoch 116/150\n",
      "1458/1458 [==============================] - 0s 318us/step - loss: 0.6877 - acc: 0.5521 - val_loss: 0.6793 - val_acc: 0.5926\n",
      "Epoch 117/150\n",
      "1458/1458 [==============================] - 1s 350us/step - loss: 0.6877 - acc: 0.5521 - val_loss: 0.6793 - val_acc: 0.5926\n",
      "Epoch 118/150\n",
      "1458/1458 [==============================] - 0s 310us/step - loss: 0.6877 - acc: 0.5521 - val_loss: 0.6792 - val_acc: 0.5926\n",
      "Epoch 119/150\n",
      "1458/1458 [==============================] - 0s 296us/step - loss: 0.6877 - acc: 0.5521 - val_loss: 0.6792 - val_acc: 0.5926\n",
      "Epoch 120/150\n",
      "1458/1458 [==============================] - 0s 287us/step - loss: 0.6877 - acc: 0.5521 - val_loss: 0.6793 - val_acc: 0.5926\n",
      "Epoch 121/150\n",
      "1458/1458 [==============================] - 0s 304us/step - loss: 0.6877 - acc: 0.5521 - val_loss: 0.6793 - val_acc: 0.5926\n",
      "Epoch 122/150\n",
      "1458/1458 [==============================] - 0s 304us/step - loss: 0.6877 - acc: 0.5521 - val_loss: 0.6793 - val_acc: 0.5926\n",
      "Epoch 123/150\n",
      "1458/1458 [==============================] - 0s 278us/step - loss: 0.6877 - acc: 0.5521 - val_loss: 0.6793 - val_acc: 0.5926\n",
      "Epoch 124/150\n",
      "1458/1458 [==============================] - 0s 257us/step - loss: 0.6877 - acc: 0.5521 - val_loss: 0.6793 - val_acc: 0.5926\n",
      "Epoch 125/150\n",
      "1458/1458 [==============================] - 0s 232us/step - loss: 0.6877 - acc: 0.5521 - val_loss: 0.6791 - val_acc: 0.5926\n",
      "Epoch 126/150\n",
      "1458/1458 [==============================] - 0s 284us/step - loss: 0.6877 - acc: 0.5521 - val_loss: 0.6792 - val_acc: 0.5926\n",
      "Epoch 127/150\n",
      "1458/1458 [==============================] - 0s 277us/step - loss: 0.6877 - acc: 0.5521 - val_loss: 0.6793 - val_acc: 0.5926\n",
      "Epoch 128/150\n",
      "1458/1458 [==============================] - 0s 252us/step - loss: 0.6877 - acc: 0.5521 - val_loss: 0.6793 - val_acc: 0.5926\n",
      "Epoch 129/150\n",
      "1458/1458 [==============================] - 0s 271us/step - loss: 0.6877 - acc: 0.5521 - val_loss: 0.6793 - val_acc: 0.5926\n",
      "Epoch 130/150\n",
      "1458/1458 [==============================] - 0s 290us/step - loss: 0.6877 - acc: 0.5521 - val_loss: 0.6792 - val_acc: 0.5926\n",
      "Epoch 131/150\n",
      "1458/1458 [==============================] - 0s 277us/step - loss: 0.6877 - acc: 0.5521 - val_loss: 0.6793 - val_acc: 0.5926\n",
      "Epoch 132/150\n",
      "1458/1458 [==============================] - 0s 256us/step - loss: 0.6877 - acc: 0.5521 - val_loss: 0.6793 - val_acc: 0.5926\n",
      "Epoch 133/150\n",
      "1458/1458 [==============================] - 0s 306us/step - loss: 0.6877 - acc: 0.5521 - val_loss: 0.6793 - val_acc: 0.5926\n",
      "Epoch 134/150\n",
      "1458/1458 [==============================] - 0s 297us/step - loss: 0.6877 - acc: 0.5521 - val_loss: 0.6792 - val_acc: 0.5926\n",
      "Epoch 135/150\n",
      "1458/1458 [==============================] - 0s 264us/step - loss: 0.6877 - acc: 0.5521 - val_loss: 0.6794 - val_acc: 0.5926\n",
      "Epoch 136/150\n",
      "1458/1458 [==============================] - 0s 292us/step - loss: 0.6877 - acc: 0.5521 - val_loss: 0.6794 - val_acc: 0.5926\n",
      "Epoch 137/150\n",
      "1458/1458 [==============================] - 0s 252us/step - loss: 0.6877 - acc: 0.5521 - val_loss: 0.6792 - val_acc: 0.5926\n",
      "Epoch 138/150\n",
      "1458/1458 [==============================] - 0s 278us/step - loss: 0.6877 - acc: 0.5521 - val_loss: 0.6791 - val_acc: 0.5926\n",
      "Epoch 139/150\n",
      "1458/1458 [==============================] - 0s 302us/step - loss: 0.6877 - acc: 0.5521 - val_loss: 0.6790 - val_acc: 0.5926\n",
      "Epoch 140/150\n",
      "1458/1458 [==============================] - 0s 314us/step - loss: 0.6877 - acc: 0.5521 - val_loss: 0.6790 - val_acc: 0.5926\n",
      "Epoch 141/150\n",
      "1458/1458 [==============================] - 0s 284us/step - loss: 0.6877 - acc: 0.5521 - val_loss: 0.6791 - val_acc: 0.5926\n",
      "Epoch 142/150\n",
      "1458/1458 [==============================] - 0s 295us/step - loss: 0.6877 - acc: 0.5521 - val_loss: 0.6793 - val_acc: 0.5926\n",
      "Epoch 143/150\n",
      "1458/1458 [==============================] - 0s 295us/step - loss: 0.6877 - acc: 0.5521 - val_loss: 0.6792 - val_acc: 0.5926\n",
      "Epoch 144/150\n",
      "1458/1458 [==============================] - 0s 274us/step - loss: 0.6877 - acc: 0.5521 - val_loss: 0.6793 - val_acc: 0.5926\n",
      "Epoch 145/150\n",
      "1458/1458 [==============================] - 0s 274us/step - loss: 0.6877 - acc: 0.5521 - val_loss: 0.6792 - val_acc: 0.5926\n",
      "Epoch 146/150\n",
      "1458/1458 [==============================] - 0s 309us/step - loss: 0.6877 - acc: 0.5521 - val_loss: 0.6791 - val_acc: 0.5926\n",
      "Epoch 147/150\n",
      "1458/1458 [==============================] - 0s 285us/step - loss: 0.6877 - acc: 0.5521 - val_loss: 0.6792 - val_acc: 0.5926\n",
      "Epoch 148/150\n",
      "1458/1458 [==============================] - 0s 269us/step - loss: 0.6877 - acc: 0.5521 - val_loss: 0.6792 - val_acc: 0.5926\n",
      "Epoch 149/150\n",
      "1458/1458 [==============================] - 0s 264us/step - loss: 0.6877 - acc: 0.5521 - val_loss: 0.6792 - val_acc: 0.5926\n",
      "Epoch 150/150\n",
      "1458/1458 [==============================] - 0s 240us/step - loss: 0.6877 - acc: 0.5521 - val_loss: 0.6792 - val_acc: 0.5926\n",
      "The score is......\n",
      " [0.6791506041715174, 0.5925925925925926]\n",
      "Compute bottleneck features...\n",
      "train_bNFeatures[img].shape =  (1458, 73728)\n",
      "val_bNFeatures[img].shape =  (162, 73728)\n",
      "Train head...\n",
      "Train on 1458 samples, validate on 162 samples\n",
      "Epoch 1/150\n",
      "1458/1458 [==============================] - 1s 446us/step - loss: 0.9319 - acc: 0.5329 - val_loss: 0.6928 - val_acc: 0.5926\n",
      "Epoch 2/150\n",
      "1458/1458 [==============================] - 0s 338us/step - loss: 0.6928 - acc: 0.5521 - val_loss: 0.6921 - val_acc: 0.5926\n",
      "Epoch 3/150\n",
      "1458/1458 [==============================] - 1s 469us/step - loss: 0.6924 - acc: 0.5521 - val_loss: 0.6913 - val_acc: 0.5926\n",
      "Epoch 4/150\n",
      "1458/1458 [==============================] - 1s 353us/step - loss: 0.6919 - acc: 0.5521 - val_loss: 0.6904 - val_acc: 0.5926\n",
      "Epoch 5/150\n",
      "1458/1458 [==============================] - 0s 306us/step - loss: 0.6915 - acc: 0.5521 - val_loss: 0.6894 - val_acc: 0.5926\n",
      "Epoch 6/150\n",
      "1458/1458 [==============================] - 0s 294us/step - loss: 0.6910 - acc: 0.5521 - val_loss: 0.6887 - val_acc: 0.5926\n",
      "Epoch 7/150\n",
      "1458/1458 [==============================] - 0s 295us/step - loss: 0.6906 - acc: 0.5521 - val_loss: 0.6878 - val_acc: 0.5926\n",
      "Epoch 8/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1458/1458 [==============================] - 0s 301us/step - loss: 0.6902 - acc: 0.5521 - val_loss: 0.6871 - val_acc: 0.5926\n",
      "Epoch 9/150\n",
      "1458/1458 [==============================] - 0s 278us/step - loss: 0.6899 - acc: 0.5521 - val_loss: 0.6863 - val_acc: 0.5926\n",
      "Epoch 10/150\n",
      "1458/1458 [==============================] - 0s 272us/step - loss: 0.6896 - acc: 0.5521 - val_loss: 0.6855 - val_acc: 0.5926\n",
      "Epoch 11/150\n",
      "1458/1458 [==============================] - 0s 293us/step - loss: 0.6892 - acc: 0.5521 - val_loss: 0.6850 - val_acc: 0.5926\n",
      "Epoch 12/150\n",
      "1458/1458 [==============================] - 0s 299us/step - loss: 0.6890 - acc: 0.5521 - val_loss: 0.6845 - val_acc: 0.5926\n",
      "Epoch 13/150\n",
      "1458/1458 [==============================] - 0s 310us/step - loss: 0.6888 - acc: 0.5521 - val_loss: 0.6838 - val_acc: 0.5926\n",
      "Epoch 14/150\n",
      "1458/1458 [==============================] - 0s 291us/step - loss: 0.6886 - acc: 0.5521 - val_loss: 0.6832 - val_acc: 0.5926\n",
      "Epoch 15/150\n",
      "1458/1458 [==============================] - 0s 298us/step - loss: 0.6885 - acc: 0.5521 - val_loss: 0.6828 - val_acc: 0.5926\n",
      "Epoch 16/150\n",
      "1458/1458 [==============================] - 1s 426us/step - loss: 0.6883 - acc: 0.5521 - val_loss: 0.6825 - val_acc: 0.5926\n",
      "Epoch 17/150\n",
      "1458/1458 [==============================] - 1s 388us/step - loss: 0.6882 - acc: 0.5521 - val_loss: 0.6822 - val_acc: 0.5926\n",
      "Epoch 18/150\n",
      "1458/1458 [==============================] - 0s 322us/step - loss: 0.6881 - acc: 0.5521 - val_loss: 0.6818 - val_acc: 0.5926\n",
      "Epoch 19/150\n",
      "1458/1458 [==============================] - 0s 336us/step - loss: 0.6880 - acc: 0.5521 - val_loss: 0.6816 - val_acc: 0.5926\n",
      "Epoch 20/150\n",
      "1458/1458 [==============================] - 0s 324us/step - loss: 0.6880 - acc: 0.5521 - val_loss: 0.6812 - val_acc: 0.5926\n",
      "Epoch 21/150\n",
      "1458/1458 [==============================] - 0s 308us/step - loss: 0.6879 - acc: 0.5521 - val_loss: 0.6810 - val_acc: 0.5926\n",
      "Epoch 22/150\n",
      "1458/1458 [==============================] - 0s 246us/step - loss: 0.6879 - acc: 0.5521 - val_loss: 0.6808 - val_acc: 0.5926\n",
      "Epoch 23/150\n",
      "1458/1458 [==============================] - 0s 291us/step - loss: 0.6879 - acc: 0.5521 - val_loss: 0.6805 - val_acc: 0.5926\n",
      "Epoch 24/150\n",
      "1458/1458 [==============================] - 0s 256us/step - loss: 0.6878 - acc: 0.5521 - val_loss: 0.6804 - val_acc: 0.5926\n",
      "Epoch 25/150\n",
      "1458/1458 [==============================] - 0s 281us/step - loss: 0.6878 - acc: 0.5521 - val_loss: 0.6803 - val_acc: 0.5926\n",
      "Epoch 26/150\n",
      "1458/1458 [==============================] - 0s 272us/step - loss: 0.6878 - acc: 0.5521 - val_loss: 0.6802 - val_acc: 0.5926\n",
      "Epoch 27/150\n",
      "1458/1458 [==============================] - 0s 301us/step - loss: 0.6878 - acc: 0.5521 - val_loss: 0.6801 - val_acc: 0.5926\n",
      "Epoch 28/150\n",
      "1458/1458 [==============================] - 1s 349us/step - loss: 0.6878 - acc: 0.5521 - val_loss: 0.6800 - val_acc: 0.5926\n",
      "Epoch 29/150\n",
      "1458/1458 [==============================] - 0s 290us/step - loss: 0.6878 - acc: 0.5521 - val_loss: 0.6799 - val_acc: 0.5926\n",
      "Epoch 30/150\n",
      "1458/1458 [==============================] - 0s 266us/step - loss: 0.6877 - acc: 0.5521 - val_loss: 0.6799 - val_acc: 0.5926\n",
      "Epoch 31/150\n",
      "1458/1458 [==============================] - 0s 303us/step - loss: 0.6877 - acc: 0.5521 - val_loss: 0.6798 - val_acc: 0.5926\n",
      "Epoch 32/150\n",
      "1458/1458 [==============================] - 0s 319us/step - loss: 0.6877 - acc: 0.5521 - val_loss: 0.6797 - val_acc: 0.5926\n",
      "Epoch 33/150\n",
      "1458/1458 [==============================] - 0s 332us/step - loss: 0.6877 - acc: 0.5521 - val_loss: 0.6797 - val_acc: 0.5926\n",
      "Epoch 34/150\n",
      "1458/1458 [==============================] - 0s 305us/step - loss: 0.6877 - acc: 0.5521 - val_loss: 0.6797 - val_acc: 0.5926\n",
      "Epoch 35/150\n",
      "1458/1458 [==============================] - 0s 243us/step - loss: 0.6877 - acc: 0.5521 - val_loss: 0.6797 - val_acc: 0.5926\n",
      "Epoch 36/150\n",
      "1458/1458 [==============================] - 0s 259us/step - loss: 0.6877 - acc: 0.5521 - val_loss: 0.6795 - val_acc: 0.5926\n",
      "Epoch 37/150\n",
      "1458/1458 [==============================] - 0s 323us/step - loss: 0.6877 - acc: 0.5521 - val_loss: 0.6796 - val_acc: 0.5926\n",
      "Epoch 38/150\n",
      "1458/1458 [==============================] - 0s 320us/step - loss: 0.6877 - acc: 0.5521 - val_loss: 0.6796 - val_acc: 0.5926\n",
      "Epoch 39/150\n",
      "1458/1458 [==============================] - 1s 429us/step - loss: 0.6877 - acc: 0.5521 - val_loss: 0.6796 - val_acc: 0.5926\n",
      "Epoch 40/150\n",
      "1458/1458 [==============================] - 0s 313us/step - loss: 0.6877 - acc: 0.5521 - val_loss: 0.6795 - val_acc: 0.5926\n",
      "Epoch 41/150\n",
      "1458/1458 [==============================] - 0s 308us/step - loss: 0.6877 - acc: 0.5521 - val_loss: 0.6795 - val_acc: 0.5926\n",
      "Epoch 42/150\n",
      "1458/1458 [==============================] - 0s 258us/step - loss: 0.6877 - acc: 0.5521 - val_loss: 0.6793 - val_acc: 0.5926\n",
      "Epoch 43/150\n",
      "1458/1458 [==============================] - 0s 283us/step - loss: 0.6877 - acc: 0.5521 - val_loss: 0.6793 - val_acc: 0.5926\n",
      "Epoch 44/150\n",
      "1458/1458 [==============================] - 0s 281us/step - loss: 0.6877 - acc: 0.5521 - val_loss: 0.6792 - val_acc: 0.5926\n",
      "Epoch 45/150\n",
      "1458/1458 [==============================] - 0s 270us/step - loss: 0.6877 - acc: 0.5521 - val_loss: 0.6793 - val_acc: 0.5926\n",
      "Epoch 46/150\n",
      "1458/1458 [==============================] - 0s 239us/step - loss: 0.6877 - acc: 0.5521 - val_loss: 0.6792 - val_acc: 0.5926\n",
      "Epoch 47/150\n",
      "1458/1458 [==============================] - 0s 286us/step - loss: 0.6877 - acc: 0.5521 - val_loss: 0.6793 - val_acc: 0.5926\n",
      "Epoch 48/150\n",
      "1458/1458 [==============================] - 0s 316us/step - loss: 0.6877 - acc: 0.5521 - val_loss: 0.6793 - val_acc: 0.5926\n",
      "Epoch 49/150\n",
      "1458/1458 [==============================] - 0s 278us/step - loss: 0.6877 - acc: 0.5521 - val_loss: 0.6793 - val_acc: 0.5926\n",
      "Epoch 50/150\n",
      "1458/1458 [==============================] - 0s 250us/step - loss: 0.6877 - acc: 0.5521 - val_loss: 0.6793 - val_acc: 0.5926\n",
      "Epoch 51/150\n",
      "1458/1458 [==============================] - 0s 240us/step - loss: 0.6877 - acc: 0.5521 - val_loss: 0.6793 - val_acc: 0.5926\n",
      "Epoch 52/150\n",
      "1458/1458 [==============================] - 0s 262us/step - loss: 0.6877 - acc: 0.5521 - val_loss: 0.6793 - val_acc: 0.5926\n",
      "Epoch 53/150\n",
      "1458/1458 [==============================] - 0s 255us/step - loss: 0.6877 - acc: 0.5521 - val_loss: 0.6792 - val_acc: 0.5926\n",
      "Epoch 54/150\n",
      "1458/1458 [==============================] - 0s 294us/step - loss: 0.6877 - acc: 0.5521 - val_loss: 0.6792 - val_acc: 0.5926\n",
      "Epoch 55/150\n",
      "1458/1458 [==============================] - 0s 249us/step - loss: 0.6877 - acc: 0.5521 - val_loss: 0.6793 - val_acc: 0.5926\n",
      "Epoch 56/150\n",
      "1458/1458 [==============================] - 0s 232us/step - loss: 0.6877 - acc: 0.5521 - val_loss: 0.6792 - val_acc: 0.5926\n",
      "Epoch 57/150\n",
      "1458/1458 [==============================] - 0s 269us/step - loss: 0.6877 - acc: 0.5521 - val_loss: 0.6792 - val_acc: 0.5926\n",
      "Epoch 58/150\n",
      "1458/1458 [==============================] - 0s 258us/step - loss: 0.6877 - acc: 0.5521 - val_loss: 0.6791 - val_acc: 0.5926\n",
      "Epoch 59/150\n",
      "1458/1458 [==============================] - 0s 298us/step - loss: 0.6877 - acc: 0.5521 - val_loss: 0.6792 - val_acc: 0.5926\n",
      "Epoch 60/150\n",
      "1458/1458 [==============================] - 1s 350us/step - loss: 0.6877 - acc: 0.5521 - val_loss: 0.6792 - val_acc: 0.5926\n",
      "Epoch 61/150\n",
      "1458/1458 [==============================] - 0s 250us/step - loss: 0.6877 - acc: 0.5521 - val_loss: 0.6793 - val_acc: 0.5926\n",
      "Epoch 62/150\n",
      "1458/1458 [==============================] - 0s 270us/step - loss: 0.6877 - acc: 0.5521 - val_loss: 0.6793 - val_acc: 0.5926\n",
      "Epoch 63/150\n",
      "1458/1458 [==============================] - 0s 261us/step - loss: 0.6877 - acc: 0.5521 - val_loss: 0.6793 - val_acc: 0.5926\n",
      "Epoch 64/150\n",
      "1458/1458 [==============================] - 0s 291us/step - loss: 0.6877 - acc: 0.5521 - val_loss: 0.6794 - val_acc: 0.5926\n",
      "Epoch 65/150\n",
      "1458/1458 [==============================] - 0s 237us/step - loss: 0.6877 - acc: 0.5521 - val_loss: 0.6792 - val_acc: 0.5926\n",
      "Epoch 66/150\n",
      "1458/1458 [==============================] - 0s 297us/step - loss: 0.6877 - acc: 0.5521 - val_loss: 0.6791 - val_acc: 0.5926\n",
      "Epoch 67/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1458/1458 [==============================] - 0s 241us/step - loss: 0.6877 - acc: 0.5521 - val_loss: 0.6793 - val_acc: 0.5926\n",
      "Epoch 68/150\n",
      "1458/1458 [==============================] - 0s 235us/step - loss: 0.6877 - acc: 0.5521 - val_loss: 0.6793 - val_acc: 0.5926\n",
      "Epoch 69/150\n",
      "1458/1458 [==============================] - 0s 272us/step - loss: 0.6877 - acc: 0.5521 - val_loss: 0.6794 - val_acc: 0.5926\n",
      "Epoch 70/150\n",
      "1458/1458 [==============================] - 0s 256us/step - loss: 0.6877 - acc: 0.5521 - val_loss: 0.6792 - val_acc: 0.5926\n",
      "Epoch 71/150\n",
      "1458/1458 [==============================] - 0s 273us/step - loss: 0.6877 - acc: 0.5521 - val_loss: 0.6793 - val_acc: 0.5926\n",
      "Epoch 72/150\n",
      "1458/1458 [==============================] - 0s 277us/step - loss: 0.6877 - acc: 0.5521 - val_loss: 0.6792 - val_acc: 0.5926\n",
      "Epoch 73/150\n",
      "1458/1458 [==============================] - 0s 272us/step - loss: 0.6877 - acc: 0.5521 - val_loss: 0.6793 - val_acc: 0.5926\n",
      "Epoch 74/150\n",
      "1458/1458 [==============================] - 0s 285us/step - loss: 0.6877 - acc: 0.5521 - val_loss: 0.6793 - val_acc: 0.5926\n",
      "Epoch 75/150\n",
      "1458/1458 [==============================] - 0s 254us/step - loss: 0.6877 - acc: 0.5521 - val_loss: 0.6793 - val_acc: 0.5926\n",
      "Epoch 76/150\n",
      "1458/1458 [==============================] - 0s 300us/step - loss: 0.6877 - acc: 0.5521 - val_loss: 0.6794 - val_acc: 0.5926\n",
      "Epoch 77/150\n",
      "1458/1458 [==============================] - 0s 243us/step - loss: 0.6877 - acc: 0.5521 - val_loss: 0.6795 - val_acc: 0.5926\n",
      "Epoch 78/150\n",
      "1458/1458 [==============================] - 0s 228us/step - loss: 0.6877 - acc: 0.5521 - val_loss: 0.6794 - val_acc: 0.5926\n",
      "Epoch 79/150\n",
      "1458/1458 [==============================] - 0s 257us/step - loss: 0.6877 - acc: 0.5521 - val_loss: 0.6793 - val_acc: 0.5926\n",
      "Epoch 80/150\n",
      "1458/1458 [==============================] - 0s 262us/step - loss: 0.6877 - acc: 0.5521 - val_loss: 0.6793 - val_acc: 0.5926\n",
      "Epoch 81/150\n",
      "1458/1458 [==============================] - 0s 290us/step - loss: 0.6877 - acc: 0.5521 - val_loss: 0.6793 - val_acc: 0.5926\n",
      "Epoch 82/150\n",
      "1458/1458 [==============================] - 0s 278us/step - loss: 0.6877 - acc: 0.5521 - val_loss: 0.6794 - val_acc: 0.5926\n",
      "Epoch 83/150\n",
      "1458/1458 [==============================] - 0s 242us/step - loss: 0.6877 - acc: 0.5521 - val_loss: 0.6794 - val_acc: 0.5926\n",
      "Epoch 84/150\n",
      "1458/1458 [==============================] - 0s 310us/step - loss: 0.6877 - acc: 0.5521 - val_loss: 0.6793 - val_acc: 0.5926\n",
      "Epoch 85/150\n",
      "1458/1458 [==============================] - 0s 296us/step - loss: 0.6877 - acc: 0.5521 - val_loss: 0.6792 - val_acc: 0.5926\n",
      "Epoch 86/150\n",
      "1458/1458 [==============================] - 0s 332us/step - loss: 0.6878 - acc: 0.5521 - val_loss: 0.6794 - val_acc: 0.5926\n",
      "Epoch 87/150\n",
      "1458/1458 [==============================] - 0s 298us/step - loss: 0.6877 - acc: 0.5521 - val_loss: 0.6792 - val_acc: 0.5926\n",
      "Epoch 88/150\n",
      "1458/1458 [==============================] - 0s 237us/step - loss: 0.6877 - acc: 0.5521 - val_loss: 0.6792 - val_acc: 0.5926\n",
      "Epoch 89/150\n",
      "1458/1458 [==============================] - 0s 238us/step - loss: 0.6877 - acc: 0.5521 - val_loss: 0.6792 - val_acc: 0.5926\n",
      "Epoch 90/150\n",
      "1458/1458 [==============================] - 0s 273us/step - loss: 0.6877 - acc: 0.5521 - val_loss: 0.6792 - val_acc: 0.5926\n",
      "Epoch 91/150\n",
      "1458/1458 [==============================] - 0s 265us/step - loss: 0.6877 - acc: 0.5521 - val_loss: 0.6792 - val_acc: 0.5926\n",
      "Epoch 92/150\n",
      "1458/1458 [==============================] - 0s 281us/step - loss: 0.6877 - acc: 0.5521 - val_loss: 0.6792 - val_acc: 0.5926\n",
      "Epoch 93/150\n",
      "1458/1458 [==============================] - 0s 272us/step - loss: 0.6877 - acc: 0.5521 - val_loss: 0.6792 - val_acc: 0.5926\n",
      "Epoch 94/150\n",
      "1458/1458 [==============================] - 0s 297us/step - loss: 0.6877 - acc: 0.5521 - val_loss: 0.6791 - val_acc: 0.5926\n",
      "Epoch 95/150\n",
      "1458/1458 [==============================] - 0s 297us/step - loss: 0.6877 - acc: 0.5521 - val_loss: 0.6792 - val_acc: 0.5926\n",
      "Epoch 96/150\n",
      "1458/1458 [==============================] - 0s 262us/step - loss: 0.6877 - acc: 0.5521 - val_loss: 0.6793 - val_acc: 0.5926\n",
      "Epoch 97/150\n",
      "1458/1458 [==============================] - 0s 253us/step - loss: 0.6877 - acc: 0.5521 - val_loss: 0.6793 - val_acc: 0.5926\n",
      "Epoch 98/150\n",
      "1458/1458 [==============================] - 0s 296us/step - loss: 0.6877 - acc: 0.5521 - val_loss: 0.6792 - val_acc: 0.5926\n",
      "Epoch 99/150\n",
      "1458/1458 [==============================] - 0s 288us/step - loss: 0.6877 - acc: 0.5521 - val_loss: 0.6792 - val_acc: 0.5926\n",
      "Epoch 100/150\n",
      "1458/1458 [==============================] - 0s 250us/step - loss: 0.6877 - acc: 0.5521 - val_loss: 0.6793 - val_acc: 0.5926\n",
      "Epoch 101/150\n",
      "1458/1458 [==============================] - 0s 237us/step - loss: 0.6878 - acc: 0.5521 - val_loss: 0.6790 - val_acc: 0.5926\n",
      "Epoch 102/150\n",
      "1458/1458 [==============================] - 0s 257us/step - loss: 0.6877 - acc: 0.5521 - val_loss: 0.6791 - val_acc: 0.5926\n",
      "Epoch 103/150\n",
      "1458/1458 [==============================] - 0s 262us/step - loss: 0.6877 - acc: 0.5521 - val_loss: 0.6792 - val_acc: 0.5926\n",
      "Epoch 104/150\n",
      "1458/1458 [==============================] - 0s 257us/step - loss: 0.6877 - acc: 0.5521 - val_loss: 0.6792 - val_acc: 0.5926\n",
      "Epoch 105/150\n",
      "1458/1458 [==============================] - 0s 236us/step - loss: 0.6877 - acc: 0.5521 - val_loss: 0.6793 - val_acc: 0.5926\n",
      "Epoch 106/150\n",
      "1458/1458 [==============================] - 0s 259us/step - loss: 0.6877 - acc: 0.5521 - val_loss: 0.6792 - val_acc: 0.5926\n",
      "Epoch 107/150\n",
      "1458/1458 [==============================] - 0s 234us/step - loss: 0.6877 - acc: 0.5521 - val_loss: 0.6793 - val_acc: 0.5926\n",
      "Epoch 108/150\n",
      "1458/1458 [==============================] - 0s 231us/step - loss: 0.6877 - acc: 0.5521 - val_loss: 0.6793 - val_acc: 0.5926\n",
      "Epoch 109/150\n",
      "1458/1458 [==============================] - 0s 283us/step - loss: 0.6877 - acc: 0.5521 - val_loss: 0.6792 - val_acc: 0.5926\n",
      "Epoch 110/150\n",
      "1458/1458 [==============================] - 0s 283us/step - loss: 0.6877 - acc: 0.5521 - val_loss: 0.6792 - val_acc: 0.5926\n",
      "Epoch 111/150\n",
      "1458/1458 [==============================] - 0s 279us/step - loss: 0.6877 - acc: 0.5521 - val_loss: 0.6791 - val_acc: 0.5926\n",
      "Epoch 112/150\n",
      "1458/1458 [==============================] - 0s 230us/step - loss: 0.6877 - acc: 0.5521 - val_loss: 0.6792 - val_acc: 0.5926\n",
      "Epoch 113/150\n",
      "1458/1458 [==============================] - 0s 235us/step - loss: 0.6877 - acc: 0.5521 - val_loss: 0.6791 - val_acc: 0.5926\n",
      "Epoch 114/150\n",
      "1458/1458 [==============================] - 0s 237us/step - loss: 0.6877 - acc: 0.5521 - val_loss: 0.6791 - val_acc: 0.5926\n",
      "Epoch 115/150\n",
      "1458/1458 [==============================] - 0s 282us/step - loss: 0.6877 - acc: 0.5521 - val_loss: 0.6792 - val_acc: 0.5926\n",
      "Epoch 116/150\n",
      "1458/1458 [==============================] - 0s 251us/step - loss: 0.6877 - acc: 0.5521 - val_loss: 0.6792 - val_acc: 0.5926\n",
      "Epoch 117/150\n",
      "1458/1458 [==============================] - 0s 245us/step - loss: 0.6877 - acc: 0.5521 - val_loss: 0.6793 - val_acc: 0.5926\n",
      "Epoch 118/150\n",
      "1458/1458 [==============================] - 0s 287us/step - loss: 0.6877 - acc: 0.5521 - val_loss: 0.6793 - val_acc: 0.5926\n",
      "Epoch 119/150\n",
      "1458/1458 [==============================] - 0s 260us/step - loss: 0.6878 - acc: 0.5521 - val_loss: 0.6794 - val_acc: 0.5926\n",
      "Epoch 120/150\n",
      "1458/1458 [==============================] - 0s 261us/step - loss: 0.6877 - acc: 0.5521 - val_loss: 0.6793 - val_acc: 0.5926\n",
      "Epoch 121/150\n",
      "1458/1458 [==============================] - 0s 274us/step - loss: 0.6877 - acc: 0.5521 - val_loss: 0.6792 - val_acc: 0.5926\n",
      "Epoch 122/150\n",
      "1458/1458 [==============================] - 0s 251us/step - loss: 0.6877 - acc: 0.5521 - val_loss: 0.6792 - val_acc: 0.5926\n",
      "Epoch 123/150\n",
      "1458/1458 [==============================] - 0s 254us/step - loss: 0.6877 - acc: 0.5521 - val_loss: 0.6793 - val_acc: 0.5926\n",
      "Epoch 124/150\n",
      "1458/1458 [==============================] - 0s 281us/step - loss: 0.6877 - acc: 0.5521 - val_loss: 0.6794 - val_acc: 0.5926\n",
      "Epoch 125/150\n",
      "1458/1458 [==============================] - 0s 288us/step - loss: 0.6877 - acc: 0.5521 - val_loss: 0.6793 - val_acc: 0.5926\n",
      "Epoch 126/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1458/1458 [==============================] - 0s 264us/step - loss: 0.6877 - acc: 0.5521 - val_loss: 0.6794 - val_acc: 0.5926\n",
      "Epoch 127/150\n",
      "1458/1458 [==============================] - 0s 327us/step - loss: 0.6877 - acc: 0.5521 - val_loss: 0.6794 - val_acc: 0.5926\n",
      "Epoch 128/150\n",
      "1458/1458 [==============================] - 0s 332us/step - loss: 0.6877 - acc: 0.5521 - val_loss: 0.6793 - val_acc: 0.5926\n",
      "Epoch 129/150\n",
      "1458/1458 [==============================] - 0s 275us/step - loss: 0.6877 - acc: 0.5521 - val_loss: 0.6792 - val_acc: 0.5926\n",
      "Epoch 130/150\n",
      "1458/1458 [==============================] - 0s 292us/step - loss: 0.6877 - acc: 0.5521 - val_loss: 0.6792 - val_acc: 0.5926\n",
      "Epoch 131/150\n",
      "1458/1458 [==============================] - 0s 317us/step - loss: 0.6877 - acc: 0.5521 - val_loss: 0.6792 - val_acc: 0.5926\n",
      "Epoch 132/150\n",
      "1458/1458 [==============================] - 0s 302us/step - loss: 0.6877 - acc: 0.5521 - val_loss: 0.6793 - val_acc: 0.5926\n",
      "Epoch 133/150\n",
      "1458/1458 [==============================] - 0s 279us/step - loss: 0.6877 - acc: 0.5521 - val_loss: 0.6793 - val_acc: 0.5926\n",
      "Epoch 134/150\n",
      "1458/1458 [==============================] - 0s 292us/step - loss: 0.6877 - acc: 0.5521 - val_loss: 0.6792 - val_acc: 0.5926\n",
      "Epoch 135/150\n",
      "1458/1458 [==============================] - 0s 245us/step - loss: 0.6877 - acc: 0.5521 - val_loss: 0.6793 - val_acc: 0.5926\n",
      "Epoch 136/150\n",
      "1458/1458 [==============================] - 0s 257us/step - loss: 0.6877 - acc: 0.5521 - val_loss: 0.6793 - val_acc: 0.5926\n",
      "Epoch 137/150\n",
      "1458/1458 [==============================] - 0s 288us/step - loss: 0.6877 - acc: 0.5521 - val_loss: 0.6794 - val_acc: 0.5926\n",
      "Epoch 138/150\n",
      "1458/1458 [==============================] - 0s 252us/step - loss: 0.6878 - acc: 0.5521 - val_loss: 0.6795 - val_acc: 0.5926\n",
      "Epoch 139/150\n",
      "1458/1458 [==============================] - 0s 253us/step - loss: 0.6877 - acc: 0.5521 - val_loss: 0.6794 - val_acc: 0.5926\n",
      "Epoch 140/150\n",
      "1458/1458 [==============================] - 0s 259us/step - loss: 0.6877 - acc: 0.5521 - val_loss: 0.6793 - val_acc: 0.5926\n",
      "Epoch 141/150\n",
      "1458/1458 [==============================] - 0s 237us/step - loss: 0.6877 - acc: 0.5521 - val_loss: 0.6792 - val_acc: 0.5926\n",
      "Epoch 142/150\n",
      "1458/1458 [==============================] - 0s 241us/step - loss: 0.6877 - acc: 0.5521 - val_loss: 0.6792 - val_acc: 0.5926\n",
      "Epoch 143/150\n",
      "1458/1458 [==============================] - 0s 236us/step - loss: 0.6877 - acc: 0.5521 - val_loss: 0.6792 - val_acc: 0.5926\n",
      "Epoch 144/150\n",
      "1458/1458 [==============================] - 0s 285us/step - loss: 0.6877 - acc: 0.5521 - val_loss: 0.6792 - val_acc: 0.5926\n",
      "Epoch 145/150\n",
      "1458/1458 [==============================] - 0s 244us/step - loss: 0.6878 - acc: 0.5521 - val_loss: 0.6794 - val_acc: 0.5926\n",
      "Epoch 146/150\n",
      "1458/1458 [==============================] - 0s 308us/step - loss: 0.6877 - acc: 0.5521 - val_loss: 0.6791 - val_acc: 0.5926\n",
      "Epoch 147/150\n",
      "1458/1458 [==============================] - 0s 260us/step - loss: 0.6877 - acc: 0.5521 - val_loss: 0.6793 - val_acc: 0.5926\n",
      "Epoch 148/150\n",
      "1458/1458 [==============================] - 0s 277us/step - loss: 0.6877 - acc: 0.5521 - val_loss: 0.6792 - val_acc: 0.5926\n",
      "Epoch 149/150\n",
      "1458/1458 [==============================] - 0s 259us/step - loss: 0.6877 - acc: 0.5521 - val_loss: 0.6792 - val_acc: 0.5926\n",
      "Epoch 150/150\n",
      "1458/1458 [==============================] - 0s 296us/step - loss: 0.6877 - acc: 0.5521 - val_loss: 0.6791 - val_acc: 0.5926\n",
      "The score is......\n",
      " [0.6790800727443931, 0.5925925925925926]\n",
      "Compute bottleneck features...\n",
      "train_bNFeatures[img].shape =  (1458, 73728)\n",
      "val_bNFeatures[img].shape =  (162, 73728)\n",
      "Train head...\n",
      "Train on 1458 samples, validate on 162 samples\n",
      "Epoch 1/150\n",
      "1458/1458 [==============================] - 1s 561us/step - loss: 2.5488 - acc: 0.5466 - val_loss: 1.7299 - val_acc: 0.6049\n",
      "Epoch 2/150\n",
      "1458/1458 [==============================] - 0s 330us/step - loss: 0.9609 - acc: 0.6413 - val_loss: 0.5710 - val_acc: 0.7284\n",
      "Epoch 3/150\n",
      "1458/1458 [==============================] - 1s 487us/step - loss: 0.5798 - acc: 0.7016 - val_loss: 0.4752 - val_acc: 0.7840\n",
      "Epoch 4/150\n",
      "1458/1458 [==============================] - 1s 475us/step - loss: 0.4705 - acc: 0.7833 - val_loss: 0.3803 - val_acc: 0.8025\n",
      "Epoch 5/150\n",
      "1458/1458 [==============================] - 0s 306us/step - loss: 0.3899 - acc: 0.8162 - val_loss: 0.3499 - val_acc: 0.8457\n",
      "Epoch 6/150\n",
      "1458/1458 [==============================] - 0s 313us/step - loss: 0.3514 - acc: 0.8608 - val_loss: 0.3476 - val_acc: 0.8704\n",
      "Epoch 7/150\n",
      "1458/1458 [==============================] - 0s 305us/step - loss: 0.3321 - acc: 0.8601 - val_loss: 0.2947 - val_acc: 0.8951\n",
      "Epoch 8/150\n",
      "1458/1458 [==============================] - 0s 292us/step - loss: 0.2987 - acc: 0.8923 - val_loss: 0.2800 - val_acc: 0.9136\n",
      "Epoch 9/150\n",
      "1458/1458 [==============================] - 0s 296us/step - loss: 0.2673 - acc: 0.9053 - val_loss: 0.2675 - val_acc: 0.9198\n",
      "Epoch 10/150\n",
      "1458/1458 [==============================] - 0s 294us/step - loss: 0.2570 - acc: 0.9108 - val_loss: 0.2773 - val_acc: 0.9136\n",
      "Epoch 11/150\n",
      "1458/1458 [==============================] - 0s 299us/step - loss: 0.2300 - acc: 0.9328 - val_loss: 0.2293 - val_acc: 0.9321\n",
      "Epoch 12/150\n",
      "1458/1458 [==============================] - 0s 268us/step - loss: 0.2038 - acc: 0.9451 - val_loss: 0.2091 - val_acc: 0.9506\n",
      "Epoch 13/150\n",
      "1458/1458 [==============================] - 1s 398us/step - loss: 0.1932 - acc: 0.9554 - val_loss: 0.1984 - val_acc: 0.9568\n",
      "Epoch 14/150\n",
      "1458/1458 [==============================] - 0s 280us/step - loss: 0.1703 - acc: 0.9623 - val_loss: 0.2068 - val_acc: 0.9198\n",
      "Epoch 15/150\n",
      "1458/1458 [==============================] - 0s 240us/step - loss: 0.1657 - acc: 0.9609 - val_loss: 0.1812 - val_acc: 0.9568\n",
      "Epoch 16/150\n",
      "1458/1458 [==============================] - 0s 296us/step - loss: 0.1444 - acc: 0.9698 - val_loss: 0.1733 - val_acc: 0.9506\n",
      "Epoch 17/150\n",
      "1458/1458 [==============================] - 0s 280us/step - loss: 0.1339 - acc: 0.9801 - val_loss: 0.1789 - val_acc: 0.9568\n",
      "Epoch 18/150\n",
      "1458/1458 [==============================] - 1s 384us/step - loss: 0.1340 - acc: 0.9753 - val_loss: 0.1696 - val_acc: 0.9568\n",
      "Epoch 19/150\n",
      "1458/1458 [==============================] - 0s 295us/step - loss: 0.1223 - acc: 0.9794 - val_loss: 0.1846 - val_acc: 0.9444\n",
      "Epoch 20/150\n",
      "1458/1458 [==============================] - 0s 310us/step - loss: 0.1210 - acc: 0.9781 - val_loss: 0.1631 - val_acc: 0.9568\n",
      "Epoch 21/150\n",
      "1458/1458 [==============================] - 0s 294us/step - loss: 0.1000 - acc: 0.9870 - val_loss: 0.1442 - val_acc: 0.9506\n",
      "Epoch 22/150\n",
      "1458/1458 [==============================] - 0s 327us/step - loss: 0.0915 - acc: 0.9883 - val_loss: 0.1377 - val_acc: 0.9568\n",
      "Epoch 23/150\n",
      "1458/1458 [==============================] - 0s 246us/step - loss: 0.0853 - acc: 0.9877 - val_loss: 0.1337 - val_acc: 0.9568\n",
      "Epoch 24/150\n",
      "1458/1458 [==============================] - 0s 258us/step - loss: 0.0801 - acc: 0.9904 - val_loss: 0.1312 - val_acc: 0.9568\n",
      "Epoch 25/150\n",
      "1458/1458 [==============================] - 0s 299us/step - loss: 0.0786 - acc: 0.9931 - val_loss: 0.1256 - val_acc: 0.9568\n",
      "Epoch 26/150\n",
      "1458/1458 [==============================] - 0s 276us/step - loss: 0.0726 - acc: 0.9931 - val_loss: 0.1234 - val_acc: 0.9568\n",
      "Epoch 27/150\n",
      "1458/1458 [==============================] - 0s 258us/step - loss: 0.0655 - acc: 0.9925 - val_loss: 0.1175 - val_acc: 0.9568\n",
      "Epoch 28/150\n",
      "1458/1458 [==============================] - 0s 289us/step - loss: 0.0640 - acc: 0.9952 - val_loss: 0.1164 - val_acc: 0.9568\n",
      "Epoch 29/150\n",
      "1458/1458 [==============================] - 0s 268us/step - loss: 0.0653 - acc: 0.9938 - val_loss: 0.1100 - val_acc: 0.9568\n",
      "Epoch 30/150\n",
      "1458/1458 [==============================] - 0s 316us/step - loss: 0.0557 - acc: 0.9945 - val_loss: 0.1072 - val_acc: 0.9568\n",
      "Epoch 31/150\n",
      "1458/1458 [==============================] - 0s 336us/step - loss: 0.0510 - acc: 0.9959 - val_loss: 0.1032 - val_acc: 0.9568\n",
      "Epoch 32/150\n",
      "1458/1458 [==============================] - 0s 276us/step - loss: 0.0486 - acc: 0.9966 - val_loss: 0.1016 - val_acc: 0.9630\n",
      "Epoch 33/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1458/1458 [==============================] - 0s 280us/step - loss: 0.0453 - acc: 0.9966 - val_loss: 0.0968 - val_acc: 0.9568\n",
      "Epoch 34/150\n",
      "1458/1458 [==============================] - 0s 281us/step - loss: 0.0428 - acc: 0.9973 - val_loss: 0.0948 - val_acc: 0.9630\n",
      "Epoch 35/150\n",
      "1458/1458 [==============================] - 0s 239us/step - loss: 0.0407 - acc: 0.9959 - val_loss: 0.0919 - val_acc: 0.9630\n",
      "Epoch 36/150\n",
      "1458/1458 [==============================] - 0s 254us/step - loss: 0.0402 - acc: 0.9973 - val_loss: 0.0876 - val_acc: 0.9568\n",
      "Epoch 37/150\n",
      "1458/1458 [==============================] - 0s 291us/step - loss: 0.0375 - acc: 0.9973 - val_loss: 0.0846 - val_acc: 0.9630\n",
      "Epoch 38/150\n",
      "1458/1458 [==============================] - 0s 308us/step - loss: 0.0352 - acc: 0.9966 - val_loss: 0.0835 - val_acc: 0.9630\n",
      "Epoch 39/150\n",
      "1458/1458 [==============================] - 0s 240us/step - loss: 0.0342 - acc: 0.9986 - val_loss: 0.0971 - val_acc: 0.9753\n",
      "Epoch 40/150\n",
      "1458/1458 [==============================] - 0s 261us/step - loss: 0.0345 - acc: 0.9966 - val_loss: 0.0785 - val_acc: 0.9630\n",
      "Epoch 41/150\n",
      "1458/1458 [==============================] - 0s 276us/step - loss: 0.0288 - acc: 0.9986 - val_loss: 0.0783 - val_acc: 0.9630\n",
      "Epoch 42/150\n",
      "1458/1458 [==============================] - 0s 327us/step - loss: 0.0285 - acc: 0.9979 - val_loss: 0.0775 - val_acc: 0.9691\n",
      "Epoch 43/150\n",
      "1458/1458 [==============================] - 0s 311us/step - loss: 0.0260 - acc: 0.9986 - val_loss: 0.0775 - val_acc: 0.9753\n",
      "Epoch 44/150\n",
      "1458/1458 [==============================] - 0s 244us/step - loss: 0.0252 - acc: 1.0000 - val_loss: 0.0723 - val_acc: 0.9691\n",
      "Epoch 45/150\n",
      "1458/1458 [==============================] - 0s 326us/step - loss: 0.0262 - acc: 0.9986 - val_loss: 0.0755 - val_acc: 0.9691\n",
      "Epoch 46/150\n",
      "1458/1458 [==============================] - 1s 362us/step - loss: 0.0246 - acc: 0.9979 - val_loss: 0.0719 - val_acc: 0.9691\n",
      "Epoch 47/150\n",
      "1458/1458 [==============================] - 1s 444us/step - loss: 0.0216 - acc: 1.0000 - val_loss: 0.0678 - val_acc: 0.9753\n",
      "Epoch 48/150\n",
      "1458/1458 [==============================] - 0s 321us/step - loss: 0.0205 - acc: 0.9993 - val_loss: 0.0660 - val_acc: 0.9691\n",
      "Epoch 49/150\n",
      "1458/1458 [==============================] - 0s 244us/step - loss: 0.0199 - acc: 1.0000 - val_loss: 0.0664 - val_acc: 0.9753\n",
      "Epoch 50/150\n",
      "1458/1458 [==============================] - 0s 235us/step - loss: 0.0189 - acc: 0.9993 - val_loss: 0.0628 - val_acc: 0.9691\n",
      "Epoch 51/150\n",
      "1458/1458 [==============================] - 0s 271us/step - loss: 0.0176 - acc: 1.0000 - val_loss: 0.0615 - val_acc: 0.9753\n",
      "Epoch 52/150\n",
      "1458/1458 [==============================] - 0s 237us/step - loss: 0.0178 - acc: 1.0000 - val_loss: 0.0667 - val_acc: 0.9815\n",
      "Epoch 53/150\n",
      "1458/1458 [==============================] - 0s 235us/step - loss: 0.0177 - acc: 1.0000 - val_loss: 0.0604 - val_acc: 0.9753\n",
      "Epoch 54/150\n",
      "1458/1458 [==============================] - 0s 235us/step - loss: 0.0165 - acc: 1.0000 - val_loss: 0.0617 - val_acc: 0.9753\n",
      "Epoch 55/150\n",
      "1458/1458 [==============================] - 0s 276us/step - loss: 0.0152 - acc: 1.0000 - val_loss: 0.0594 - val_acc: 0.9753\n",
      "Epoch 56/150\n",
      "1458/1458 [==============================] - 0s 277us/step - loss: 0.0149 - acc: 1.0000 - val_loss: 0.0644 - val_acc: 0.9815\n",
      "Epoch 57/150\n",
      "1458/1458 [==============================] - 0s 242us/step - loss: 0.0144 - acc: 1.0000 - val_loss: 0.0580 - val_acc: 0.9753\n",
      "Epoch 58/150\n",
      "1458/1458 [==============================] - 0s 247us/step - loss: 0.0148 - acc: 1.0000 - val_loss: 0.0590 - val_acc: 0.9753\n",
      "Epoch 59/150\n",
      "1458/1458 [==============================] - 0s 306us/step - loss: 0.0146 - acc: 1.0000 - val_loss: 0.0583 - val_acc: 0.9815\n",
      "Epoch 60/150\n",
      "1458/1458 [==============================] - 0s 252us/step - loss: 0.0132 - acc: 1.0000 - val_loss: 0.0553 - val_acc: 0.9815\n",
      "Epoch 61/150\n",
      "1458/1458 [==============================] - 0s 299us/step - loss: 0.0119 - acc: 1.0000 - val_loss: 0.0566 - val_acc: 0.9753\n",
      "Epoch 62/150\n",
      "1458/1458 [==============================] - 0s 281us/step - loss: 0.0114 - acc: 1.0000 - val_loss: 0.0546 - val_acc: 0.9815\n",
      "Epoch 63/150\n",
      "1458/1458 [==============================] - 0s 291us/step - loss: 0.0110 - acc: 1.0000 - val_loss: 0.0539 - val_acc: 0.9815\n",
      "Epoch 64/150\n",
      "1458/1458 [==============================] - 0s 235us/step - loss: 0.0105 - acc: 1.0000 - val_loss: 0.0536 - val_acc: 0.9753\n",
      "Epoch 65/150\n",
      "1458/1458 [==============================] - 0s 235us/step - loss: 0.0107 - acc: 1.0000 - val_loss: 0.0535 - val_acc: 0.9753\n",
      "Epoch 66/150\n",
      "1458/1458 [==============================] - 0s 300us/step - loss: 0.0104 - acc: 1.0000 - val_loss: 0.0573 - val_acc: 0.9815\n",
      "Epoch 67/150\n",
      "1458/1458 [==============================] - 0s 270us/step - loss: 0.0095 - acc: 1.0000 - val_loss: 0.0535 - val_acc: 0.9753\n",
      "Epoch 68/150\n",
      "1458/1458 [==============================] - 0s 283us/step - loss: 0.0095 - acc: 1.0000 - val_loss: 0.0519 - val_acc: 0.9815\n",
      "Epoch 69/150\n",
      "1458/1458 [==============================] - 0s 247us/step - loss: 0.0092 - acc: 1.0000 - val_loss: 0.0506 - val_acc: 0.9815\n",
      "Epoch 70/150\n",
      "1458/1458 [==============================] - 0s 236us/step - loss: 0.0087 - acc: 1.0000 - val_loss: 0.0502 - val_acc: 0.9815\n",
      "Epoch 71/150\n",
      "1458/1458 [==============================] - 0s 278us/step - loss: 0.0091 - acc: 1.0000 - val_loss: 0.0696 - val_acc: 0.9753\n",
      "Epoch 72/150\n",
      "1458/1458 [==============================] - 0s 278us/step - loss: 0.0101 - acc: 1.0000 - val_loss: 0.0521 - val_acc: 0.9753\n",
      "Epoch 73/150\n",
      "1458/1458 [==============================] - 0s 259us/step - loss: 0.0083 - acc: 1.0000 - val_loss: 0.0551 - val_acc: 0.9815\n",
      "Epoch 74/150\n",
      "1458/1458 [==============================] - 0s 281us/step - loss: 0.0079 - acc: 1.0000 - val_loss: 0.0498 - val_acc: 0.9815\n",
      "Epoch 75/150\n",
      "1458/1458 [==============================] - 0s 304us/step - loss: 0.0072 - acc: 1.0000 - val_loss: 0.0494 - val_acc: 0.9753\n",
      "Epoch 76/150\n",
      "1458/1458 [==============================] - 0s 253us/step - loss: 0.0071 - acc: 1.0000 - val_loss: 0.0500 - val_acc: 0.9753\n",
      "Epoch 77/150\n",
      "1458/1458 [==============================] - 0s 266us/step - loss: 0.0068 - acc: 1.0000 - val_loss: 0.0521 - val_acc: 0.9815\n",
      "Epoch 78/150\n",
      "1458/1458 [==============================] - 0s 262us/step - loss: 0.0067 - acc: 1.0000 - val_loss: 0.0492 - val_acc: 0.9815\n",
      "Epoch 79/150\n",
      "1458/1458 [==============================] - 0s 261us/step - loss: 0.0065 - acc: 1.0000 - val_loss: 0.0493 - val_acc: 0.9753\n",
      "Epoch 80/150\n",
      "1458/1458 [==============================] - 0s 298us/step - loss: 0.0065 - acc: 1.0000 - val_loss: 0.0478 - val_acc: 0.9815\n",
      "Epoch 81/150\n",
      "1458/1458 [==============================] - 0s 282us/step - loss: 0.0059 - acc: 1.0000 - val_loss: 0.0507 - val_acc: 0.9815\n",
      "Epoch 82/150\n",
      "1458/1458 [==============================] - 0s 313us/step - loss: 0.0057 - acc: 1.0000 - val_loss: 0.0474 - val_acc: 0.9815\n",
      "Epoch 83/150\n",
      "1458/1458 [==============================] - 0s 310us/step - loss: 0.0055 - acc: 1.0000 - val_loss: 0.0475 - val_acc: 0.9815\n",
      "Epoch 84/150\n",
      "1458/1458 [==============================] - 0s 268us/step - loss: 0.0055 - acc: 1.0000 - val_loss: 0.0471 - val_acc: 0.9815\n",
      "Epoch 85/150\n",
      "1458/1458 [==============================] - 1s 364us/step - loss: 0.0054 - acc: 1.0000 - val_loss: 0.0512 - val_acc: 0.9815\n",
      "Epoch 86/150\n",
      "1458/1458 [==============================] - 0s 335us/step - loss: 0.0054 - acc: 1.0000 - val_loss: 0.0471 - val_acc: 0.9815\n",
      "Epoch 87/150\n",
      "1458/1458 [==============================] - 0s 300us/step - loss: 0.0050 - acc: 1.0000 - val_loss: 0.0459 - val_acc: 0.9815\n",
      "Epoch 88/150\n",
      "1458/1458 [==============================] - 0s 284us/step - loss: 0.0050 - acc: 1.0000 - val_loss: 0.0455 - val_acc: 0.9815\n",
      "Epoch 89/150\n",
      "1458/1458 [==============================] - 0s 277us/step - loss: 0.0049 - acc: 1.0000 - val_loss: 0.0455 - val_acc: 0.9815\n",
      "Epoch 90/150\n",
      "1458/1458 [==============================] - 0s 245us/step - loss: 0.0048 - acc: 1.0000 - val_loss: 0.0453 - val_acc: 0.9815\n",
      "Epoch 91/150\n",
      "1458/1458 [==============================] - 0s 304us/step - loss: 0.0047 - acc: 1.0000 - val_loss: 0.0476 - val_acc: 0.9877\n",
      "Epoch 92/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1458/1458 [==============================] - 0s 292us/step - loss: 0.0044 - acc: 1.0000 - val_loss: 0.0448 - val_acc: 0.9815\n",
      "Epoch 93/150\n",
      "1458/1458 [==============================] - 0s 293us/step - loss: 0.0047 - acc: 1.0000 - val_loss: 0.0449 - val_acc: 0.9753\n",
      "Epoch 94/150\n",
      "1458/1458 [==============================] - 0s 299us/step - loss: 0.0044 - acc: 1.0000 - val_loss: 0.0448 - val_acc: 0.9815\n",
      "Epoch 95/150\n",
      "1458/1458 [==============================] - 0s 277us/step - loss: 0.0041 - acc: 1.0000 - val_loss: 0.0439 - val_acc: 0.9815\n",
      "Epoch 96/150\n",
      "1458/1458 [==============================] - 0s 292us/step - loss: 0.0039 - acc: 1.0000 - val_loss: 0.0445 - val_acc: 0.9815\n",
      "Epoch 97/150\n",
      "1458/1458 [==============================] - 0s 275us/step - loss: 0.0039 - acc: 1.0000 - val_loss: 0.0454 - val_acc: 0.9877\n",
      "Epoch 98/150\n",
      "1458/1458 [==============================] - 0s 295us/step - loss: 0.0038 - acc: 1.0000 - val_loss: 0.0442 - val_acc: 0.9815\n",
      "Epoch 99/150\n",
      "1458/1458 [==============================] - 0s 334us/step - loss: 0.0038 - acc: 1.0000 - val_loss: 0.0435 - val_acc: 0.9815\n",
      "Epoch 100/150\n",
      "1458/1458 [==============================] - 0s 296us/step - loss: 0.0036 - acc: 1.0000 - val_loss: 0.0444 - val_acc: 0.9815\n",
      "Epoch 101/150\n",
      "1458/1458 [==============================] - 0s 324us/step - loss: 0.0037 - acc: 1.0000 - val_loss: 0.0460 - val_acc: 0.9815\n",
      "Epoch 102/150\n",
      "1458/1458 [==============================] - 0s 279us/step - loss: 0.0036 - acc: 1.0000 - val_loss: 0.0426 - val_acc: 0.9815\n",
      "Epoch 103/150\n",
      "1458/1458 [==============================] - 0s 293us/step - loss: 0.0037 - acc: 1.0000 - val_loss: 0.0430 - val_acc: 0.9815\n",
      "Epoch 104/150\n",
      "1458/1458 [==============================] - 0s 262us/step - loss: 0.0033 - acc: 1.0000 - val_loss: 0.0453 - val_acc: 0.9877\n",
      "Epoch 105/150\n",
      "1458/1458 [==============================] - 0s 237us/step - loss: 0.0032 - acc: 1.0000 - val_loss: 0.0439 - val_acc: 0.9877\n",
      "Epoch 106/150\n",
      "1458/1458 [==============================] - 0s 250us/step - loss: 0.0031 - acc: 1.0000 - val_loss: 0.0438 - val_acc: 0.9877\n",
      "Epoch 107/150\n",
      "1458/1458 [==============================] - 0s 296us/step - loss: 0.0031 - acc: 1.0000 - val_loss: 0.0449 - val_acc: 0.9877\n",
      "Epoch 108/150\n",
      "1458/1458 [==============================] - 0s 271us/step - loss: 0.0031 - acc: 1.0000 - val_loss: 0.0448 - val_acc: 0.9877\n",
      "Epoch 109/150\n",
      "1458/1458 [==============================] - 0s 253us/step - loss: 0.0029 - acc: 1.0000 - val_loss: 0.0424 - val_acc: 0.9815\n",
      "Epoch 110/150\n",
      "1458/1458 [==============================] - 0s 233us/step - loss: 0.0029 - acc: 1.0000 - val_loss: 0.0429 - val_acc: 0.9815\n",
      "Epoch 111/150\n",
      "1458/1458 [==============================] - 0s 255us/step - loss: 0.0029 - acc: 1.0000 - val_loss: 0.0430 - val_acc: 0.9815\n",
      "Epoch 112/150\n",
      "1458/1458 [==============================] - 0s 264us/step - loss: 0.0029 - acc: 1.0000 - val_loss: 0.0410 - val_acc: 0.9815\n",
      "Epoch 113/150\n",
      "1458/1458 [==============================] - 0s 265us/step - loss: 0.0031 - acc: 1.0000 - val_loss: 0.0414 - val_acc: 0.9815\n",
      "Epoch 114/150\n",
      "1458/1458 [==============================] - 0s 245us/step - loss: 0.0028 - acc: 1.0000 - val_loss: 0.0415 - val_acc: 0.9815\n",
      "Epoch 115/150\n",
      "1458/1458 [==============================] - 0s 269us/step - loss: 0.0026 - acc: 1.0000 - val_loss: 0.0415 - val_acc: 0.9815\n",
      "Epoch 116/150\n",
      "1458/1458 [==============================] - 0s 289us/step - loss: 0.0025 - acc: 1.0000 - val_loss: 0.0433 - val_acc: 0.9877\n",
      "Epoch 117/150\n",
      "1458/1458 [==============================] - 0s 241us/step - loss: 0.0025 - acc: 1.0000 - val_loss: 0.0432 - val_acc: 0.9877\n",
      "Epoch 118/150\n",
      "1458/1458 [==============================] - 0s 250us/step - loss: 0.0024 - acc: 1.0000 - val_loss: 0.0440 - val_acc: 0.9877\n",
      "Epoch 119/150\n",
      "1458/1458 [==============================] - 0s 239us/step - loss: 0.0024 - acc: 1.0000 - val_loss: 0.0452 - val_acc: 0.9877\n",
      "Epoch 120/150\n",
      "1458/1458 [==============================] - 0s 239us/step - loss: 0.0024 - acc: 1.0000 - val_loss: 0.0444 - val_acc: 0.9877\n",
      "Epoch 121/150\n",
      "1458/1458 [==============================] - 0s 269us/step - loss: 0.0023 - acc: 1.0000 - val_loss: 0.0416 - val_acc: 0.9815\n",
      "Epoch 122/150\n",
      "1458/1458 [==============================] - 0s 302us/step - loss: 0.0023 - acc: 1.0000 - val_loss: 0.0421 - val_acc: 0.9815\n",
      "Epoch 123/150\n",
      "1458/1458 [==============================] - 0s 241us/step - loss: 0.0022 - acc: 1.0000 - val_loss: 0.0430 - val_acc: 0.9877\n",
      "Epoch 124/150\n",
      "1458/1458 [==============================] - 0s 250us/step - loss: 0.0022 - acc: 1.0000 - val_loss: 0.0444 - val_acc: 0.9877\n",
      "Epoch 125/150\n",
      "1458/1458 [==============================] - 0s 234us/step - loss: 0.0022 - acc: 1.0000 - val_loss: 0.0435 - val_acc: 0.9877\n",
      "Epoch 126/150\n",
      "1458/1458 [==============================] - 0s 229us/step - loss: 0.0021 - acc: 1.0000 - val_loss: 0.0434 - val_acc: 0.9877\n",
      "Epoch 127/150\n",
      "1458/1458 [==============================] - 0s 233us/step - loss: 0.0021 - acc: 1.0000 - val_loss: 0.0439 - val_acc: 0.9877\n",
      "Epoch 128/150\n",
      "1458/1458 [==============================] - 0s 251us/step - loss: 0.0020 - acc: 1.0000 - val_loss: 0.0429 - val_acc: 0.9877\n",
      "Epoch 129/150\n",
      "1458/1458 [==============================] - 0s 254us/step - loss: 0.0020 - acc: 1.0000 - val_loss: 0.0423 - val_acc: 0.9877\n",
      "Epoch 130/150\n",
      "1458/1458 [==============================] - 0s 268us/step - loss: 0.0020 - acc: 1.0000 - val_loss: 0.0404 - val_acc: 0.9815\n",
      "Epoch 131/150\n",
      "1458/1458 [==============================] - 0s 261us/step - loss: 0.0020 - acc: 1.0000 - val_loss: 0.0417 - val_acc: 0.9815\n",
      "Epoch 132/150\n",
      "1458/1458 [==============================] - 0s 309us/step - loss: 0.0018 - acc: 1.0000 - val_loss: 0.0410 - val_acc: 0.9815\n",
      "Epoch 133/150\n",
      "1458/1458 [==============================] - 0s 245us/step - loss: 0.0018 - acc: 1.0000 - val_loss: 0.0431 - val_acc: 0.9877\n",
      "Epoch 134/150\n",
      "1458/1458 [==============================] - 0s 270us/step - loss: 0.0018 - acc: 1.0000 - val_loss: 0.0428 - val_acc: 0.9877\n",
      "Epoch 135/150\n",
      "1458/1458 [==============================] - 0s 227us/step - loss: 0.0017 - acc: 1.0000 - val_loss: 0.0417 - val_acc: 0.9815\n",
      "Epoch 136/150\n",
      "1458/1458 [==============================] - 0s 227us/step - loss: 0.0017 - acc: 1.0000 - val_loss: 0.0419 - val_acc: 0.9815\n",
      "Epoch 137/150\n",
      "1458/1458 [==============================] - 0s 224us/step - loss: 0.0017 - acc: 1.0000 - val_loss: 0.0422 - val_acc: 0.9877\n",
      "Epoch 138/150\n",
      "1458/1458 [==============================] - 0s 260us/step - loss: 0.0016 - acc: 1.0000 - val_loss: 0.0447 - val_acc: 0.9877\n",
      "Epoch 139/150\n",
      "1458/1458 [==============================] - 0s 226us/step - loss: 0.0017 - acc: 1.0000 - val_loss: 0.0438 - val_acc: 0.9877\n",
      "Epoch 140/150\n",
      "1458/1458 [==============================] - 0s 227us/step - loss: 0.0016 - acc: 1.0000 - val_loss: 0.0434 - val_acc: 0.9877\n",
      "Epoch 141/150\n",
      "1458/1458 [==============================] - 0s 228us/step - loss: 0.0016 - acc: 1.0000 - val_loss: 0.0416 - val_acc: 0.9815\n",
      "Epoch 142/150\n",
      "1458/1458 [==============================] - 0s 235us/step - loss: 0.0015 - acc: 1.0000 - val_loss: 0.0423 - val_acc: 0.9877\n",
      "Epoch 143/150\n",
      "1458/1458 [==============================] - 0s 321us/step - loss: 0.0015 - acc: 1.0000 - val_loss: 0.0442 - val_acc: 0.9877\n",
      "Epoch 144/150\n",
      "1458/1458 [==============================] - 0s 237us/step - loss: 0.0015 - acc: 1.0000 - val_loss: 0.0427 - val_acc: 0.9877\n",
      "Epoch 145/150\n",
      "1458/1458 [==============================] - 0s 239us/step - loss: 0.0015 - acc: 1.0000 - val_loss: 0.0452 - val_acc: 0.9877\n",
      "Epoch 146/150\n",
      "1458/1458 [==============================] - 0s 322us/step - loss: 0.0015 - acc: 1.0000 - val_loss: 0.0408 - val_acc: 0.9815\n",
      "Epoch 147/150\n",
      "1458/1458 [==============================] - 0s 298us/step - loss: 0.0014 - acc: 1.0000 - val_loss: 0.0405 - val_acc: 0.9815\n",
      "Epoch 148/150\n",
      "1458/1458 [==============================] - 0s 253us/step - loss: 0.0014 - acc: 1.0000 - val_loss: 0.0399 - val_acc: 0.9815\n",
      "Epoch 149/150\n",
      "1458/1458 [==============================] - 0s 329us/step - loss: 0.0014 - acc: 1.0000 - val_loss: 0.0397 - val_acc: 0.9815\n",
      "Epoch 150/150\n",
      "1458/1458 [==============================] - 0s 306us/step - loss: 0.0014 - acc: 1.0000 - val_loss: 0.0401 - val_acc: 0.9815\n",
      "The score is......\n",
      " [0.04010752821053712, 0.9814814814814815]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compute bottleneck features...\n",
      "train_bNFeatures[img].shape =  (1458, 73728)\n",
      "val_bNFeatures[img].shape =  (162, 73728)\n",
      "Train head...\n",
      "Train on 1458 samples, validate on 162 samples\n",
      "Epoch 1/150\n",
      "1458/1458 [==============================] - 1s 592us/step - loss: 1.1616 - acc: 0.4650 - val_loss: 0.6933 - val_acc: 0.4753\n",
      "Epoch 2/150\n",
      "1458/1458 [==============================] - 0s 281us/step - loss: 0.6932 - acc: 0.4842 - val_loss: 0.6930 - val_acc: 0.5247\n",
      "Epoch 3/150\n",
      "1458/1458 [==============================] - 0s 300us/step - loss: 0.6926 - acc: 0.5597 - val_loss: 0.6927 - val_acc: 0.5247\n",
      "Epoch 4/150\n",
      "1458/1458 [==============================] - 1s 514us/step - loss: 0.6917 - acc: 0.5597 - val_loss: 0.6925 - val_acc: 0.5247\n",
      "Epoch 5/150\n",
      "1458/1458 [==============================] - 0s 319us/step - loss: 0.6910 - acc: 0.5597 - val_loss: 0.6922 - val_acc: 0.5247\n",
      "Epoch 6/150\n",
      "1458/1458 [==============================] - 0s 273us/step - loss: 0.6902 - acc: 0.5597 - val_loss: 0.6921 - val_acc: 0.5247\n",
      "Epoch 7/150\n",
      "1458/1458 [==============================] - 0s 257us/step - loss: 0.6895 - acc: 0.5597 - val_loss: 0.6920 - val_acc: 0.5247\n",
      "Epoch 8/150\n",
      "1458/1458 [==============================] - 0s 286us/step - loss: 0.6890 - acc: 0.5597 - val_loss: 0.6919 - val_acc: 0.5247\n",
      "Epoch 9/150\n",
      "1458/1458 [==============================] - 0s 240us/step - loss: 0.6885 - acc: 0.5597 - val_loss: 0.6919 - val_acc: 0.5247\n",
      "Epoch 10/150\n",
      "1458/1458 [==============================] - 0s 305us/step - loss: 0.6881 - acc: 0.5597 - val_loss: 0.6920 - val_acc: 0.5247\n",
      "Epoch 11/150\n",
      "1458/1458 [==============================] - 0s 248us/step - loss: 0.6877 - acc: 0.5597 - val_loss: 0.6920 - val_acc: 0.5247\n",
      "Epoch 12/150\n",
      "1458/1458 [==============================] - 0s 283us/step - loss: 0.6874 - acc: 0.5597 - val_loss: 0.6921 - val_acc: 0.5247\n",
      "Epoch 13/150\n",
      "1458/1458 [==============================] - 0s 300us/step - loss: 0.6872 - acc: 0.5597 - val_loss: 0.6922 - val_acc: 0.5247\n",
      "Epoch 14/150\n",
      "1458/1458 [==============================] - 0s 279us/step - loss: 0.6869 - acc: 0.5597 - val_loss: 0.6924 - val_acc: 0.5247\n",
      "Epoch 15/150\n",
      "1458/1458 [==============================] - 0s 291us/step - loss: 0.6868 - acc: 0.5597 - val_loss: 0.6925 - val_acc: 0.5247\n",
      "Epoch 16/150\n",
      "1458/1458 [==============================] - 0s 301us/step - loss: 0.6866 - acc: 0.5597 - val_loss: 0.6926 - val_acc: 0.5247\n",
      "Epoch 17/150\n",
      "1458/1458 [==============================] - 0s 318us/step - loss: 0.6865 - acc: 0.5597 - val_loss: 0.6927 - val_acc: 0.5247\n",
      "Epoch 18/150\n",
      "1458/1458 [==============================] - 0s 288us/step - loss: 0.6864 - acc: 0.5597 - val_loss: 0.6929 - val_acc: 0.5247\n",
      "Epoch 19/150\n",
      "1458/1458 [==============================] - 0s 301us/step - loss: 0.6863 - acc: 0.5597 - val_loss: 0.6930 - val_acc: 0.5247\n",
      "Epoch 20/150\n",
      "1458/1458 [==============================] - 0s 305us/step - loss: 0.6863 - acc: 0.5597 - val_loss: 0.6931 - val_acc: 0.5247\n",
      "Epoch 21/150\n",
      "1458/1458 [==============================] - 0s 249us/step - loss: 0.6862 - acc: 0.5597 - val_loss: 0.6932 - val_acc: 0.5247\n",
      "Epoch 22/150\n",
      "1458/1458 [==============================] - 0s 281us/step - loss: 0.6862 - acc: 0.5597 - val_loss: 0.6934 - val_acc: 0.5247\n",
      "Epoch 23/150\n",
      "1458/1458 [==============================] - 0s 312us/step - loss: 0.6862 - acc: 0.5597 - val_loss: 0.6934 - val_acc: 0.5247\n",
      "Epoch 24/150\n",
      "1458/1458 [==============================] - 0s 301us/step - loss: 0.6861 - acc: 0.5597 - val_loss: 0.6935 - val_acc: 0.5247\n",
      "Epoch 25/150\n",
      "1458/1458 [==============================] - 0s 276us/step - loss: 0.6861 - acc: 0.5597 - val_loss: 0.6936 - val_acc: 0.5247\n",
      "Epoch 26/150\n",
      "1458/1458 [==============================] - 0s 266us/step - loss: 0.6861 - acc: 0.5597 - val_loss: 0.6937 - val_acc: 0.5247\n",
      "Epoch 27/150\n",
      "1458/1458 [==============================] - 0s 289us/step - loss: 0.6861 - acc: 0.5597 - val_loss: 0.6938 - val_acc: 0.5247\n",
      "Epoch 28/150\n",
      "1458/1458 [==============================] - 0s 285us/step - loss: 0.6861 - acc: 0.5597 - val_loss: 0.6939 - val_acc: 0.5247\n",
      "Epoch 29/150\n",
      "1458/1458 [==============================] - 1s 352us/step - loss: 0.6860 - acc: 0.5597 - val_loss: 0.6940 - val_acc: 0.5247\n",
      "Epoch 30/150\n",
      "1458/1458 [==============================] - 1s 442us/step - loss: 0.6860 - acc: 0.5597 - val_loss: 0.6940 - val_acc: 0.5247\n",
      "Epoch 31/150\n",
      "1458/1458 [==============================] - 1s 388us/step - loss: 0.6860 - acc: 0.5597 - val_loss: 0.6940 - val_acc: 0.5247\n",
      "Epoch 32/150\n",
      "1458/1458 [==============================] - 0s 337us/step - loss: 0.6860 - acc: 0.5597 - val_loss: 0.6941 - val_acc: 0.5247\n",
      "Epoch 33/150\n",
      "1458/1458 [==============================] - 1s 349us/step - loss: 0.6860 - acc: 0.5597 - val_loss: 0.6943 - val_acc: 0.5247\n",
      "Epoch 34/150\n",
      "1458/1458 [==============================] - 0s 314us/step - loss: 0.6860 - acc: 0.5597 - val_loss: 0.6944 - val_acc: 0.5247\n",
      "Epoch 35/150\n",
      "1458/1458 [==============================] - 0s 316us/step - loss: 0.6860 - acc: 0.5597 - val_loss: 0.6943 - val_acc: 0.5247\n",
      "Epoch 36/150\n",
      "1458/1458 [==============================] - 0s 333us/step - loss: 0.6860 - acc: 0.5597 - val_loss: 0.6942 - val_acc: 0.5247\n",
      "Epoch 37/150\n",
      "1458/1458 [==============================] - 0s 324us/step - loss: 0.6860 - acc: 0.5597 - val_loss: 0.6943 - val_acc: 0.5247\n",
      "Epoch 38/150\n",
      "1458/1458 [==============================] - 0s 275us/step - loss: 0.6860 - acc: 0.5597 - val_loss: 0.6943 - val_acc: 0.5247\n",
      "Epoch 39/150\n",
      "1458/1458 [==============================] - 0s 312us/step - loss: 0.6860 - acc: 0.5597 - val_loss: 0.6943 - val_acc: 0.5247\n",
      "Epoch 40/150\n",
      "1458/1458 [==============================] - 1s 400us/step - loss: 0.6860 - acc: 0.5597 - val_loss: 0.6945 - val_acc: 0.5247\n",
      "Epoch 41/150\n",
      "1458/1458 [==============================] - 0s 276us/step - loss: 0.6860 - acc: 0.5597 - val_loss: 0.6944 - val_acc: 0.5247\n",
      "Epoch 42/150\n",
      "1458/1458 [==============================] - 0s 236us/step - loss: 0.6860 - acc: 0.5597 - val_loss: 0.6944 - val_acc: 0.5247\n",
      "Epoch 43/150\n",
      "1458/1458 [==============================] - 0s 287us/step - loss: 0.6860 - acc: 0.5597 - val_loss: 0.6944 - val_acc: 0.5247\n",
      "Epoch 44/150\n",
      "1458/1458 [==============================] - 0s 289us/step - loss: 0.6860 - acc: 0.5597 - val_loss: 0.6945 - val_acc: 0.5247\n",
      "Epoch 45/150\n",
      "1458/1458 [==============================] - 0s 277us/step - loss: 0.6861 - acc: 0.5597 - val_loss: 0.6942 - val_acc: 0.5247\n",
      "Epoch 46/150\n",
      "1458/1458 [==============================] - 0s 261us/step - loss: 0.6860 - acc: 0.5597 - val_loss: 0.6943 - val_acc: 0.5247\n",
      "Epoch 47/150\n",
      "1458/1458 [==============================] - 0s 315us/step - loss: 0.6860 - acc: 0.5597 - val_loss: 0.6944 - val_acc: 0.5247\n",
      "Epoch 48/150\n",
      "1458/1458 [==============================] - 0s 323us/step - loss: 0.6860 - acc: 0.5597 - val_loss: 0.6944 - val_acc: 0.5247\n",
      "Epoch 49/150\n",
      "1458/1458 [==============================] - 0s 309us/step - loss: 0.6860 - acc: 0.5597 - val_loss: 0.6944 - val_acc: 0.5247\n",
      "Epoch 50/150\n",
      "1458/1458 [==============================] - 0s 242us/step - loss: 0.6860 - acc: 0.5597 - val_loss: 0.6944 - val_acc: 0.5247\n",
      "Epoch 51/150\n",
      "1458/1458 [==============================] - 0s 271us/step - loss: 0.6860 - acc: 0.5597 - val_loss: 0.6945 - val_acc: 0.5247\n",
      "Epoch 52/150\n",
      "1458/1458 [==============================] - 0s 260us/step - loss: 0.6860 - acc: 0.5597 - val_loss: 0.6945 - val_acc: 0.5247\n",
      "Epoch 53/150\n",
      "1458/1458 [==============================] - 0s 234us/step - loss: 0.6860 - acc: 0.5597 - val_loss: 0.6945 - val_acc: 0.5247\n",
      "Epoch 54/150\n",
      "1458/1458 [==============================] - 0s 237us/step - loss: 0.6860 - acc: 0.5597 - val_loss: 0.6946 - val_acc: 0.5247\n",
      "Epoch 55/150\n",
      "1458/1458 [==============================] - 0s 282us/step - loss: 0.6860 - acc: 0.5597 - val_loss: 0.6944 - val_acc: 0.5247\n",
      "Epoch 56/150\n",
      "1458/1458 [==============================] - 0s 251us/step - loss: 0.6860 - acc: 0.5597 - val_loss: 0.6944 - val_acc: 0.5247\n",
      "Epoch 57/150\n",
      "1458/1458 [==============================] - 0s 296us/step - loss: 0.6860 - acc: 0.5597 - val_loss: 0.6944 - val_acc: 0.5247\n",
      "Epoch 58/150\n",
      "1458/1458 [==============================] - 0s 300us/step - loss: 0.6860 - acc: 0.5597 - val_loss: 0.6944 - val_acc: 0.5247\n",
      "Epoch 59/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1458/1458 [==============================] - 0s 319us/step - loss: 0.6860 - acc: 0.5597 - val_loss: 0.6944 - val_acc: 0.5247\n",
      "Epoch 60/150\n",
      "1458/1458 [==============================] - 0s 239us/step - loss: 0.6860 - acc: 0.5597 - val_loss: 0.6944 - val_acc: 0.5247\n",
      "Epoch 61/150\n",
      "1458/1458 [==============================] - 0s 286us/step - loss: 0.6860 - acc: 0.5597 - val_loss: 0.6943 - val_acc: 0.5247\n",
      "Epoch 62/150\n",
      "1458/1458 [==============================] - 0s 322us/step - loss: 0.6860 - acc: 0.5597 - val_loss: 0.6943 - val_acc: 0.5247\n",
      "Epoch 63/150\n",
      "1458/1458 [==============================] - 0s 291us/step - loss: 0.6860 - acc: 0.5597 - val_loss: 0.6943 - val_acc: 0.5247\n",
      "Epoch 64/150\n",
      "1458/1458 [==============================] - 0s 272us/step - loss: 0.6860 - acc: 0.5597 - val_loss: 0.6943 - val_acc: 0.5247\n",
      "Epoch 65/150\n",
      "1458/1458 [==============================] - 0s 243us/step - loss: 0.6860 - acc: 0.5597 - val_loss: 0.6943 - val_acc: 0.5247\n",
      "Epoch 66/150\n",
      "1458/1458 [==============================] - 0s 293us/step - loss: 0.6860 - acc: 0.5597 - val_loss: 0.6944 - val_acc: 0.5247\n",
      "Epoch 67/150\n",
      "1458/1458 [==============================] - 0s 282us/step - loss: 0.6860 - acc: 0.5597 - val_loss: 0.6943 - val_acc: 0.5247\n",
      "Epoch 68/150\n",
      "1458/1458 [==============================] - 0s 290us/step - loss: 0.6860 - acc: 0.5597 - val_loss: 0.6944 - val_acc: 0.5247\n",
      "Epoch 69/150\n",
      "1458/1458 [==============================] - 0s 248us/step - loss: 0.6860 - acc: 0.5597 - val_loss: 0.6944 - val_acc: 0.5247\n",
      "Epoch 70/150\n",
      "1458/1458 [==============================] - 0s 238us/step - loss: 0.6860 - acc: 0.5597 - val_loss: 0.6945 - val_acc: 0.5247\n",
      "Epoch 71/150\n",
      "1458/1458 [==============================] - 0s 273us/step - loss: 0.6860 - acc: 0.5597 - val_loss: 0.6944 - val_acc: 0.5247\n",
      "Epoch 72/150\n",
      "1458/1458 [==============================] - 0s 291us/step - loss: 0.6860 - acc: 0.5597 - val_loss: 0.6945 - val_acc: 0.5247\n",
      "Epoch 73/150\n",
      "1458/1458 [==============================] - 0s 268us/step - loss: 0.6860 - acc: 0.5597 - val_loss: 0.6944 - val_acc: 0.5247\n",
      "Epoch 74/150\n",
      "1458/1458 [==============================] - 0s 341us/step - loss: 0.6860 - acc: 0.5597 - val_loss: 0.6943 - val_acc: 0.5247\n",
      "Epoch 75/150\n",
      "1458/1458 [==============================] - 0s 326us/step - loss: 0.6860 - acc: 0.5597 - val_loss: 0.6943 - val_acc: 0.5247\n",
      "Epoch 76/150\n",
      "1458/1458 [==============================] - 1s 345us/step - loss: 0.6860 - acc: 0.5597 - val_loss: 0.6943 - val_acc: 0.5247\n",
      "Epoch 77/150\n",
      "1458/1458 [==============================] - 0s 323us/step - loss: 0.6860 - acc: 0.5597 - val_loss: 0.6944 - val_acc: 0.5247\n",
      "Epoch 78/150\n",
      "1458/1458 [==============================] - 0s 310us/step - loss: 0.6860 - acc: 0.5597 - val_loss: 0.6943 - val_acc: 0.5247\n",
      "Epoch 79/150\n",
      "1458/1458 [==============================] - 1s 344us/step - loss: 0.6860 - acc: 0.5597 - val_loss: 0.6943 - val_acc: 0.5247\n",
      "Epoch 80/150\n",
      "1458/1458 [==============================] - 0s 306us/step - loss: 0.6860 - acc: 0.5597 - val_loss: 0.6943 - val_acc: 0.5247\n",
      "Epoch 81/150\n",
      "1458/1458 [==============================] - 0s 333us/step - loss: 0.6860 - acc: 0.5597 - val_loss: 0.6943 - val_acc: 0.5247\n",
      "Epoch 82/150\n",
      "1458/1458 [==============================] - 0s 276us/step - loss: 0.6860 - acc: 0.5597 - val_loss: 0.6943 - val_acc: 0.5247\n",
      "Epoch 83/150\n",
      "1458/1458 [==============================] - 0s 322us/step - loss: 0.6860 - acc: 0.5597 - val_loss: 0.6943 - val_acc: 0.5247\n",
      "Epoch 84/150\n",
      "1458/1458 [==============================] - 0s 307us/step - loss: 0.6860 - acc: 0.5597 - val_loss: 0.6943 - val_acc: 0.5247\n",
      "Epoch 85/150\n",
      "1458/1458 [==============================] - 0s 306us/step - loss: 0.6860 - acc: 0.5597 - val_loss: 0.6943 - val_acc: 0.5247\n",
      "Epoch 86/150\n",
      "1458/1458 [==============================] - 0s 315us/step - loss: 0.6860 - acc: 0.5597 - val_loss: 0.6943 - val_acc: 0.5247\n",
      "Epoch 87/150\n",
      "1458/1458 [==============================] - 0s 301us/step - loss: 0.6860 - acc: 0.5597 - val_loss: 0.6944 - val_acc: 0.5247\n",
      "Epoch 88/150\n",
      "1458/1458 [==============================] - 0s 299us/step - loss: 0.6860 - acc: 0.5597 - val_loss: 0.6943 - val_acc: 0.5247\n",
      "Epoch 89/150\n",
      "1458/1458 [==============================] - 0s 292us/step - loss: 0.6860 - acc: 0.5597 - val_loss: 0.6943 - val_acc: 0.5247\n",
      "Epoch 90/150\n",
      "1458/1458 [==============================] - 0s 232us/step - loss: 0.6860 - acc: 0.5597 - val_loss: 0.6943 - val_acc: 0.5247\n",
      "Epoch 91/150\n",
      "1458/1458 [==============================] - 0s 284us/step - loss: 0.6860 - acc: 0.5597 - val_loss: 0.6944 - val_acc: 0.5247\n",
      "Epoch 92/150\n",
      "1458/1458 [==============================] - 0s 279us/step - loss: 0.6860 - acc: 0.5597 - val_loss: 0.6943 - val_acc: 0.5247\n",
      "Epoch 93/150\n",
      "1458/1458 [==============================] - 0s 252us/step - loss: 0.6861 - acc: 0.5597 - val_loss: 0.6944 - val_acc: 0.5247\n",
      "Epoch 94/150\n",
      "1458/1458 [==============================] - 0s 307us/step - loss: 0.6860 - acc: 0.5597 - val_loss: 0.6943 - val_acc: 0.5247\n",
      "Epoch 95/150\n",
      "1458/1458 [==============================] - 0s 292us/step - loss: 0.6860 - acc: 0.5597 - val_loss: 0.6944 - val_acc: 0.5247\n",
      "Epoch 96/150\n",
      "1458/1458 [==============================] - 0s 247us/step - loss: 0.6860 - acc: 0.5597 - val_loss: 0.6943 - val_acc: 0.5247\n",
      "Epoch 97/150\n",
      "1458/1458 [==============================] - 0s 271us/step - loss: 0.6860 - acc: 0.5597 - val_loss: 0.6944 - val_acc: 0.5247\n",
      "Epoch 98/150\n",
      "1458/1458 [==============================] - 0s 271us/step - loss: 0.6860 - acc: 0.5597 - val_loss: 0.6943 - val_acc: 0.5247\n",
      "Epoch 99/150\n",
      "1458/1458 [==============================] - 0s 311us/step - loss: 0.6860 - acc: 0.5597 - val_loss: 0.6944 - val_acc: 0.5247\n",
      "Epoch 100/150\n",
      "1458/1458 [==============================] - 0s 305us/step - loss: 0.6860 - acc: 0.5597 - val_loss: 0.6944 - val_acc: 0.5247\n",
      "Epoch 101/150\n",
      "1458/1458 [==============================] - 0s 296us/step - loss: 0.6860 - acc: 0.5597 - val_loss: 0.6943 - val_acc: 0.5247\n",
      "Epoch 102/150\n",
      "1458/1458 [==============================] - 0s 310us/step - loss: 0.6860 - acc: 0.5597 - val_loss: 0.6943 - val_acc: 0.5247\n",
      "Epoch 103/150\n",
      "1458/1458 [==============================] - 1s 350us/step - loss: 0.6860 - acc: 0.5597 - val_loss: 0.6944 - val_acc: 0.5247\n",
      "Epoch 104/150\n",
      "1458/1458 [==============================] - 0s 260us/step - loss: 0.6861 - acc: 0.5597 - val_loss: 0.6945 - val_acc: 0.5247\n",
      "Epoch 105/150\n",
      "1458/1458 [==============================] - 0s 285us/step - loss: 0.6860 - acc: 0.5597 - val_loss: 0.6944 - val_acc: 0.5247\n",
      "Epoch 106/150\n",
      "1458/1458 [==============================] - 0s 267us/step - loss: 0.6860 - acc: 0.5597 - val_loss: 0.6943 - val_acc: 0.5247\n",
      "Epoch 107/150\n",
      "1458/1458 [==============================] - 0s 286us/step - loss: 0.6860 - acc: 0.5597 - val_loss: 0.6943 - val_acc: 0.5247\n",
      "Epoch 108/150\n",
      "1458/1458 [==============================] - 0s 289us/step - loss: 0.6860 - acc: 0.5597 - val_loss: 0.6944 - val_acc: 0.5247\n",
      "Epoch 109/150\n",
      "1458/1458 [==============================] - 0s 300us/step - loss: 0.6860 - acc: 0.5597 - val_loss: 0.6944 - val_acc: 0.5247\n",
      "Epoch 110/150\n",
      "1458/1458 [==============================] - 0s 237us/step - loss: 0.6860 - acc: 0.5597 - val_loss: 0.6944 - val_acc: 0.5247\n",
      "Epoch 111/150\n",
      "1458/1458 [==============================] - 0s 284us/step - loss: 0.6860 - acc: 0.5597 - val_loss: 0.6945 - val_acc: 0.5247\n",
      "Epoch 112/150\n",
      "1458/1458 [==============================] - 0s 293us/step - loss: 0.6860 - acc: 0.5597 - val_loss: 0.6944 - val_acc: 0.5247\n",
      "Epoch 113/150\n",
      "1458/1458 [==============================] - 0s 313us/step - loss: 0.6860 - acc: 0.5597 - val_loss: 0.6944 - val_acc: 0.5247\n",
      "Epoch 114/150\n",
      "1458/1458 [==============================] - 0s 262us/step - loss: 0.6860 - acc: 0.5597 - val_loss: 0.6944 - val_acc: 0.5247\n",
      "Epoch 115/150\n",
      "1458/1458 [==============================] - 0s 235us/step - loss: 0.6860 - acc: 0.5597 - val_loss: 0.6945 - val_acc: 0.5247\n",
      "Epoch 116/150\n",
      "1458/1458 [==============================] - 0s 306us/step - loss: 0.6860 - acc: 0.5597 - val_loss: 0.6945 - val_acc: 0.5247\n",
      "Epoch 117/150\n",
      "1458/1458 [==============================] - 0s 246us/step - loss: 0.6860 - acc: 0.5597 - val_loss: 0.6945 - val_acc: 0.5247\n",
      "Epoch 118/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1458/1458 [==============================] - 0s 232us/step - loss: 0.6860 - acc: 0.5597 - val_loss: 0.6944 - val_acc: 0.5247\n",
      "Epoch 119/150\n",
      "1458/1458 [==============================] - 0s 310us/step - loss: 0.6860 - acc: 0.5597 - val_loss: 0.6944 - val_acc: 0.5247\n",
      "Epoch 120/150\n",
      "1458/1458 [==============================] - 0s 312us/step - loss: 0.6860 - acc: 0.5597 - val_loss: 0.6943 - val_acc: 0.5247\n",
      "Epoch 121/150\n",
      "1458/1458 [==============================] - 0s 294us/step - loss: 0.6860 - acc: 0.5597 - val_loss: 0.6942 - val_acc: 0.5247\n",
      "Epoch 122/150\n",
      "1458/1458 [==============================] - 0s 268us/step - loss: 0.6860 - acc: 0.5597 - val_loss: 0.6944 - val_acc: 0.5247\n",
      "Epoch 123/150\n",
      "1458/1458 [==============================] - 0s 246us/step - loss: 0.6860 - acc: 0.5597 - val_loss: 0.6942 - val_acc: 0.5247\n",
      "Epoch 124/150\n",
      "1458/1458 [==============================] - 0s 259us/step - loss: 0.6860 - acc: 0.5597 - val_loss: 0.6942 - val_acc: 0.5247\n",
      "Epoch 125/150\n",
      "1458/1458 [==============================] - 0s 236us/step - loss: 0.6860 - acc: 0.5597 - val_loss: 0.6943 - val_acc: 0.5247\n",
      "Epoch 126/150\n",
      "1458/1458 [==============================] - 0s 229us/step - loss: 0.6860 - acc: 0.5597 - val_loss: 0.6942 - val_acc: 0.5247\n",
      "Epoch 127/150\n",
      "1458/1458 [==============================] - 0s 240us/step - loss: 0.6860 - acc: 0.5597 - val_loss: 0.6942 - val_acc: 0.5247\n",
      "Epoch 128/150\n",
      "1458/1458 [==============================] - 0s 239us/step - loss: 0.6861 - acc: 0.5597 - val_loss: 0.6943 - val_acc: 0.5247\n",
      "Epoch 129/150\n",
      "1458/1458 [==============================] - 0s 279us/step - loss: 0.6860 - acc: 0.5597 - val_loss: 0.6943 - val_acc: 0.5247\n",
      "Epoch 130/150\n",
      "1458/1458 [==============================] - 0s 298us/step - loss: 0.6860 - acc: 0.5597 - val_loss: 0.6943 - val_acc: 0.5247\n",
      "Epoch 131/150\n",
      "1458/1458 [==============================] - 0s 300us/step - loss: 0.6860 - acc: 0.5597 - val_loss: 0.6942 - val_acc: 0.5247\n",
      "Epoch 132/150\n",
      "1458/1458 [==============================] - 1s 366us/step - loss: 0.6860 - acc: 0.5597 - val_loss: 0.6942 - val_acc: 0.5247\n",
      "Epoch 133/150\n",
      "1458/1458 [==============================] - 0s 315us/step - loss: 0.6860 - acc: 0.5597 - val_loss: 0.6943 - val_acc: 0.5247\n",
      "Epoch 134/150\n",
      "1458/1458 [==============================] - 0s 282us/step - loss: 0.6860 - acc: 0.5597 - val_loss: 0.6943 - val_acc: 0.5247\n",
      "Epoch 135/150\n",
      "1458/1458 [==============================] - 0s 328us/step - loss: 0.6860 - acc: 0.5597 - val_loss: 0.6944 - val_acc: 0.5247\n",
      "Epoch 136/150\n",
      "1458/1458 [==============================] - 0s 307us/step - loss: 0.6860 - acc: 0.5597 - val_loss: 0.6944 - val_acc: 0.5247\n",
      "Epoch 137/150\n",
      "1458/1458 [==============================] - 0s 290us/step - loss: 0.6860 - acc: 0.5597 - val_loss: 0.6944 - val_acc: 0.5247\n",
      "Epoch 138/150\n",
      "1458/1458 [==============================] - 0s 276us/step - loss: 0.6860 - acc: 0.5597 - val_loss: 0.6944 - val_acc: 0.5247\n",
      "Epoch 139/150\n",
      "1458/1458 [==============================] - 0s 301us/step - loss: 0.6860 - acc: 0.5597 - val_loss: 0.6945 - val_acc: 0.5247\n",
      "Epoch 140/150\n",
      "1458/1458 [==============================] - 0s 279us/step - loss: 0.6860 - acc: 0.5597 - val_loss: 0.6945 - val_acc: 0.5247\n",
      "Epoch 141/150\n",
      "1458/1458 [==============================] - 0s 246us/step - loss: 0.6860 - acc: 0.5597 - val_loss: 0.6946 - val_acc: 0.5247\n",
      "Epoch 142/150\n",
      "1458/1458 [==============================] - 0s 253us/step - loss: 0.6860 - acc: 0.5597 - val_loss: 0.6945 - val_acc: 0.5247\n",
      "Epoch 143/150\n",
      "1458/1458 [==============================] - 0s 284us/step - loss: 0.6860 - acc: 0.5597 - val_loss: 0.6945 - val_acc: 0.5247\n",
      "Epoch 144/150\n",
      "1458/1458 [==============================] - 0s 321us/step - loss: 0.6860 - acc: 0.5597 - val_loss: 0.6944 - val_acc: 0.5247\n",
      "Epoch 145/150\n",
      "1458/1458 [==============================] - 0s 251us/step - loss: 0.6860 - acc: 0.5597 - val_loss: 0.6944 - val_acc: 0.5247\n",
      "Epoch 146/150\n",
      "1458/1458 [==============================] - 0s 246us/step - loss: 0.6860 - acc: 0.5597 - val_loss: 0.6943 - val_acc: 0.5247\n",
      "Epoch 147/150\n",
      "1458/1458 [==============================] - 0s 236us/step - loss: 0.6860 - acc: 0.5597 - val_loss: 0.6944 - val_acc: 0.5247\n",
      "Epoch 148/150\n",
      "1458/1458 [==============================] - 0s 268us/step - loss: 0.6860 - acc: 0.5597 - val_loss: 0.6944 - val_acc: 0.5247\n",
      "Epoch 149/150\n",
      "1458/1458 [==============================] - 0s 288us/step - loss: 0.6860 - acc: 0.5597 - val_loss: 0.6944 - val_acc: 0.5247\n",
      "Epoch 150/150\n",
      "1458/1458 [==============================] - 0s 283us/step - loss: 0.6860 - acc: 0.5597 - val_loss: 0.6945 - val_acc: 0.5247\n",
      "The score is......\n",
      " [0.6945326894889643, 0.5246913580246914]\n",
      "Compute bottleneck features...\n",
      "train_bNFeatures[img].shape =  (1458, 73728)\n",
      "val_bNFeatures[img].shape =  (162, 73728)\n",
      "Train head...\n",
      "Train on 1458 samples, validate on 162 samples\n",
      "Epoch 1/150\n",
      "1458/1458 [==============================] - 1s 601us/step - loss: 8.3488 - acc: 0.4547 - val_loss: 9.3015 - val_acc: 0.4198\n",
      "Epoch 2/150\n",
      "1458/1458 [==============================] - 0s 288us/step - loss: 8.8727 - acc: 0.4465 - val_loss: 9.3015 - val_acc: 0.4198\n",
      "Epoch 3/150\n",
      "1458/1458 [==============================] - 0s 337us/step - loss: 8.8727 - acc: 0.4465 - val_loss: 9.3015 - val_acc: 0.4198\n",
      "Epoch 4/150\n",
      "1458/1458 [==============================] - 0s 275us/step - loss: 8.8727 - acc: 0.4465 - val_loss: 9.3015 - val_acc: 0.4198\n",
      "Epoch 5/150\n",
      "1458/1458 [==============================] - 0s 267us/step - loss: 8.8727 - acc: 0.4465 - val_loss: 9.3015 - val_acc: 0.4198\n",
      "Epoch 6/150\n",
      "1458/1458 [==============================] - 0s 308us/step - loss: 8.8727 - acc: 0.4465 - val_loss: 9.3015 - val_acc: 0.4198\n",
      "Epoch 7/150\n",
      "1458/1458 [==============================] - 1s 353us/step - loss: 8.8727 - acc: 0.4465 - val_loss: 9.3015 - val_acc: 0.4198\n",
      "Epoch 8/150\n",
      "1458/1458 [==============================] - 0s 313us/step - loss: 8.8727 - acc: 0.4465 - val_loss: 9.3015 - val_acc: 0.4198\n",
      "Epoch 9/150\n",
      "1458/1458 [==============================] - 0s 302us/step - loss: 8.8727 - acc: 0.4465 - val_loss: 9.3015 - val_acc: 0.4198\n",
      "Epoch 10/150\n",
      "1458/1458 [==============================] - 0s 330us/step - loss: 8.8727 - acc: 0.4465 - val_loss: 9.3015 - val_acc: 0.4198\n",
      "Epoch 11/150\n",
      "1458/1458 [==============================] - 0s 286us/step - loss: 8.8727 - acc: 0.4465 - val_loss: 9.3015 - val_acc: 0.4198\n",
      "Epoch 12/150\n",
      "1458/1458 [==============================] - 0s 284us/step - loss: 8.8727 - acc: 0.4465 - val_loss: 9.3015 - val_acc: 0.4198\n",
      "Epoch 13/150\n",
      "1458/1458 [==============================] - 0s 323us/step - loss: 8.8727 - acc: 0.4465 - val_loss: 9.3015 - val_acc: 0.4198\n",
      "Epoch 14/150\n",
      "1458/1458 [==============================] - 0s 301us/step - loss: 8.8727 - acc: 0.4465 - val_loss: 9.3015 - val_acc: 0.4198\n",
      "Epoch 15/150\n",
      "1458/1458 [==============================] - 0s 320us/step - loss: 8.8727 - acc: 0.4465 - val_loss: 9.3015 - val_acc: 0.4198\n",
      "Epoch 16/150\n",
      "1458/1458 [==============================] - 0s 297us/step - loss: 8.8727 - acc: 0.4465 - val_loss: 9.3015 - val_acc: 0.4198\n",
      "Epoch 17/150\n",
      "1458/1458 [==============================] - 1s 361us/step - loss: 8.8727 - acc: 0.4465 - val_loss: 9.3015 - val_acc: 0.4198\n",
      "Epoch 18/150\n",
      "1458/1458 [==============================] - 1s 427us/step - loss: 8.8727 - acc: 0.4465 - val_loss: 9.3015 - val_acc: 0.4198\n",
      "Epoch 19/150\n",
      "1458/1458 [==============================] - 1s 403us/step - loss: 8.8727 - acc: 0.4465 - val_loss: 9.3015 - val_acc: 0.4198\n",
      "Epoch 20/150\n",
      "1458/1458 [==============================] - 0s 335us/step - loss: 8.8727 - acc: 0.4465 - val_loss: 9.3015 - val_acc: 0.4198\n",
      "Epoch 21/150\n",
      "1458/1458 [==============================] - 0s 341us/step - loss: 8.8727 - acc: 0.4465 - val_loss: 9.3015 - val_acc: 0.4198\n",
      "Epoch 22/150\n",
      "1458/1458 [==============================] - 0s 313us/step - loss: 8.8727 - acc: 0.4465 - val_loss: 9.3015 - val_acc: 0.4198\n",
      "Epoch 23/150\n",
      "1458/1458 [==============================] - 0s 336us/step - loss: 8.8727 - acc: 0.4465 - val_loss: 9.3015 - val_acc: 0.4198\n",
      "Epoch 24/150\n",
      "1458/1458 [==============================] - 0s 271us/step - loss: 8.8727 - acc: 0.4465 - val_loss: 9.3015 - val_acc: 0.4198\n",
      "Epoch 25/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1458/1458 [==============================] - 0s 327us/step - loss: 8.8727 - acc: 0.4465 - val_loss: 9.3015 - val_acc: 0.4198\n",
      "Epoch 26/150\n",
      "1458/1458 [==============================] - 0s 323us/step - loss: 8.8727 - acc: 0.4465 - val_loss: 9.3015 - val_acc: 0.4198\n",
      "Epoch 27/150\n",
      "1458/1458 [==============================] - 0s 280us/step - loss: 8.8727 - acc: 0.4465 - val_loss: 9.3015 - val_acc: 0.4198\n",
      "Epoch 28/150\n",
      "1458/1458 [==============================] - 0s 334us/step - loss: 8.8727 - acc: 0.4465 - val_loss: 9.3015 - val_acc: 0.4198\n",
      "Epoch 29/150\n",
      "1458/1458 [==============================] - 1s 374us/step - loss: 8.8727 - acc: 0.4465 - val_loss: 9.3015 - val_acc: 0.4198\n",
      "Epoch 30/150\n",
      "1458/1458 [==============================] - 1s 351us/step - loss: 8.8727 - acc: 0.4465 - val_loss: 9.3015 - val_acc: 0.4198\n",
      "Epoch 31/150\n",
      "1458/1458 [==============================] - 0s 292us/step - loss: 8.8727 - acc: 0.4465 - val_loss: 9.3015 - val_acc: 0.4198\n",
      "Epoch 32/150\n",
      "1458/1458 [==============================] - 0s 302us/step - loss: 8.8727 - acc: 0.4465 - val_loss: 9.3015 - val_acc: 0.4198\n",
      "Epoch 33/150\n",
      "1458/1458 [==============================] - 1s 395us/step - loss: 8.8727 - acc: 0.4465 - val_loss: 9.3015 - val_acc: 0.4198\n",
      "Epoch 34/150\n",
      "1458/1458 [==============================] - 0s 317us/step - loss: 8.8727 - acc: 0.4465 - val_loss: 9.3015 - val_acc: 0.4198\n",
      "Epoch 35/150\n",
      "1458/1458 [==============================] - 0s 300us/step - loss: 8.8727 - acc: 0.4465 - val_loss: 9.3015 - val_acc: 0.4198\n",
      "Epoch 36/150\n",
      "1458/1458 [==============================] - 0s 323us/step - loss: 8.8727 - acc: 0.4465 - val_loss: 9.3015 - val_acc: 0.4198\n",
      "Epoch 37/150\n",
      "1458/1458 [==============================] - 0s 300us/step - loss: 8.8727 - acc: 0.4465 - val_loss: 9.3015 - val_acc: 0.4198\n",
      "Epoch 38/150\n",
      "1458/1458 [==============================] - 0s 305us/step - loss: 8.8727 - acc: 0.4465 - val_loss: 9.3015 - val_acc: 0.4198\n",
      "Epoch 39/150\n",
      "1458/1458 [==============================] - 0s 271us/step - loss: 8.8727 - acc: 0.4465 - val_loss: 9.3015 - val_acc: 0.4198\n",
      "Epoch 40/150\n",
      "1458/1458 [==============================] - 1s 407us/step - loss: 8.8727 - acc: 0.4465 - val_loss: 9.3015 - val_acc: 0.4198\n",
      "Epoch 41/150\n",
      "1458/1458 [==============================] - 1s 428us/step - loss: 8.8727 - acc: 0.4465 - val_loss: 9.3015 - val_acc: 0.4198\n",
      "Epoch 42/150\n",
      "1458/1458 [==============================] - 1s 370us/step - loss: 8.8727 - acc: 0.4465 - val_loss: 9.3015 - val_acc: 0.4198\n",
      "Epoch 43/150\n",
      "1458/1458 [==============================] - 1s 370us/step - loss: 8.8727 - acc: 0.4465 - val_loss: 9.3015 - val_acc: 0.4198\n",
      "Epoch 44/150\n",
      "1458/1458 [==============================] - 1s 346us/step - loss: 8.8727 - acc: 0.4465 - val_loss: 9.3015 - val_acc: 0.4198\n",
      "Epoch 45/150\n",
      "1458/1458 [==============================] - 0s 334us/step - loss: 8.8727 - acc: 0.4465 - val_loss: 9.3015 - val_acc: 0.4198\n",
      "Epoch 46/150\n",
      "1458/1458 [==============================] - 0s 331us/step - loss: 8.8727 - acc: 0.4465 - val_loss: 9.3015 - val_acc: 0.4198\n",
      "Epoch 47/150\n",
      "1458/1458 [==============================] - 0s 316us/step - loss: 8.8727 - acc: 0.4465 - val_loss: 9.3015 - val_acc: 0.4198\n",
      "Epoch 48/150\n",
      "1458/1458 [==============================] - 0s 307us/step - loss: 8.8727 - acc: 0.4465 - val_loss: 9.3015 - val_acc: 0.4198\n",
      "Epoch 49/150\n",
      "1458/1458 [==============================] - 0s 337us/step - loss: 8.8727 - acc: 0.4465 - val_loss: 9.3015 - val_acc: 0.4198\n",
      "Epoch 50/150\n",
      "1458/1458 [==============================] - 0s 296us/step - loss: 8.8727 - acc: 0.4465 - val_loss: 9.3015 - val_acc: 0.4198\n",
      "Epoch 51/150\n",
      "1458/1458 [==============================] - 0s 287us/step - loss: 8.8727 - acc: 0.4465 - val_loss: 9.3015 - val_acc: 0.4198\n",
      "Epoch 52/150\n",
      "1458/1458 [==============================] - 0s 316us/step - loss: 8.8727 - acc: 0.4465 - val_loss: 9.3015 - val_acc: 0.4198\n",
      "Epoch 53/150\n",
      "1458/1458 [==============================] - 1s 397us/step - loss: 8.8727 - acc: 0.4465 - val_loss: 9.3015 - val_acc: 0.4198\n",
      "Epoch 54/150\n",
      "1458/1458 [==============================] - 0s 313us/step - loss: 8.8727 - acc: 0.4465 - val_loss: 9.3015 - val_acc: 0.4198\n",
      "Epoch 55/150\n",
      "1458/1458 [==============================] - 0s 320us/step - loss: 8.8727 - acc: 0.4465 - val_loss: 9.3015 - val_acc: 0.4198\n",
      "Epoch 56/150\n",
      "1458/1458 [==============================] - 0s 308us/step - loss: 8.8727 - acc: 0.4465 - val_loss: 9.3015 - val_acc: 0.4198\n",
      "Epoch 57/150\n",
      "1458/1458 [==============================] - 0s 320us/step - loss: 8.8727 - acc: 0.4465 - val_loss: 9.3015 - val_acc: 0.4198\n",
      "Epoch 58/150\n",
      "1458/1458 [==============================] - 0s 281us/step - loss: 8.8727 - acc: 0.4465 - val_loss: 9.3015 - val_acc: 0.4198\n",
      "Epoch 59/150\n",
      "1458/1458 [==============================] - 0s 337us/step - loss: 8.8727 - acc: 0.4465 - val_loss: 9.3015 - val_acc: 0.4198\n",
      "Epoch 60/150\n",
      "1458/1458 [==============================] - 0s 318us/step - loss: 8.8727 - acc: 0.4465 - val_loss: 9.3015 - val_acc: 0.4198\n",
      "Epoch 61/150\n",
      "1458/1458 [==============================] - 1s 352us/step - loss: 8.8727 - acc: 0.4465 - val_loss: 9.3015 - val_acc: 0.4198\n",
      "Epoch 62/150\n",
      "1458/1458 [==============================] - 0s 313us/step - loss: 8.8727 - acc: 0.4465 - val_loss: 9.3015 - val_acc: 0.4198\n",
      "Epoch 63/150\n",
      "1458/1458 [==============================] - 1s 374us/step - loss: 8.8727 - acc: 0.4465 - val_loss: 9.3015 - val_acc: 0.4198\n",
      "Epoch 64/150\n",
      "1458/1458 [==============================] - 1s 373us/step - loss: 8.8727 - acc: 0.4465 - val_loss: 9.3015 - val_acc: 0.4198\n",
      "Epoch 65/150\n",
      "1458/1458 [==============================] - 0s 311us/step - loss: 8.8727 - acc: 0.4465 - val_loss: 9.3015 - val_acc: 0.4198\n",
      "Epoch 66/150\n",
      "1458/1458 [==============================] - 0s 295us/step - loss: 8.8727 - acc: 0.4465 - val_loss: 9.3015 - val_acc: 0.4198\n",
      "Epoch 67/150\n",
      "1458/1458 [==============================] - 0s 284us/step - loss: 8.8727 - acc: 0.4465 - val_loss: 9.3015 - val_acc: 0.4198\n",
      "Epoch 68/150\n",
      "1458/1458 [==============================] - 0s 306us/step - loss: 8.8727 - acc: 0.4465 - val_loss: 9.3015 - val_acc: 0.4198\n",
      "Epoch 69/150\n",
      "1458/1458 [==============================] - 0s 327us/step - loss: 8.8727 - acc: 0.4465 - val_loss: 9.3015 - val_acc: 0.4198\n",
      "Epoch 70/150\n",
      "1458/1458 [==============================] - 0s 325us/step - loss: 8.8727 - acc: 0.4465 - val_loss: 9.3015 - val_acc: 0.4198\n",
      "Epoch 71/150\n",
      "1458/1458 [==============================] - 1s 359us/step - loss: 8.8727 - acc: 0.4465 - val_loss: 9.3015 - val_acc: 0.4198\n",
      "Epoch 72/150\n",
      "1458/1458 [==============================] - 1s 367us/step - loss: 8.8727 - acc: 0.4465 - val_loss: 9.3015 - val_acc: 0.4198\n",
      "Epoch 73/150\n",
      "1458/1458 [==============================] - 0s 324us/step - loss: 8.8727 - acc: 0.4465 - val_loss: 9.3015 - val_acc: 0.4198\n",
      "Epoch 74/150\n",
      "1458/1458 [==============================] - 0s 309us/step - loss: 8.8727 - acc: 0.4465 - val_loss: 9.3015 - val_acc: 0.4198\n",
      "Epoch 75/150\n",
      "1458/1458 [==============================] - 0s 275us/step - loss: 8.8727 - acc: 0.4465 - val_loss: 9.3015 - val_acc: 0.4198\n",
      "Epoch 76/150\n",
      "1458/1458 [==============================] - 0s 293us/step - loss: 8.8727 - acc: 0.4465 - val_loss: 9.3015 - val_acc: 0.4198\n",
      "Epoch 77/150\n",
      "1458/1458 [==============================] - 0s 333us/step - loss: 8.8727 - acc: 0.4465 - val_loss: 9.3015 - val_acc: 0.4198\n",
      "Epoch 78/150\n",
      "1458/1458 [==============================] - 0s 279us/step - loss: 8.8727 - acc: 0.4465 - val_loss: 9.3015 - val_acc: 0.4198\n",
      "Epoch 79/150\n",
      "1458/1458 [==============================] - 0s 291us/step - loss: 8.8727 - acc: 0.4465 - val_loss: 9.3015 - val_acc: 0.4198\n",
      "Epoch 80/150\n",
      "1458/1458 [==============================] - 0s 322us/step - loss: 8.8727 - acc: 0.4465 - val_loss: 9.3015 - val_acc: 0.4198\n",
      "Epoch 81/150\n",
      "1458/1458 [==============================] - 1s 373us/step - loss: 8.8727 - acc: 0.4465 - val_loss: 9.3015 - val_acc: 0.4198\n",
      "Epoch 82/150\n",
      "1458/1458 [==============================] - 1s 389us/step - loss: 8.8727 - acc: 0.4465 - val_loss: 9.3015 - val_acc: 0.4198\n",
      "Epoch 83/150\n",
      "1458/1458 [==============================] - 0s 336us/step - loss: 8.8727 - acc: 0.4465 - val_loss: 9.3015 - val_acc: 0.4198\n",
      "Epoch 84/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1458/1458 [==============================] - 1s 360us/step - loss: 8.8727 - acc: 0.4465 - val_loss: 9.3015 - val_acc: 0.4198\n",
      "Epoch 85/150\n",
      "1458/1458 [==============================] - 0s 321us/step - loss: 8.8727 - acc: 0.4465 - val_loss: 9.3015 - val_acc: 0.4198\n",
      "Epoch 86/150\n",
      "1458/1458 [==============================] - 0s 328us/step - loss: 8.8727 - acc: 0.4465 - val_loss: 9.3015 - val_acc: 0.4198\n",
      "Epoch 87/150\n",
      "1458/1458 [==============================] - 0s 331us/step - loss: 8.8727 - acc: 0.4465 - val_loss: 9.3015 - val_acc: 0.4198\n",
      "Epoch 88/150\n",
      "1458/1458 [==============================] - 0s 325us/step - loss: 8.8727 - acc: 0.4465 - val_loss: 9.3015 - val_acc: 0.4198\n",
      "Epoch 89/150\n",
      "1458/1458 [==============================] - 0s 303us/step - loss: 8.8727 - acc: 0.4465 - val_loss: 9.3015 - val_acc: 0.4198\n",
      "Epoch 90/150\n",
      "1458/1458 [==============================] - 0s 296us/step - loss: 8.8727 - acc: 0.4465 - val_loss: 9.3015 - val_acc: 0.4198\n",
      "Epoch 91/150\n",
      "1458/1458 [==============================] - 1s 378us/step - loss: 8.8727 - acc: 0.4465 - val_loss: 9.3015 - val_acc: 0.4198\n",
      "Epoch 92/150\n",
      "1458/1458 [==============================] - 0s 259us/step - loss: 8.8727 - acc: 0.4465 - val_loss: 9.3015 - val_acc: 0.4198\n",
      "Epoch 93/150\n",
      "1458/1458 [==============================] - 0s 258us/step - loss: 8.8727 - acc: 0.4465 - val_loss: 9.3015 - val_acc: 0.4198\n",
      "Epoch 94/150\n",
      "1458/1458 [==============================] - 0s 307us/step - loss: 8.8727 - acc: 0.4465 - val_loss: 9.3015 - val_acc: 0.4198\n",
      "Epoch 95/150\n",
      "1458/1458 [==============================] - 0s 322us/step - loss: 8.8727 - acc: 0.4465 - val_loss: 9.3015 - val_acc: 0.4198\n",
      "Epoch 96/150\n",
      "1458/1458 [==============================] - 0s 295us/step - loss: 8.8727 - acc: 0.4465 - val_loss: 9.3015 - val_acc: 0.4198\n",
      "Epoch 97/150\n",
      "1458/1458 [==============================] - 0s 265us/step - loss: 8.8727 - acc: 0.4465 - val_loss: 9.3015 - val_acc: 0.4198\n",
      "Epoch 98/150\n",
      "1458/1458 [==============================] - 0s 335us/step - loss: 8.8727 - acc: 0.4465 - val_loss: 9.3015 - val_acc: 0.4198\n",
      "Epoch 99/150\n",
      "1458/1458 [==============================] - 0s 264us/step - loss: 8.8727 - acc: 0.4465 - val_loss: 9.3015 - val_acc: 0.4198\n",
      "Epoch 100/150\n",
      "1458/1458 [==============================] - 0s 336us/step - loss: 8.8727 - acc: 0.4465 - val_loss: 9.3015 - val_acc: 0.4198\n",
      "Epoch 101/150\n",
      "1458/1458 [==============================] - 1s 345us/step - loss: 8.8727 - acc: 0.4465 - val_loss: 9.3015 - val_acc: 0.4198\n",
      "Epoch 102/150\n",
      "1458/1458 [==============================] - 1s 360us/step - loss: 8.8727 - acc: 0.4465 - val_loss: 9.3015 - val_acc: 0.4198\n",
      "Epoch 103/150\n",
      "1458/1458 [==============================] - 0s 304us/step - loss: 8.8727 - acc: 0.4465 - val_loss: 9.3015 - val_acc: 0.4198\n",
      "Epoch 104/150\n",
      "1458/1458 [==============================] - 1s 399us/step - loss: 8.8727 - acc: 0.4465 - val_loss: 9.3015 - val_acc: 0.4198\n",
      "Epoch 105/150\n",
      "1458/1458 [==============================] - 1s 386us/step - loss: 8.8727 - acc: 0.4465 - val_loss: 9.3015 - val_acc: 0.4198\n",
      "Epoch 106/150\n",
      "1458/1458 [==============================] - 1s 361us/step - loss: 8.8727 - acc: 0.4465 - val_loss: 9.3015 - val_acc: 0.4198\n",
      "Epoch 107/150\n",
      "1458/1458 [==============================] - 1s 349us/step - loss: 8.8727 - acc: 0.4465 - val_loss: 9.3015 - val_acc: 0.4198\n",
      "Epoch 108/150\n",
      "1458/1458 [==============================] - 0s 330us/step - loss: 8.8727 - acc: 0.4465 - val_loss: 9.3015 - val_acc: 0.4198\n",
      "Epoch 109/150\n",
      "1458/1458 [==============================] - 0s 342us/step - loss: 8.8727 - acc: 0.4465 - val_loss: 9.3015 - val_acc: 0.4198\n",
      "Epoch 110/150\n",
      "1458/1458 [==============================] - 1s 374us/step - loss: 8.8727 - acc: 0.4465 - val_loss: 9.3015 - val_acc: 0.4198\n",
      "Epoch 111/150\n",
      "1458/1458 [==============================] - 1s 370us/step - loss: 8.8727 - acc: 0.4465 - val_loss: 9.3015 - val_acc: 0.4198\n",
      "Epoch 112/150\n",
      "1458/1458 [==============================] - 1s 378us/step - loss: 8.8727 - acc: 0.4465 - val_loss: 9.3015 - val_acc: 0.4198\n",
      "Epoch 113/150\n",
      "1458/1458 [==============================] - 0s 317us/step - loss: 8.8727 - acc: 0.4465 - val_loss: 9.3015 - val_acc: 0.4198\n",
      "Epoch 114/150\n",
      "1458/1458 [==============================] - 1s 357us/step - loss: 8.8727 - acc: 0.4465 - val_loss: 9.3015 - val_acc: 0.4198\n",
      "Epoch 115/150\n",
      "1458/1458 [==============================] - 0s 332us/step - loss: 8.8727 - acc: 0.4465 - val_loss: 9.3015 - val_acc: 0.4198\n",
      "Epoch 116/150\n",
      "1458/1458 [==============================] - 0s 315us/step - loss: 8.8727 - acc: 0.4465 - val_loss: 9.3015 - val_acc: 0.4198\n",
      "Epoch 117/150\n",
      "1458/1458 [==============================] - 0s 312us/step - loss: 8.8727 - acc: 0.4465 - val_loss: 9.3015 - val_acc: 0.4198\n",
      "Epoch 118/150\n",
      "1458/1458 [==============================] - 1s 382us/step - loss: 8.8727 - acc: 0.4465 - val_loss: 9.3015 - val_acc: 0.4198\n",
      "Epoch 119/150\n",
      "1458/1458 [==============================] - 0s 341us/step - loss: 8.8727 - acc: 0.4465 - val_loss: 9.3015 - val_acc: 0.4198\n",
      "Epoch 120/150\n",
      "1458/1458 [==============================] - 1s 366us/step - loss: 8.8727 - acc: 0.4465 - val_loss: 9.3015 - val_acc: 0.4198\n",
      "Epoch 121/150\n",
      "1458/1458 [==============================] - 0s 298us/step - loss: 8.8727 - acc: 0.4465 - val_loss: 9.3015 - val_acc: 0.4198\n",
      "Epoch 122/150\n",
      "1458/1458 [==============================] - 0s 339us/step - loss: 8.8727 - acc: 0.4465 - val_loss: 9.3015 - val_acc: 0.4198\n",
      "Epoch 123/150\n",
      "1458/1458 [==============================] - 0s 299us/step - loss: 8.8727 - acc: 0.4465 - val_loss: 9.3015 - val_acc: 0.4198\n",
      "Epoch 124/150\n",
      "1458/1458 [==============================] - 0s 327us/step - loss: 8.8727 - acc: 0.4465 - val_loss: 9.3015 - val_acc: 0.4198\n",
      "Epoch 125/150\n",
      "1458/1458 [==============================] - 0s 282us/step - loss: 8.8727 - acc: 0.4465 - val_loss: 9.3015 - val_acc: 0.4198\n",
      "Epoch 126/150\n",
      "1458/1458 [==============================] - 0s 319us/step - loss: 8.8727 - acc: 0.4465 - val_loss: 9.3015 - val_acc: 0.4198\n",
      "Epoch 127/150\n",
      "1458/1458 [==============================] - 0s 283us/step - loss: 8.8727 - acc: 0.4465 - val_loss: 9.3015 - val_acc: 0.4198\n",
      "Epoch 128/150\n",
      "1458/1458 [==============================] - 1s 348us/step - loss: 8.8727 - acc: 0.4465 - val_loss: 9.3015 - val_acc: 0.4198\n",
      "Epoch 129/150\n",
      "1458/1458 [==============================] - 0s 311us/step - loss: 8.8727 - acc: 0.4465 - val_loss: 9.3015 - val_acc: 0.4198\n",
      "Epoch 130/150\n",
      "1458/1458 [==============================] - 1s 434us/step - loss: 8.8727 - acc: 0.4465 - val_loss: 9.3015 - val_acc: 0.4198\n",
      "Epoch 131/150\n",
      "1458/1458 [==============================] - 1s 347us/step - loss: 8.8727 - acc: 0.4465 - val_loss: 9.3015 - val_acc: 0.4198\n",
      "Epoch 132/150\n",
      "1458/1458 [==============================] - 0s 328us/step - loss: 8.8727 - acc: 0.4465 - val_loss: 9.3015 - val_acc: 0.4198\n",
      "Epoch 133/150\n",
      "1458/1458 [==============================] - 0s 338us/step - loss: 8.8727 - acc: 0.4465 - val_loss: 9.3015 - val_acc: 0.4198\n",
      "Epoch 134/150\n",
      "1458/1458 [==============================] - 0s 311us/step - loss: 8.8727 - acc: 0.4465 - val_loss: 9.3015 - val_acc: 0.4198\n",
      "Epoch 135/150\n",
      "1458/1458 [==============================] - 0s 303us/step - loss: 8.8727 - acc: 0.4465 - val_loss: 9.3015 - val_acc: 0.4198\n",
      "Epoch 136/150\n",
      "1458/1458 [==============================] - 0s 326us/step - loss: 8.8727 - acc: 0.4465 - val_loss: 9.3015 - val_acc: 0.4198\n",
      "Epoch 137/150\n",
      "1458/1458 [==============================] - 0s 295us/step - loss: 8.8727 - acc: 0.4465 - val_loss: 9.3015 - val_acc: 0.4198\n",
      "Epoch 138/150\n",
      "1458/1458 [==============================] - 1s 350us/step - loss: 8.8727 - acc: 0.4465 - val_loss: 9.3015 - val_acc: 0.4198\n",
      "Epoch 139/150\n",
      "1458/1458 [==============================] - 0s 335us/step - loss: 8.8727 - acc: 0.4465 - val_loss: 9.3015 - val_acc: 0.4198\n",
      "Epoch 140/150\n",
      "1458/1458 [==============================] - 1s 465us/step - loss: 8.8727 - acc: 0.4465 - val_loss: 9.3015 - val_acc: 0.4198\n",
      "Epoch 141/150\n",
      "1458/1458 [==============================] - 0s 335us/step - loss: 8.8727 - acc: 0.4465 - val_loss: 9.3015 - val_acc: 0.4198\n",
      "Epoch 142/150\n",
      "1458/1458 [==============================] - 0s 324us/step - loss: 8.8727 - acc: 0.4465 - val_loss: 9.3015 - val_acc: 0.4198\n",
      "Epoch 143/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1458/1458 [==============================] - 1s 344us/step - loss: 8.8727 - acc: 0.4465 - val_loss: 9.3015 - val_acc: 0.4198\n",
      "Epoch 144/150\n",
      "1458/1458 [==============================] - 0s 273us/step - loss: 8.8727 - acc: 0.4465 - val_loss: 9.3015 - val_acc: 0.4198\n",
      "Epoch 145/150\n",
      "1458/1458 [==============================] - 0s 296us/step - loss: 8.8727 - acc: 0.4465 - val_loss: 9.3015 - val_acc: 0.4198\n",
      "Epoch 146/150\n",
      "1458/1458 [==============================] - 0s 245us/step - loss: 8.8727 - acc: 0.4465 - val_loss: 9.3015 - val_acc: 0.4198\n",
      "Epoch 147/150\n",
      "1458/1458 [==============================] - 0s 298us/step - loss: 8.8727 - acc: 0.4465 - val_loss: 9.3015 - val_acc: 0.4198\n",
      "Epoch 148/150\n",
      "1458/1458 [==============================] - 0s 272us/step - loss: 8.8727 - acc: 0.4465 - val_loss: 9.3015 - val_acc: 0.4198\n",
      "Epoch 149/150\n",
      "1458/1458 [==============================] - 1s 353us/step - loss: 8.8727 - acc: 0.4465 - val_loss: 9.3015 - val_acc: 0.4198\n",
      "Epoch 150/150\n",
      "1458/1458 [==============================] - 0s 311us/step - loss: 8.8727 - acc: 0.4465 - val_loss: 9.3015 - val_acc: 0.4198\n",
      "The score is......\n",
      " [9.301496624828019, 0.41975308641975306]\n",
      "Compute bottleneck features...\n",
      "train_bNFeatures[img].shape =  (1458, 73728)\n",
      "val_bNFeatures[img].shape =  (162, 73728)\n",
      "Train head...\n",
      "Train on 1458 samples, validate on 162 samples\n",
      "Epoch 1/150\n",
      "1458/1458 [==============================] - 1s 609us/step - loss: 8.3053 - acc: 0.4568 - val_loss: 9.2025 - val_acc: 0.4259\n",
      "Epoch 2/150\n",
      "1458/1458 [==============================] - 1s 350us/step - loss: 8.8837 - acc: 0.4458 - val_loss: 9.2025 - val_acc: 0.4259\n",
      "Epoch 3/150\n",
      "1458/1458 [==============================] - 0s 337us/step - loss: 8.8837 - acc: 0.4458 - val_loss: 9.2025 - val_acc: 0.4259\n",
      "Epoch 4/150\n",
      "1458/1458 [==============================] - 0s 329us/step - loss: 8.8837 - acc: 0.4458 - val_loss: 9.2025 - val_acc: 0.4259\n",
      "Epoch 5/150\n",
      "1458/1458 [==============================] - 0s 333us/step - loss: 8.8837 - acc: 0.4458 - val_loss: 9.2025 - val_acc: 0.4259\n",
      "Epoch 6/150\n",
      "1458/1458 [==============================] - 0s 324us/step - loss: 8.8837 - acc: 0.4458 - val_loss: 9.2025 - val_acc: 0.4259\n",
      "Epoch 7/150\n",
      "1458/1458 [==============================] - 0s 335us/step - loss: 8.8837 - acc: 0.4458 - val_loss: 9.2025 - val_acc: 0.4259\n",
      "Epoch 8/150\n",
      "1458/1458 [==============================] - 1s 403us/step - loss: 8.8837 - acc: 0.4458 - val_loss: 9.2025 - val_acc: 0.4259\n",
      "Epoch 9/150\n",
      "1458/1458 [==============================] - 1s 438us/step - loss: 8.8837 - acc: 0.4458 - val_loss: 9.2025 - val_acc: 0.4259\n",
      "Epoch 10/150\n",
      "1458/1458 [==============================] - 1s 359us/step - loss: 8.8837 - acc: 0.4458 - val_loss: 9.2025 - val_acc: 0.4259\n",
      "Epoch 11/150\n",
      "1458/1458 [==============================] - 1s 364us/step - loss: 8.8837 - acc: 0.4458 - val_loss: 9.2025 - val_acc: 0.4259\n",
      "Epoch 12/150\n",
      "1458/1458 [==============================] - 0s 333us/step - loss: 8.8837 - acc: 0.4458 - val_loss: 9.2025 - val_acc: 0.4259\n",
      "Epoch 13/150\n",
      "1458/1458 [==============================] - 1s 344us/step - loss: 8.8837 - acc: 0.4458 - val_loss: 9.2025 - val_acc: 0.4259\n",
      "Epoch 14/150\n",
      "1458/1458 [==============================] - 0s 316us/step - loss: 8.8837 - acc: 0.4458 - val_loss: 9.2025 - val_acc: 0.4259\n",
      "Epoch 15/150\n",
      "1458/1458 [==============================] - 0s 304us/step - loss: 8.8837 - acc: 0.4458 - val_loss: 9.2025 - val_acc: 0.4259\n",
      "Epoch 16/150\n",
      "1458/1458 [==============================] - 0s 325us/step - loss: 8.8837 - acc: 0.4458 - val_loss: 9.2025 - val_acc: 0.4259\n",
      "Epoch 17/150\n",
      "1458/1458 [==============================] - 0s 291us/step - loss: 8.8837 - acc: 0.4458 - val_loss: 9.2025 - val_acc: 0.4259\n",
      "Epoch 18/150\n",
      "1458/1458 [==============================] - 0s 253us/step - loss: 8.8837 - acc: 0.4458 - val_loss: 9.2025 - val_acc: 0.4259\n",
      "Epoch 19/150\n",
      "1458/1458 [==============================] - 0s 310us/step - loss: 8.8837 - acc: 0.4458 - val_loss: 9.2025 - val_acc: 0.4259\n",
      "Epoch 20/150\n",
      "1458/1458 [==============================] - 0s 317us/step - loss: 8.8837 - acc: 0.4458 - val_loss: 9.2025 - val_acc: 0.4259\n",
      "Epoch 21/150\n",
      "1458/1458 [==============================] - 0s 302us/step - loss: 8.8837 - acc: 0.4458 - val_loss: 9.2025 - val_acc: 0.4259\n",
      "Epoch 22/150\n",
      "1458/1458 [==============================] - 0s 260us/step - loss: 8.8837 - acc: 0.4458 - val_loss: 9.2025 - val_acc: 0.4259\n",
      "Epoch 23/150\n",
      "1458/1458 [==============================] - 0s 274us/step - loss: 8.8837 - acc: 0.4458 - val_loss: 9.2025 - val_acc: 0.4259\n",
      "Epoch 24/150\n",
      "1458/1458 [==============================] - 0s 290us/step - loss: 8.8837 - acc: 0.4458 - val_loss: 9.2025 - val_acc: 0.4259\n",
      "Epoch 25/150\n",
      "1458/1458 [==============================] - 0s 292us/step - loss: 8.8837 - acc: 0.4458 - val_loss: 9.2025 - val_acc: 0.4259\n",
      "Epoch 26/150\n",
      "1458/1458 [==============================] - 0s 269us/step - loss: 8.8837 - acc: 0.4458 - val_loss: 9.2025 - val_acc: 0.4259\n",
      "Epoch 27/150\n",
      "1458/1458 [==============================] - 0s 316us/step - loss: 8.8837 - acc: 0.4458 - val_loss: 9.2025 - val_acc: 0.4259\n",
      "Epoch 28/150\n",
      "1458/1458 [==============================] - 0s 301us/step - loss: 8.8837 - acc: 0.4458 - val_loss: 9.2025 - val_acc: 0.4259\n",
      "Epoch 29/150\n",
      "1458/1458 [==============================] - 1s 388us/step - loss: 8.8837 - acc: 0.4458 - val_loss: 9.2025 - val_acc: 0.4259\n",
      "Epoch 30/150\n",
      "1458/1458 [==============================] - 0s 338us/step - loss: 8.8837 - acc: 0.4458 - val_loss: 9.2025 - val_acc: 0.4259\n",
      "Epoch 31/150\n",
      "1458/1458 [==============================] - 0s 313us/step - loss: 8.8837 - acc: 0.4458 - val_loss: 9.2025 - val_acc: 0.4259\n",
      "Epoch 32/150\n",
      "1458/1458 [==============================] - 0s 302us/step - loss: 8.8837 - acc: 0.4458 - val_loss: 9.2025 - val_acc: 0.4259\n",
      "Epoch 33/150\n",
      "1458/1458 [==============================] - 1s 424us/step - loss: 8.8837 - acc: 0.4458 - val_loss: 9.2025 - val_acc: 0.4259\n",
      "Epoch 34/150\n",
      "1458/1458 [==============================] - 0s 312us/step - loss: 8.8837 - acc: 0.4458 - val_loss: 9.2025 - val_acc: 0.4259\n",
      "Epoch 35/150\n",
      "1458/1458 [==============================] - 0s 316us/step - loss: 8.8837 - acc: 0.4458 - val_loss: 9.2025 - val_acc: 0.4259\n",
      "Epoch 36/150\n",
      "1458/1458 [==============================] - 0s 315us/step - loss: 8.8837 - acc: 0.4458 - val_loss: 9.2025 - val_acc: 0.4259\n",
      "Epoch 37/150\n",
      "1458/1458 [==============================] - 1s 350us/step - loss: 8.8837 - acc: 0.4458 - val_loss: 9.2025 - val_acc: 0.4259\n",
      "Epoch 38/150\n",
      "1458/1458 [==============================] - 0s 327us/step - loss: 8.8837 - acc: 0.4458 - val_loss: 9.2025 - val_acc: 0.4259\n",
      "Epoch 39/150\n",
      "1458/1458 [==============================] - 0s 317us/step - loss: 8.8837 - acc: 0.4458 - val_loss: 9.2025 - val_acc: 0.4259\n",
      "Epoch 40/150\n",
      "1458/1458 [==============================] - 0s 274us/step - loss: 8.8837 - acc: 0.4458 - val_loss: 9.2025 - val_acc: 0.4259\n",
      "Epoch 41/150\n",
      "1458/1458 [==============================] - 0s 250us/step - loss: 8.8837 - acc: 0.4458 - val_loss: 9.2025 - val_acc: 0.4259\n",
      "Epoch 42/150\n",
      "1458/1458 [==============================] - 0s 280us/step - loss: 8.8837 - acc: 0.4458 - val_loss: 9.2025 - val_acc: 0.4259\n",
      "Epoch 43/150\n",
      "1458/1458 [==============================] - 0s 316us/step - loss: 8.8837 - acc: 0.4458 - val_loss: 9.2025 - val_acc: 0.4259\n",
      "Epoch 44/150\n",
      "1458/1458 [==============================] - 0s 295us/step - loss: 8.8837 - acc: 0.4458 - val_loss: 9.2025 - val_acc: 0.4259\n",
      "Epoch 45/150\n",
      "1458/1458 [==============================] - 0s 301us/step - loss: 8.8837 - acc: 0.4458 - val_loss: 9.2025 - val_acc: 0.4259\n",
      "Epoch 46/150\n",
      "1458/1458 [==============================] - 0s 280us/step - loss: 8.8837 - acc: 0.4458 - val_loss: 9.2025 - val_acc: 0.4259\n",
      "Epoch 47/150\n",
      "1458/1458 [==============================] - 0s 294us/step - loss: 8.8837 - acc: 0.4458 - val_loss: 9.2025 - val_acc: 0.4259\n",
      "Epoch 48/150\n",
      "1458/1458 [==============================] - 0s 282us/step - loss: 8.8837 - acc: 0.4458 - val_loss: 9.2025 - val_acc: 0.4259\n",
      "Epoch 49/150\n",
      "1458/1458 [==============================] - 0s 336us/step - loss: 8.8837 - acc: 0.4458 - val_loss: 9.2025 - val_acc: 0.4259\n",
      "Epoch 50/150\n",
      "1458/1458 [==============================] - 0s 280us/step - loss: 8.8837 - acc: 0.4458 - val_loss: 9.2025 - val_acc: 0.4259\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 51/150\n",
      "1458/1458 [==============================] - 0s 247us/step - loss: 8.8837 - acc: 0.4458 - val_loss: 9.2025 - val_acc: 0.4259\n",
      "Epoch 52/150\n",
      "1458/1458 [==============================] - 0s 309us/step - loss: 8.8837 - acc: 0.4458 - val_loss: 9.2025 - val_acc: 0.4259\n",
      "Epoch 53/150\n",
      "1458/1458 [==============================] - 0s 295us/step - loss: 8.8837 - acc: 0.4458 - val_loss: 9.2025 - val_acc: 0.4259\n",
      "Epoch 54/150\n",
      "1458/1458 [==============================] - 0s 283us/step - loss: 8.8837 - acc: 0.4458 - val_loss: 9.2025 - val_acc: 0.4259\n",
      "Epoch 55/150\n",
      "1458/1458 [==============================] - 0s 324us/step - loss: 8.8837 - acc: 0.4458 - val_loss: 9.2025 - val_acc: 0.4259\n",
      "Epoch 56/150\n",
      "1458/1458 [==============================] - 0s 260us/step - loss: 8.8837 - acc: 0.4458 - val_loss: 9.2025 - val_acc: 0.4259\n",
      "Epoch 57/150\n",
      "1458/1458 [==============================] - 0s 248us/step - loss: 8.8837 - acc: 0.4458 - val_loss: 9.2025 - val_acc: 0.4259\n",
      "Epoch 58/150\n",
      "1458/1458 [==============================] - 0s 293us/step - loss: 8.8837 - acc: 0.4458 - val_loss: 9.2025 - val_acc: 0.4259\n",
      "Epoch 59/150\n",
      "1458/1458 [==============================] - 0s 244us/step - loss: 8.8837 - acc: 0.4458 - val_loss: 9.2025 - val_acc: 0.4259\n",
      "Epoch 60/150\n",
      "1458/1458 [==============================] - 0s 247us/step - loss: 8.8837 - acc: 0.4458 - val_loss: 9.2025 - val_acc: 0.4259\n",
      "Epoch 61/150\n",
      "1458/1458 [==============================] - 0s 304us/step - loss: 8.8837 - acc: 0.4458 - val_loss: 9.2025 - val_acc: 0.4259\n",
      "Epoch 62/150\n",
      "1458/1458 [==============================] - 0s 322us/step - loss: 8.8837 - acc: 0.4458 - val_loss: 9.2025 - val_acc: 0.4259\n",
      "Epoch 63/150\n",
      "1458/1458 [==============================] - 0s 311us/step - loss: 8.8837 - acc: 0.4458 - val_loss: 9.2025 - val_acc: 0.4259\n",
      "Epoch 64/150\n",
      "1458/1458 [==============================] - 0s 282us/step - loss: 8.8837 - acc: 0.4458 - val_loss: 9.2025 - val_acc: 0.4259\n",
      "Epoch 65/150\n",
      "1458/1458 [==============================] - 0s 312us/step - loss: 8.8837 - acc: 0.4458 - val_loss: 9.2025 - val_acc: 0.4259\n",
      "Epoch 66/150\n",
      "1458/1458 [==============================] - 1s 345us/step - loss: 8.8837 - acc: 0.4458 - val_loss: 9.2025 - val_acc: 0.4259\n",
      "Epoch 67/150\n",
      "1458/1458 [==============================] - 1s 381us/step - loss: 8.8837 - acc: 0.4458 - val_loss: 9.2025 - val_acc: 0.4259\n",
      "Epoch 68/150\n",
      "1458/1458 [==============================] - 0s 277us/step - loss: 8.8837 - acc: 0.4458 - val_loss: 9.2025 - val_acc: 0.4259\n",
      "Epoch 69/150\n",
      "1458/1458 [==============================] - 0s 310us/step - loss: 8.8837 - acc: 0.4458 - val_loss: 9.2025 - val_acc: 0.4259\n",
      "Epoch 70/150\n",
      "1458/1458 [==============================] - 0s 337us/step - loss: 8.8837 - acc: 0.4458 - val_loss: 9.2025 - val_acc: 0.4259\n",
      "Epoch 71/150\n",
      "1458/1458 [==============================] - 0s 330us/step - loss: 8.8837 - acc: 0.4458 - val_loss: 9.2025 - val_acc: 0.4259\n",
      "Epoch 72/150\n",
      "1458/1458 [==============================] - 1s 357us/step - loss: 8.8837 - acc: 0.4458 - val_loss: 9.2025 - val_acc: 0.4259\n",
      "Epoch 73/150\n",
      "1458/1458 [==============================] - 0s 325us/step - loss: 8.8837 - acc: 0.4458 - val_loss: 9.2025 - val_acc: 0.4259\n",
      "Epoch 74/150\n",
      "1458/1458 [==============================] - 0s 303us/step - loss: 8.8837 - acc: 0.4458 - val_loss: 9.2025 - val_acc: 0.4259\n",
      "Epoch 75/150\n",
      "1458/1458 [==============================] - 0s 336us/step - loss: 8.8837 - acc: 0.4458 - val_loss: 9.2025 - val_acc: 0.4259\n",
      "Epoch 76/150\n",
      "1458/1458 [==============================] - 0s 304us/step - loss: 8.8837 - acc: 0.4458 - val_loss: 9.2025 - val_acc: 0.4259\n",
      "Epoch 77/150\n",
      "1458/1458 [==============================] - 0s 318us/step - loss: 8.8837 - acc: 0.4458 - val_loss: 9.2025 - val_acc: 0.4259\n",
      "Epoch 78/150\n",
      "1458/1458 [==============================] - 0s 259us/step - loss: 8.8837 - acc: 0.4458 - val_loss: 9.2025 - val_acc: 0.4259\n",
      "Epoch 79/150\n",
      "1458/1458 [==============================] - 0s 298us/step - loss: 8.8837 - acc: 0.4458 - val_loss: 9.2025 - val_acc: 0.4259\n",
      "Epoch 80/150\n",
      "1458/1458 [==============================] - 0s 326us/step - loss: 8.8837 - acc: 0.4458 - val_loss: 9.2025 - val_acc: 0.4259\n",
      "Epoch 81/150\n",
      "1458/1458 [==============================] - 0s 298us/step - loss: 8.8837 - acc: 0.4458 - val_loss: 9.2025 - val_acc: 0.4259\n",
      "Epoch 82/150\n",
      "1458/1458 [==============================] - 0s 245us/step - loss: 8.8837 - acc: 0.4458 - val_loss: 9.2025 - val_acc: 0.4259\n",
      "Epoch 83/150\n",
      "1458/1458 [==============================] - 0s 335us/step - loss: 8.8837 - acc: 0.4458 - val_loss: 9.2025 - val_acc: 0.4259\n",
      "Epoch 84/150\n",
      "1458/1458 [==============================] - 0s 261us/step - loss: 8.8837 - acc: 0.4458 - val_loss: 9.2025 - val_acc: 0.4259\n",
      "Epoch 85/150\n",
      "1458/1458 [==============================] - 0s 278us/step - loss: 8.8837 - acc: 0.4458 - val_loss: 9.2025 - val_acc: 0.4259\n",
      "Epoch 86/150\n",
      "1458/1458 [==============================] - 0s 330us/step - loss: 8.8837 - acc: 0.4458 - val_loss: 9.2025 - val_acc: 0.4259\n",
      "Epoch 87/150\n",
      "1458/1458 [==============================] - 0s 316us/step - loss: 8.8837 - acc: 0.4458 - val_loss: 9.2025 - val_acc: 0.4259\n",
      "Epoch 88/150\n",
      "1458/1458 [==============================] - 0s 290us/step - loss: 8.8837 - acc: 0.4458 - val_loss: 9.2025 - val_acc: 0.4259\n",
      "Epoch 89/150\n",
      "1458/1458 [==============================] - 1s 349us/step - loss: 8.8837 - acc: 0.4458 - val_loss: 9.2025 - val_acc: 0.4259\n",
      "Epoch 90/150\n",
      "1458/1458 [==============================] - 1s 403us/step - loss: 8.8837 - acc: 0.4458 - val_loss: 9.2025 - val_acc: 0.4259\n",
      "Epoch 91/150\n",
      "1458/1458 [==============================] - 1s 376us/step - loss: 8.8837 - acc: 0.4458 - val_loss: 9.2025 - val_acc: 0.4259\n",
      "Epoch 92/150\n",
      "1458/1458 [==============================] - 1s 350us/step - loss: 8.8837 - acc: 0.4458 - val_loss: 9.2025 - val_acc: 0.4259\n",
      "Epoch 93/150\n",
      "1458/1458 [==============================] - 0s 317us/step - loss: 8.8837 - acc: 0.4458 - val_loss: 9.2025 - val_acc: 0.4259\n",
      "Epoch 94/150\n",
      "1458/1458 [==============================] - 0s 302us/step - loss: 8.8837 - acc: 0.4458 - val_loss: 9.2025 - val_acc: 0.4259\n",
      "Epoch 95/150\n",
      "1458/1458 [==============================] - 1s 348us/step - loss: 8.8837 - acc: 0.4458 - val_loss: 9.2025 - val_acc: 0.4259\n",
      "Epoch 96/150\n",
      "1458/1458 [==============================] - 0s 286us/step - loss: 8.8837 - acc: 0.4458 - val_loss: 9.2025 - val_acc: 0.4259\n",
      "Epoch 97/150\n",
      "1458/1458 [==============================] - 0s 285us/step - loss: 8.8837 - acc: 0.4458 - val_loss: 9.2025 - val_acc: 0.4259\n",
      "Epoch 98/150\n",
      "1458/1458 [==============================] - 0s 322us/step - loss: 8.8837 - acc: 0.4458 - val_loss: 9.2025 - val_acc: 0.4259\n",
      "Epoch 99/150\n",
      "1458/1458 [==============================] - 0s 323us/step - loss: 8.8837 - acc: 0.4458 - val_loss: 9.2025 - val_acc: 0.4259\n",
      "Epoch 100/150\n",
      "1458/1458 [==============================] - 0s 322us/step - loss: 8.8837 - acc: 0.4458 - val_loss: 9.2025 - val_acc: 0.4259\n",
      "Epoch 101/150\n",
      "1458/1458 [==============================] - 0s 336us/step - loss: 8.8837 - acc: 0.4458 - val_loss: 9.2025 - val_acc: 0.4259\n",
      "Epoch 102/150\n",
      "1458/1458 [==============================] - 1s 355us/step - loss: 8.8837 - acc: 0.4458 - val_loss: 9.2025 - val_acc: 0.4259\n",
      "Epoch 103/150\n",
      "1458/1458 [==============================] - 1s 362us/step - loss: 8.8837 - acc: 0.4458 - val_loss: 9.2025 - val_acc: 0.4259\n",
      "Epoch 104/150\n",
      "1458/1458 [==============================] - 1s 559us/step - loss: 8.8837 - acc: 0.4458 - val_loss: 9.2025 - val_acc: 0.4259\n",
      "Epoch 105/150\n",
      "1458/1458 [==============================] - 0s 282us/step - loss: 8.8837 - acc: 0.4458 - val_loss: 9.2025 - val_acc: 0.4259\n",
      "Epoch 106/150\n",
      "1458/1458 [==============================] - 0s 324us/step - loss: 8.8837 - acc: 0.4458 - val_loss: 9.2025 - val_acc: 0.4259\n",
      "Epoch 107/150\n",
      "1458/1458 [==============================] - 1s 349us/step - loss: 8.8837 - acc: 0.4458 - val_loss: 9.2025 - val_acc: 0.4259\n",
      "Epoch 108/150\n",
      "1458/1458 [==============================] - 0s 328us/step - loss: 8.8837 - acc: 0.4458 - val_loss: 9.2025 - val_acc: 0.4259\n",
      "Epoch 109/150\n",
      "1458/1458 [==============================] - 0s 319us/step - loss: 8.8837 - acc: 0.4458 - val_loss: 9.2025 - val_acc: 0.4259\n",
      "Epoch 110/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1458/1458 [==============================] - 0s 323us/step - loss: 8.8837 - acc: 0.4458 - val_loss: 9.2025 - val_acc: 0.4259\n",
      "Epoch 111/150\n",
      "1458/1458 [==============================] - 0s 304us/step - loss: 8.8837 - acc: 0.4458 - val_loss: 9.2025 - val_acc: 0.4259\n",
      "Epoch 112/150\n",
      "1458/1458 [==============================] - 1s 356us/step - loss: 8.8837 - acc: 0.4458 - val_loss: 9.2025 - val_acc: 0.4259\n",
      "Epoch 113/150\n",
      "1458/1458 [==============================] - 1s 413us/step - loss: 8.8837 - acc: 0.4458 - val_loss: 9.2025 - val_acc: 0.4259\n",
      "Epoch 114/150\n",
      "1458/1458 [==============================] - 0s 319us/step - loss: 8.8837 - acc: 0.4458 - val_loss: 9.2025 - val_acc: 0.4259\n",
      "Epoch 115/150\n",
      "1458/1458 [==============================] - 1s 354us/step - loss: 8.8837 - acc: 0.4458 - val_loss: 9.2025 - val_acc: 0.4259\n",
      "Epoch 116/150\n",
      "1458/1458 [==============================] - 0s 296us/step - loss: 8.8837 - acc: 0.4458 - val_loss: 9.2025 - val_acc: 0.4259\n",
      "Epoch 117/150\n",
      "1458/1458 [==============================] - 0s 320us/step - loss: 8.8837 - acc: 0.4458 - val_loss: 9.2025 - val_acc: 0.4259\n",
      "Epoch 118/150\n",
      "1458/1458 [==============================] - 0s 312us/step - loss: 8.8837 - acc: 0.4458 - val_loss: 9.2025 - val_acc: 0.4259\n",
      "Epoch 119/150\n",
      "1458/1458 [==============================] - 0s 327us/step - loss: 8.8837 - acc: 0.4458 - val_loss: 9.2025 - val_acc: 0.4259\n",
      "Epoch 120/150\n",
      "1458/1458 [==============================] - 0s 323us/step - loss: 8.8837 - acc: 0.4458 - val_loss: 9.2025 - val_acc: 0.4259\n",
      "Epoch 121/150\n",
      "1458/1458 [==============================] - 0s 337us/step - loss: 8.8837 - acc: 0.4458 - val_loss: 9.2025 - val_acc: 0.4259\n",
      "Epoch 122/150\n",
      "1458/1458 [==============================] - 0s 332us/step - loss: 8.8837 - acc: 0.4458 - val_loss: 9.2025 - val_acc: 0.4259\n",
      "Epoch 123/150\n",
      "1458/1458 [==============================] - 0s 332us/step - loss: 8.8837 - acc: 0.4458 - val_loss: 9.2025 - val_acc: 0.4259\n",
      "Epoch 124/150\n",
      "1458/1458 [==============================] - 1s 416us/step - loss: 8.8837 - acc: 0.4458 - val_loss: 9.2025 - val_acc: 0.4259\n",
      "Epoch 125/150\n",
      "1458/1458 [==============================] - 1s 359us/step - loss: 8.8837 - acc: 0.4458 - val_loss: 9.2025 - val_acc: 0.4259\n",
      "Epoch 126/150\n",
      "1458/1458 [==============================] - 0s 343us/step - loss: 8.8837 - acc: 0.4458 - val_loss: 9.2025 - val_acc: 0.4259\n",
      "Epoch 127/150\n",
      "1458/1458 [==============================] - 0s 335us/step - loss: 8.8837 - acc: 0.4458 - val_loss: 9.2025 - val_acc: 0.4259\n",
      "Epoch 128/150\n",
      "1458/1458 [==============================] - 1s 351us/step - loss: 8.8837 - acc: 0.4458 - val_loss: 9.2025 - val_acc: 0.4259\n",
      "Epoch 129/150\n",
      "1458/1458 [==============================] - 1s 370us/step - loss: 8.8837 - acc: 0.4458 - val_loss: 9.2025 - val_acc: 0.4259\n",
      "Epoch 130/150\n",
      "1458/1458 [==============================] - 1s 488us/step - loss: 8.8837 - acc: 0.4458 - val_loss: 9.2025 - val_acc: 0.4259\n",
      "Epoch 131/150\n",
      "1458/1458 [==============================] - 0s 319us/step - loss: 8.8837 - acc: 0.4458 - val_loss: 9.2025 - val_acc: 0.4259\n",
      "Epoch 132/150\n",
      "1458/1458 [==============================] - 1s 353us/step - loss: 8.8837 - acc: 0.4458 - val_loss: 9.2025 - val_acc: 0.4259\n",
      "Epoch 133/150\n",
      "1458/1458 [==============================] - 0s 310us/step - loss: 8.8837 - acc: 0.4458 - val_loss: 9.2025 - val_acc: 0.4259\n",
      "Epoch 134/150\n",
      "1458/1458 [==============================] - 0s 322us/step - loss: 8.8837 - acc: 0.4458 - val_loss: 9.2025 - val_acc: 0.4259\n",
      "Epoch 135/150\n",
      "1458/1458 [==============================] - 0s 340us/step - loss: 8.8837 - acc: 0.4458 - val_loss: 9.2025 - val_acc: 0.4259\n",
      "Epoch 136/150\n",
      "1458/1458 [==============================] - 1s 361us/step - loss: 8.8837 - acc: 0.4458 - val_loss: 9.2025 - val_acc: 0.4259\n",
      "Epoch 137/150\n",
      "1458/1458 [==============================] - 1s 393us/step - loss: 8.8837 - acc: 0.4458 - val_loss: 9.2025 - val_acc: 0.4259\n",
      "Epoch 138/150\n",
      "1458/1458 [==============================] - 1s 383us/step - loss: 8.8837 - acc: 0.4458 - val_loss: 9.2025 - val_acc: 0.4259\n",
      "Epoch 139/150\n",
      "1458/1458 [==============================] - 0s 335us/step - loss: 8.8837 - acc: 0.4458 - val_loss: 9.2025 - val_acc: 0.4259\n",
      "Epoch 140/150\n",
      "1458/1458 [==============================] - 0s 301us/step - loss: 8.8837 - acc: 0.4458 - val_loss: 9.2025 - val_acc: 0.4259\n",
      "Epoch 141/150\n",
      "1458/1458 [==============================] - 0s 280us/step - loss: 8.8837 - acc: 0.4458 - val_loss: 9.2025 - val_acc: 0.4259\n",
      "Epoch 142/150\n",
      "1458/1458 [==============================] - 0s 330us/step - loss: 8.8837 - acc: 0.4458 - val_loss: 9.2025 - val_acc: 0.4259\n",
      "Epoch 143/150\n",
      "1458/1458 [==============================] - 0s 247us/step - loss: 8.8837 - acc: 0.4458 - val_loss: 9.2025 - val_acc: 0.4259\n",
      "Epoch 144/150\n",
      "1458/1458 [==============================] - 0s 266us/step - loss: 8.8837 - acc: 0.4458 - val_loss: 9.2025 - val_acc: 0.4259\n",
      "Epoch 145/150\n",
      "1458/1458 [==============================] - 0s 309us/step - loss: 8.8837 - acc: 0.4458 - val_loss: 9.2025 - val_acc: 0.4259\n",
      "Epoch 146/150\n",
      "1458/1458 [==============================] - 0s 327us/step - loss: 8.8837 - acc: 0.4458 - val_loss: 9.2025 - val_acc: 0.4259\n",
      "Epoch 147/150\n",
      "1458/1458 [==============================] - 0s 326us/step - loss: 8.8837 - acc: 0.4458 - val_loss: 9.2025 - val_acc: 0.4259\n",
      "Epoch 148/150\n",
      "1458/1458 [==============================] - 0s 312us/step - loss: 8.8837 - acc: 0.4458 - val_loss: 9.2025 - val_acc: 0.4259\n",
      "Epoch 149/150\n",
      "1458/1458 [==============================] - 1s 362us/step - loss: 8.8837 - acc: 0.4458 - val_loss: 9.2025 - val_acc: 0.4259\n",
      "Epoch 150/150\n",
      "1458/1458 [==============================] - 0s 328us/step - loss: 8.8837 - acc: 0.4458 - val_loss: 9.2025 - val_acc: 0.4259\n",
      "The score is......\n",
      " [9.202544742160374, 0.42592592592592593]\n",
      "Average loss:  3.4461110926544394\n",
      "Average validation:  0.6314814814814815\n"
     ]
    }
   ],
   "source": [
    "# fold\n",
    "import cv2\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.utils import np_utils\n",
    "from keras import optimizers\n",
    "# For some reason I have to tell it to use TensorFlows dimension ordering\n",
    "from keras import backend as K\n",
    "K.set_image_dim_ordering('tf')\n",
    "from keras.callbacks import TensorBoard\n",
    "from time import time\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from keras import applications\n",
    "\n",
    "class TrainValTensorBoard(TensorBoard):\n",
    "    def __init__(self, log_dir='/vol/vssp/mammo2/will/logs/new', **kwargs):\n",
    "        # Make the original `TensorBoard` log to a subdirectory 'training'\n",
    "        fCount=0\n",
    "        while os.path.exists(os.path.join(log_dir, 'training' + '_' + str(fCount))):\n",
    "            fCount+=1\n",
    "        training_log_dir = os.path.join(log_dir, 'training' + '_' + str(fCount))\n",
    "        super(TrainValTensorBoard, self).__init__(training_log_dir, **kwargs)\n",
    "\n",
    "        # Log the validation metrics to a separate subdirectory\n",
    "        self.val_log_dir = os.path.join(log_dir, 'validation' + '_' + str(fCount))\n",
    "\n",
    "    def set_model(self, model):\n",
    "        # Setup writer for validation metrics\n",
    "        self.val_writer = tf.summary.FileWriter(self.val_log_dir)\n",
    "        super(TrainValTensorBoard, self).set_model(model)\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        # Pop the validation logs and handle them separately with\n",
    "        # `self.val_writer`. Also rename the keys so that they can\n",
    "        # be plotted on the same figure with the training metrics\n",
    "        logs = logs or {}\n",
    "        val_logs = {k.replace('val_', ''): v for k, v in logs.items() if k.startswith('val_')}\n",
    "        for name, value in val_logs.items():\n",
    "            summary = tf.Summary()\n",
    "            summary_value = summary.value.add()\n",
    "            summary_value.simple_value = value.item()\n",
    "            summary_value.tag = name\n",
    "            self.val_writer.add_summary(summary, epoch)\n",
    "        self.val_writer.flush()\n",
    "\n",
    "        # Pass the remaining logs to `TensorBoard.on_epoch_end`\n",
    "        logs = {k: v for k, v in logs.items() if not k.startswith('val_')}\n",
    "        super(TrainValTensorBoard, self).on_epoch_end(epoch, logs)\n",
    "\n",
    "    def on_train_end(self, logs=None):\n",
    "        super(TrainValTensorBoard, self).on_train_end(logs)\n",
    "        self.val_writer.close()\n",
    "\n",
    "\n",
    "def get_images(path, dataSpecs):\n",
    "    fileList = glob.glob(path) #'BengaliBMPConvert/*.bmp'   \n",
    "    num = len(fileList)\n",
    "    dataSpecs['classLength'].append(len(fileList))\n",
    "    x = np.array([(cv2.imread(fname)) for fname in fileList])\n",
    "    return x\n",
    "\n",
    "def get_labels_one_hot(num_classes, class_id, num_samples):\n",
    "    x = np.zeros((num_samples, num_classes))\n",
    "    x[np.arange(num_samples),class_id] = 1\n",
    "    return x\n",
    "\n",
    "def fourCNN():\n",
    "    model = Sequential()\n",
    "    # Layer 1\n",
    "    model.add(Conv2D(32, (3,3), activation='relu', input_shape=(385, 385, 1), data_format='channels_last'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    # Layer 2\n",
    "    model.add(Conv2D(32, (3,3), activation='relu')) \n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    # Layer 3    \n",
    "    model.add(Conv2D(32, (3,3), activation='relu'))  \n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    # Layer 4     \n",
    "    model.add(Conv2D(32, (3,3), activation='relu'))   \n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))    \n",
    "    # Layer 5     \n",
    "    #model.add(Conv2D(32, (3,3), activation='relu'))   \n",
    "    #model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    # Layer 6\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1024, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(2, activation='softmax'))\n",
    "    return model\n",
    "    \n",
    "def fiveCNN():\n",
    "    model = Sequential()\n",
    "    # Layer 1\n",
    "    model.add(Conv2D(32, (3,3), activation='relu', input_shape=(385, 385, 1), data_format='channels_last'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    # Layer 2\n",
    "    model.add(Conv2D(32, (3,3), activation='relu')) \n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    # Layer 3    \n",
    "    model.add(Conv2D(32, (3,3), activation='relu'))  \n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    # Layer 4     \n",
    "    model.add(Conv2D(32, (3,3), activation='relu'))   \n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))    \n",
    "    # Layer 5     \n",
    "    model.add(Conv2D(32, (3,3), activation='relu'))   \n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    # Layer 6\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1024, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(2, activation='softmax'))  \n",
    "    return model\n",
    "    \n",
    "    \n",
    "def main():\n",
    "    import keras\n",
    "    print('keras version: ', keras.__version__)\n",
    "    print('TensorFlow version: ', tf.__version__)\n",
    "    print('\\nLoad images...')\n",
    "    \n",
    "    # Get images and labels\n",
    "    data = {'img': 0, 'label': 0}\n",
    "    dataSpecs = {'classLength': []}\n",
    "    dataSpecs['classLength'] = []\n",
    "    data['img'] = np.concatenate((\n",
    "            #get_images('/vol/vssp/mammo2/will/data/simulated/calcs/small_sample/0/*', dataSpecs), # Class 0\n",
    "            #get_images('/vol/vssp/mammo2/will/data/simulated/calcs/small_sample/1/*', dataSpecs) # Class 1\n",
    "            get_images('/user/HS204/wm0015/student/allCalcs/0/*', dataSpecs), # Class 0\n",
    "            get_images('/user/HS204/wm0015/student/allCalcs/1/*', dataSpecs) # Class 1\n",
    "    ))      \n",
    "\n",
    "    # Normalise\n",
    "    data['img'] = data['img']/255    \n",
    "    # Print image    \n",
    "    img_calc = data['img']   \n",
    "    plt.imshow(img_calc[0], cmap='gray')\n",
    "    plt.show()\n",
    "    \n",
    "    # Create one hot labels\n",
    "    labels_bg = get_labels_one_hot(2, 0, dataSpecs['classLength'][0])  \n",
    "    labels_calc = get_labels_one_hot(2, 1, dataSpecs['classLength'][1])\n",
    "    data['label'] = np.concatenate((\n",
    "            get_labels_one_hot(2, 0, dataSpecs['classLength'][0]), # Class 0 \n",
    "            get_labels_one_hot(2, 1, dataSpecs['classLength'][1]) # Class 1\n",
    "    ))\n",
    "    # Drop from 3 colour channels to 1 (greyscale)\n",
    "    if 1==0:\n",
    "        data['img'] = data['img'][:,:,:,0]\n",
    "        data['img'] = np.reshape(data['img'], (data['img'].shape[0],data['img'].shape[1],data['img'].shape[2],1))\n",
    "        print('new data shape = ', data['img'].shape)\n",
    "    \n",
    "    valStats = []\n",
    "    folds = 10\n",
    "    for crossVal in range(folds):\n",
    "\n",
    "        # Shuffle data\n",
    "        seed = 33\n",
    "    #     np.random.seed(seed) # Has to be set before each use of random\n",
    "        shuffleMask = np.random.permutation(data['img'].shape[0])    \n",
    "        data['img'] = data['img'][shuffleMask, :, :, :]\n",
    "        data['label'] = data['label'][shuffleMask, :]\n",
    "\n",
    "        # Split traing and validation data        \n",
    "        splitRatio = 0.9\n",
    "        splitPoint = math.floor(data['img'].shape[0]*splitRatio)\n",
    "        train_data = {'img': data['img'][0:splitPoint], 'label': data['label'][0:splitPoint]}\n",
    "        val_data = {'img': data['img'][splitPoint:], 'label': data['label'][splitPoint:]}\n",
    "#         print('train_data[img].shape = ', train_data['img'].shape)\n",
    "#         print('train_data[label].shape = ', train_data['label'].shape)\n",
    "#         print('val_data[img].shape = ', val_data['img'].shape)\n",
    "#         print('valdiation_data[label].shape = ', val_data['label'].shape)\n",
    "#         print('dataSpecs = ', dataSpecs['classLength'])\n",
    "\n",
    "        print('Compute bottleneck features...')\n",
    "        vggModel = applications.VGG19(weights = \"imagenet\", include_top=False, input_shape = (385, 385, 3))\n",
    "        # Freeze all layers\n",
    "        for layer in vggModel.layers:\n",
    "            layer.trainable = False\n",
    "        # Add custom final layer\n",
    "        bNModel = vggModel.output\n",
    "        bNModel = Flatten()(bNModel)\n",
    "        final_model = keras.models.Model(inputs=vggModel.input, outputs=bNModel)\n",
    "        train_bNFeatures = {'img': 0, 'label': train_data['label']}\n",
    "        val_bNFeatures = {'img': 0, 'label': val_data['label']}\n",
    "        train_bNFeatures['img'] = final_model.predict(train_data['img'], batch_size=16)\n",
    "        val_bNFeatures['img'] = final_model.predict(val_data['img'], batch_size=16)\n",
    "        print('train_bNFeatures[img].shape = ', train_bNFeatures['img'].shape)\n",
    "        print('val_bNFeatures[img].shape = ', val_bNFeatures['img'].shape)\n",
    "        \n",
    "        print('Train head...')\n",
    "        head = Sequential()\n",
    "        head.add(Dense(32, input_dim=train_bNFeatures['img'].shape[1], activation='relu'))\n",
    "        head.add(Dense(2, activation='softmax'))\n",
    "        \n",
    "        sgd = optimizers.SGD(lr=5, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "        adam = optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False) #0.001\n",
    "        head.compile(loss='binary_crossentropy',\n",
    "                    optimizer=adam,\n",
    "                     metrics=['accuracy'])\n",
    "        tensorboard = TensorBoard(log_dir='/vol/vssp/mammo2/will/logs/new'.format(time()), write_images=True)\n",
    "        if folds == 1:\n",
    "            head.summary()  \n",
    "\n",
    "        # Train\n",
    "        head.fit(train_bNFeatures['img'], train_data['label'], \n",
    "                batch_size=100, epochs=150, verbose=1,\n",
    "                callbacks=[TrainValTensorBoard(write_graph=False)],\n",
    "                validation_data=(val_bNFeatures['img'], val_bNFeatures['label']))\n",
    "\n",
    "        # Evaluate\n",
    "        score = head.evaluate(val_bNFeatures['img'], val_bNFeatures['label'], verbose=0)\n",
    "        valStats.append(score)\n",
    "        print('The score is......\\n', score)\n",
    "        \n",
    "#         model_final = keras.Model(input = model.input, output = customVgg)\n",
    "        \n",
    "\n",
    "# #         model.compile(loss='binary_crossentropy',\n",
    "# #                 optimizer=adam,\n",
    "# #                 metrics=['accuracy']) \n",
    "  \n",
    "\n",
    "    valStats = np.asarray(valStats)\n",
    "    print('Validations: \\n', valStats[:, 1])\n",
    "    print('Average loss: ', sum(valStats[:, 0])/folds)\n",
    "    print('Average validation: ', sum(valStats[:, 1])/folds)\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-13T13:58:18.045957Z",
     "start_time": "2018-07-13T13:58:18.042237Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello world\n"
     ]
    }
   ],
   "source": [
    "print('hello world')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-10T19:07:56.022196Z",
     "start_time": "2018-07-10T19:07:56.016691Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.6940992025681484, 0.3950617283950617]\n",
      "0.603475002594936\n"
     ]
    }
   ],
   "source": [
    "x = [[0.6940992025681484, 0.3950617283950617], [0.6884314866713536, 0.5185185185185185], [0.6855149121932042, 0.5679012345679012]]\n",
    "print(x[0])\n",
    "print(sum(x[:][1])/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-13T13:06:34.579475Z",
     "start_time": "2018-07-13T13:06:34.562536Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[6.53083827 0.59259259]\n",
      " [0.16470135 0.94444444]\n",
      " [0.15422182 0.94444444]\n",
      " [0.19875195 0.9382716 ]] \n",
      "\n",
      "6.5308382717179665\n",
      "[6.53083827 0.16470135 0.15422182 0.19875195]\n",
      "(4, 2)\n"
     ]
    }
   ],
   "source": [
    "x = [[6.5308382717179665, 0.5925925925925926], [0.16470135086112553, 0.9444444444444444], [0.15422181794304907, 0.9444444444444444], [0.19875195217721256, 0.9382716049382716]] \n",
    "x = np.asarray(x)\n",
    "print(x, '\\n')\n",
    "print(x[0][0])\n",
    "print(x[:, 0])\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "144px",
    "left": "1504px",
    "right": "20px",
    "top": "140px",
    "width": "350px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
