{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-07-31T19:09:32.450Z"
    },
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keras version:  2.2.0\n",
      "TensorFlow version:  1.7.1\n",
      "\n",
      "Load images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 256, 256, 3)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 256, 256, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 256, 256, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 128, 128, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 128, 128, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 128, 128, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 64, 64, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 64, 64, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 64, 64, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 64, 64, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv4 (Conv2D)        (None, 64, 64, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 32, 32, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 32, 32, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 32, 32, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 32, 32, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv4 (Conv2D)        (None, 32, 32, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 16, 16, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 16, 16, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 16, 16, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 16, 16, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv4 (Conv2D)        (None, 16, 16, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 8, 8, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 32768)             0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 2)                 65538     \n",
      "=================================================================\n",
      "Total params: 20,089,922\n",
      "Trainable params: 20,089,922\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 2673 samples, validate on 297 samples\n",
      "Epoch 1/150\n",
      "2673/2673 [==============================] - 28s 10ms/step - loss: 0.7006 - acc: 0.4729 - val_loss: 0.6932 - val_acc: 0.5320\n",
      "Epoch 2/150\n",
      "2673/2673 [==============================] - 23s 8ms/step - loss: 0.6937 - acc: 0.5021 - val_loss: 0.6929 - val_acc: 0.5455\n",
      "Epoch 3/150\n",
      "2673/2673 [==============================] - 23s 8ms/step - loss: 0.7050 - acc: 0.4927 - val_loss: 0.6938 - val_acc: 0.4545\n",
      "Epoch 4/150\n",
      "2673/2673 [==============================] - 24s 9ms/step - loss: 0.6966 - acc: 0.5088 - val_loss: 0.6934 - val_acc: 0.4545\n",
      "Epoch 5/150\n",
      "2673/2673 [==============================] - 23s 9ms/step - loss: 0.6936 - acc: 0.4946 - val_loss: 0.6941 - val_acc: 0.4545\n",
      "Epoch 6/150\n",
      "1280/2673 [=============>................] - ETA: 11s - loss: 0.6937 - acc: 0.4875"
     ]
    }
   ],
   "source": [
    "# fold\n",
    "import numpy as np\n",
    "import cv2\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "from keras.models import Sequential\n",
    "import keras\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.utils import np_utils\n",
    "from keras import optimizers\n",
    "# For some reason I have to tell it to use TensorFlows dimension ordering\n",
    "from keras import backend as K\n",
    "K.set_image_dim_ordering('tf')\n",
    "from keras.callbacks import TensorBoard\n",
    "from time import time\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from keras import applications\n",
    "from keras.utils import multi_gpu_model\n",
    "\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "config = tf.ConfigProto()\n",
    "#config.gpu_options.per_process_gpu_memory_fraction = 0.5\n",
    "config.gpu_options.visible_device_list = \"2,3\"\n",
    "config.gpu_options.allow_growth = True\n",
    "set_session(tf.Session(config=config))\n",
    "\n",
    "# Globals\n",
    "\n",
    "NORMALISE = 1\n",
    "CLASSDIR_0 = '/vol/vssp/cvpwrkspc01/scratch/wm0015/crops256/normal/*'\n",
    "CLASSDIR_1 = '/vol/vssp/cvpwrkspc01/scratch/wm0015/crops256/malignant/*'\n",
    "BATCH_SIZE = 128\n",
    "EPOCHS = 150\n",
    "INPUT_SHAPE = [256, 256, 3]\n",
    "FOLDS = 1\n",
    "\n",
    "class TrainValTensorBoard(TensorBoard):\n",
    "    def __init__(self, log_dir='/vol/vssp/mammo2/will/logs/new', **kwargs):\n",
    "        # Make the original `TensorBoard` log to a subdirectory 'training'\n",
    "        fCount=0\n",
    "        while os.path.exists(os.path.join(log_dir, 'training' + '_' + str(fCount))):\n",
    "            fCount+=1\n",
    "        training_log_dir = os.path.join(log_dir, 'training' + '_' + str(fCount))\n",
    "        super(TrainValTensorBoard, self).__init__(training_log_dir, **kwargs)\n",
    "\n",
    "        # Log the validation metrics to a separate subdirectory\n",
    "        self.val_log_dir = os.path.join(log_dir, 'validation' + '_' + str(fCount))\n",
    "\n",
    "    def set_model(self, model):\n",
    "        # Setup writer for validation metrics\n",
    "        self.val_writer = tf.summary.FileWriter(self.val_log_dir)\n",
    "        super(TrainValTensorBoard, self).set_model(model)\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        # Pop the validation logs and handle them separately with\n",
    "        # `self.val_writer`. Also rename the keys so that they can\n",
    "        # be plotted on the same figure with the training metrics\n",
    "        logs = logs or {}\n",
    "        val_logs = {k.replace('val_', ''): v for k, v in logs.items() if k.startswith('val_')}\n",
    "        for name, value in val_logs.items():\n",
    "            summary = tf.Summary()\n",
    "            summary_value = summary.value.add()\n",
    "            summary_value.simple_value = value.item()\n",
    "            summary_value.tag = name\n",
    "            self.val_writer.add_summary(summary, epoch)\n",
    "        self.val_writer.flush()\n",
    "\n",
    "        # Pass the remaining logs to `TensorBoard.on_epoch_end`\n",
    "        logs = {k: v for k, v in logs.items() if not k.startswith('val_')}\n",
    "        super(TrainValTensorBoard, self).on_epoch_end(epoch, logs)\n",
    "\n",
    "    def on_train_end(self, logs=None):\n",
    "        super(TrainValTensorBoard, self).on_train_end(logs)\n",
    "        self.val_writer.close()\n",
    "\n",
    "\n",
    "def get_images(path, dataSpecs):\n",
    "    fileList = glob.glob(path) #'BengaliBMPConvert/*.bmp'   \n",
    "    num = len(fileList)\n",
    "    dataSpecs['classLength'].append(len(fileList))\n",
    "    x = np.array([(cv2.imread(fname)) for fname in fileList])\n",
    "    return x\n",
    "\n",
    "def get_labels_one_hot(num_classes, class_id, num_samples):\n",
    "    x = np.zeros((num_samples, num_classes))\n",
    "    x[np.arange(num_samples),class_id] = 1\n",
    "    return x\n",
    "\n",
    "def fourCNN():\n",
    "    model = Sequential()\n",
    "    # Layer 1\n",
    "    model.add(Conv2D(32, (3,3), activation='relu', input_shape=INPUT_SHAPE, data_format='channels_last'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    # Layer 2\n",
    "    model.add(Conv2D(32, (3,3), activation='relu')) \n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    # Layer 3    \n",
    "    model.add(Conv2D(32, (3,3), activation='relu'))  \n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    # Layer 4     \n",
    "    model.add(Conv2D(32, (3,3), activation='relu'))   \n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))    \n",
    "    # Layer 5     \n",
    "    #model.add(Conv2D(32, (3,3), activation='relu'))   \n",
    "    #model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    # Layer 6\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1024, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(2, activation='softmax'))\n",
    "    return model\n",
    "    \n",
    "def fiveCNN():\n",
    "    model = Sequential()\n",
    "    # Layer 1\n",
    "    model.add(Conv2D(32, (3,3), activation='relu', input_shape=INPUT_SHAPE, data_format='channels_last'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    # Layer 2\n",
    "    model.add(Conv2D(32, (3,3), activation='relu')) \n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    # Layer 3    \n",
    "    model.add(Conv2D(32, (3,3), activation='relu'))  \n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    # Layer 4     \n",
    "    model.add(Conv2D(32, (3,3), activation='relu'))   \n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))    \n",
    "    # Layer 5     \n",
    "    model.add(Conv2D(32, (3,3), activation='relu'))   \n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    # Layer 6\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1024, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(2, activation='softmax'))  \n",
    "    return model\n",
    "\n",
    "def vgg():\n",
    "    vggModel = applications.VGG19(weights = None, include_top=False, input_shape = INPUT_SHAPE)\n",
    "    # Add custom final layer\n",
    "    model = vggModel.output\n",
    "    model = Flatten()(model)\n",
    "    model = Dense(2, activation='softmax')(model)\n",
    "    model = keras.models.Model(inputs=vggModel.input, outputs=model)\n",
    "    return model\n",
    "\n",
    "def tlVGG(train_data, val_data):\n",
    "    print('Compute bottleneck features...')\n",
    "    vggModel = applications.VGG19(weights = \"imagenet\", include_top=False, input_shape = INPUT_SHAPE)\n",
    "    # Freeze all layers\n",
    "    for layer in vggModel.layers:\n",
    "        layer.trainable = False\n",
    "    # Add custom final layer\n",
    "    bNModel = vggModel.output\n",
    "    bNModel = Flatten()(bNModel)\n",
    "    final_model = keras.models.Model(inputs=vggModel.input, outputs=bNModel)\n",
    "    train_bNFeatures = {'img': 0, 'label': train_data['label']}\n",
    "    val_bNFeatures = {'img': 0, 'label': val_data['label']}\n",
    "    train_bNFeatures['img'] = final_model.predict(train_data['img'], batch_size=16)\n",
    "    val_bNFeatures['img'] = final_model.predict(val_data['img'], batch_size=16)\n",
    "    print('train_bNFeatures[img].shape = ', train_bNFeatures['img'].shape)\n",
    "    print('val_bNFeatures[img].shape = ', val_bNFeatures['img'].shape)\n",
    "\n",
    "    print('Train head...')\n",
    "    head = Sequential()\n",
    "    #head.add(Dense(32, input_dim=train_bNFeatures['img'].shape[1], activation='relu'))\n",
    "    head.add(Dense(2, activation='softmax'))    \n",
    "    return head, train_bNFeatures, val_bNFeatures\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "def main():\n",
    "    import keras\n",
    "    print('keras version: ', keras.__version__)\n",
    "    print('TensorFlow version: ', tf.__version__)\n",
    "    print('\\nLoad images...')\n",
    "    \n",
    "    # Get images and labels\n",
    "    data = {'img': 0, 'label': 0}\n",
    "    dataSpecs = {'classLength': []}\n",
    "    dataSpecs['classLength'] = []\n",
    "    data['img'] = np.concatenate((\n",
    "            get_images(CLASSDIR_0, dataSpecs), # Class 0\n",
    "            get_images(CLASSDIR_1, dataSpecs) # Class 1\n",
    "    ))      \n",
    "\n",
    "    # Normalise\n",
    "    data['img'] = data['img']/NORMALISE   \n",
    "    # Print image    \n",
    "    img_calc = data['img']   \n",
    "    plt.imshow(img_calc[0], cmap='gray')\n",
    "    plt.show()\n",
    "    \n",
    "    # Create one hot labels\n",
    "    labels_bg = get_labels_one_hot(2, 0, dataSpecs['classLength'][0])  \n",
    "    labels_calc = get_labels_one_hot(2, 1, dataSpecs['classLength'][1])\n",
    "    data['label'] = np.concatenate((\n",
    "            get_labels_one_hot(2, 0, dataSpecs['classLength'][0]), # Class 0 \n",
    "            get_labels_one_hot(2, 1, dataSpecs['classLength'][1]) # Class 1\n",
    "    ))\n",
    "    # Drop from 3 colour channels to 1 (greyscale)\n",
    "    if 1==0:\n",
    "        data['img'] = data['img'][:,:,:,0]\n",
    "        data['img'] = np.reshape(data['img'], (data['img'].shape[0],data['img'].shape[1],data['img'].shape[2],1))\n",
    "        print('new data shape = ', data['img'].shape)\n",
    "    \n",
    "    valStats = []\n",
    "    for crossVal in range(FOLDS):\n",
    "\n",
    "        # Shuffle data\n",
    "        seed = 33\n",
    "    #     np.random.seed(seed) # Has to be set before each use of random\n",
    "        shuffleMask = np.random.permutation(data['img'].shape[0])    \n",
    "        data['img'] = data['img'][shuffleMask, :, :, :]\n",
    "        data['label'] = data['label'][shuffleMask, :]\n",
    "\n",
    "        # Split traing and validation data        \n",
    "        splitRatio = 0.9\n",
    "        splitPoint = math.floor(data['img'].shape[0]*splitRatio)\n",
    "        train_data = {'img': data['img'][0:splitPoint], 'label': data['label'][0:splitPoint]}\n",
    "        val_data = {'img': data['img'][splitPoint:], 'label': data['label'][splitPoint:]}\n",
    "\n",
    "        #model, train_bNFeatures, val_data = tlVGG(train_data, val_data)\n",
    "        model = vgg()        \n",
    "        model.summary()  \n",
    "        model = multi_gpu_model(model, gpus=2)\n",
    "        \n",
    "        sgd = optimizers.SGD(lr=5, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "        adam = optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False) #0.001\n",
    "        model.compile(loss='binary_crossentropy',\n",
    "                    optimizer=adam,\n",
    "                     metrics=['accuracy'])\n",
    "        tensorboard = TensorBoard(log_dir='/vol/vssp/mammo2/will/logs/new'.format(time()), write_images=True)\n",
    "\n",
    "\n",
    "        # Train\n",
    "        model.fit(train_data['img'], train_data['label'], \n",
    "                batch_size=BATCH_SIZE, epochs=EPOCHS, verbose=1,\n",
    "                callbacks=[TrainValTensorBoard(write_graph=False)],\n",
    "                validation_data=(val_data['img'], val_data['label']))\n",
    "\n",
    "        # Evaluate\n",
    "        score = model.evaluate(val_data['img'], val_data['label'], verbose=0)\n",
    "        valStats.append(score)\n",
    "        print('The score is......\\n', score)\n",
    "        \n",
    "  \n",
    "\n",
    "    valStats = np.asarray(valStats)\n",
    "    print('Validations: \\n', valStats[:, 1])\n",
    "    print('Average loss: ', sum(valStats[:, 0])/FOLDS)\n",
    "    print('Average validation: ', sum(valStats[:, 1])/FOLDS)\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-13T13:58:18.045957Z",
     "start_time": "2018-07-13T13:58:18.042237Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello world\n"
     ]
    }
   ],
   "source": [
    "print('hello world')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-31T18:09:00.228920Z",
     "start_time": "2018-07-31T18:09:00.221319Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "def test():\n",
    "    return 1, 2, 3\n",
    "\n",
    "x, y, z = test()\n",
    "print(x)\n",
    "print(y)dd\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-13T13:06:34.579475Z",
     "start_time": "2018-07-13T13:06:34.562536Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[6.53083827 0.59259259]\n",
      " [0.16470135 0.94444444]\n",
      " [0.15422182 0.94444444]\n",
      " [0.19875195 0.9382716 ]] \n",
      "\n",
      "6.5308382717179665\n",
      "[6.53083827 0.16470135 0.15422182 0.19875195]\n",
      "(4, 2)\n"
     ]
    }
   ],
   "source": [
    "x = [[6.5308382717179665, 0.5925925925925926], [0.16470135086112553, 0.9444444444444444], [0.15422181794304907, 0.9444444444444444], [0.19875195217721256, 0.9382716049382716]] \n",
    "x = np.asarray(x)\n",
    "print(x, '\\n')\n",
    "print(x[0][0])\n",
    "print(x[:, 0])\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "144px",
    "left": "1504px",
    "right": "20px",
    "top": "140px",
    "width": "350px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
