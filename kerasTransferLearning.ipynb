{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-08-05T20:15:17.583Z"
    },
    "code_folding": [
     91,
     115,
     163,
     172
    ],
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keras version:  2.2.0\n",
      "TensorFlow version:  1.7.1\n",
      "\n",
      "Load images...\n",
      "1176  Files found\n",
      "Loading images...\n",
      "1 / 1176\n",
      "2 / 1176\n",
      "3 / 1176\n",
      "4 / 1176\n",
      "5 / 1176\n",
      "6 / 1176\n",
      "7 / 1176\n",
      "8 / 1176\n",
      "9 / 1176\n",
      "10 / 1176\n",
      "11 / 1176\n",
      "12 / 1176\n",
      "13 / 1176\n",
      "14 / 1176\n",
      "15 / 1176\n",
      "16 / 1176\n",
      "17 / 1176\n",
      "18 / 1176\n",
      "19 / 1176\n",
      "20 / 1176\n",
      "21 / 1176\n",
      "22 / 1176\n",
      "23 / 1176\n",
      "24 / 1176\n",
      "25 / 1176\n",
      "26 / 1176\n",
      "27 / 1176\n",
      "28 / 1176\n",
      "29 / 1176\n",
      "30 / 1176\n",
      "31 / 1176\n",
      "32 / 1176\n",
      "33 / 1176\n",
      "34 / 1176\n",
      "35 / 1176\n",
      "36 / 1176\n",
      "37 / 1176\n",
      "38 / 1176\n",
      "39 / 1176\n",
      "40 / 1176\n",
      "41 / 1176\n",
      "42 / 1176\n",
      "43 / 1176\n",
      "44 / 1176\n",
      "45 / 1176\n",
      "46 / 1176\n",
      "47 / 1176\n",
      "48 / 1176\n",
      "49 / 1176\n",
      "50 / 1176\n",
      "51 / 1176\n",
      "52 / 1176\n",
      "53 / 1176\n",
      "54 / 1176\n",
      "55 / 1176\n",
      "56 / 1176\n",
      "57 / 1176\n",
      "58 / 1176\n",
      "59 / 1176\n",
      "60 / 1176\n",
      "61 / 1176\n",
      "62 / 1176\n",
      "63 / 1176\n",
      "64 / 1176\n",
      "65 / 1176\n",
      "66 / 1176\n",
      "67 / 1176\n",
      "68 / 1176\n",
      "69 / 1176\n",
      "70 / 1176\n",
      "71 / 1176\n",
      "72 / 1176\n",
      "73 / 1176\n",
      "74 / 1176\n",
      "75 / 1176\n",
      "76 / 1176\n",
      "77 / 1176\n",
      "78 / 1176\n",
      "79 / 1176\n",
      "80 / 1176\n",
      "81 / 1176\n",
      "82 / 1176\n",
      "83 / 1176\n",
      "84 / 1176\n",
      "85 / 1176\n",
      "86 / 1176\n",
      "87 / 1176\n",
      "88 / 1176\n",
      "89 / 1176\n",
      "90 / 1176\n",
      "91 / 1176\n",
      "92 / 1176\n",
      "93 / 1176\n",
      "94 / 1176\n",
      "95 / 1176\n",
      "96 / 1176\n",
      "97 / 1176\n",
      "98 / 1176\n",
      "99 / 1176\n",
      "100 / 1176\n",
      "101 / 1176\n",
      "102 / 1176\n",
      "103 / 1176\n",
      "104 / 1176\n",
      "105 / 1176\n",
      "106 / 1176\n",
      "107 / 1176\n",
      "108 / 1176\n",
      "109 / 1176\n",
      "110 / 1176\n",
      "111 / 1176\n",
      "112 / 1176\n",
      "113 / 1176\n",
      "114 / 1176\n",
      "115 / 1176\n",
      "116 / 1176\n",
      "117 / 1176\n",
      "118 / 1176\n",
      "119 / 1176\n",
      "120 / 1176\n",
      "121 / 1176\n",
      "122 / 1176\n",
      "123 / 1176\n",
      "124 / 1176\n",
      "125 / 1176\n",
      "126 / 1176\n",
      "127 / 1176\n",
      "128 / 1176\n",
      "129 / 1176\n",
      "130 / 1176\n",
      "131 / 1176\n",
      "132 / 1176\n",
      "133 / 1176\n",
      "134 / 1176\n",
      "135 / 1176\n",
      "136 / 1176\n",
      "137 / 1176\n",
      "138 / 1176\n",
      "139 / 1176\n",
      "140 / 1176\n",
      "141 / 1176\n",
      "142 / 1176\n",
      "143 / 1176\n",
      "144 / 1176\n",
      "145 / 1176\n",
      "146 / 1176\n",
      "147 / 1176\n",
      "148 / 1176\n",
      "149 / 1176\n",
      "150 / 1176\n",
      "151 / 1176\n",
      "152 / 1176\n",
      "153 / 1176\n",
      "154 / 1176\n",
      "155 / 1176\n",
      "156 / 1176\n",
      "157 / 1176\n",
      "158 / 1176\n",
      "159 / 1176\n",
      "160 / 1176\n",
      "161 / 1176\n",
      "162 / 1176\n",
      "163 / 1176\n",
      "164 / 1176\n",
      "165 / 1176\n",
      "166 / 1176\n",
      "167 / 1176\n",
      "168 / 1176\n",
      "169 / 1176\n",
      "170 / 1176\n",
      "171 / 1176\n",
      "172 / 1176\n",
      "173 / 1176\n",
      "174 / 1176\n",
      "175 / 1176\n",
      "176 / 1176\n",
      "177 / 1176\n",
      "178 / 1176\n",
      "179 / 1176\n",
      "180 / 1176\n",
      "181 / 1176\n",
      "182 / 1176\n",
      "183 / 1176\n",
      "184 / 1176\n",
      "185 / 1176\n",
      "186 / 1176\n",
      "187 / 1176\n",
      "188 / 1176\n",
      "189 / 1176\n",
      "190 / 1176\n",
      "191 / 1176\n",
      "192 / 1176\n",
      "193 / 1176\n",
      "194 / 1176\n",
      "195 / 1176\n",
      "196 / 1176\n",
      "197 / 1176\n",
      "198 / 1176\n",
      "199 / 1176\n",
      "200 / 1176\n",
      "201 / 1176\n",
      "202 / 1176\n",
      "203 / 1176\n",
      "204 / 1176\n",
      "205 / 1176\n",
      "206 / 1176\n",
      "207 / 1176\n",
      "208 / 1176\n",
      "209 / 1176\n",
      "210 / 1176\n",
      "211 / 1176\n",
      "212 / 1176\n",
      "213 / 1176\n",
      "214 / 1176\n",
      "215 / 1176\n",
      "216 / 1176\n",
      "217 / 1176\n",
      "218 / 1176\n",
      "219 / 1176\n",
      "220 / 1176\n",
      "221 / 1176\n",
      "222 / 1176\n",
      "223 / 1176\n",
      "224 / 1176\n",
      "225 / 1176\n",
      "226 / 1176\n",
      "227 / 1176\n",
      "228 / 1176\n",
      "229 / 1176\n",
      "230 / 1176\n",
      "231 / 1176\n",
      "232 / 1176\n",
      "233 / 1176\n",
      "234 / 1176\n",
      "235 / 1176\n",
      "236 / 1176\n",
      "237 / 1176\n",
      "238 / 1176\n",
      "239 / 1176\n",
      "240 / 1176\n",
      "241 / 1176\n",
      "242 / 1176\n",
      "243 / 1176\n",
      "244 / 1176\n",
      "245 / 1176\n",
      "246 / 1176\n",
      "247 / 1176\n",
      "248 / 1176\n",
      "249 / 1176\n",
      "250 / 1176\n",
      "251 / 1176\n",
      "252 / 1176\n",
      "253 / 1176\n",
      "254 / 1176\n",
      "255 / 1176\n",
      "256 / 1176\n",
      "257 / 1176\n",
      "258 / 1176\n",
      "259 / 1176\n",
      "260 / 1176\n",
      "261 / 1176\n",
      "262 / 1176\n",
      "263 / 1176\n",
      "264 / 1176\n",
      "265 / 1176\n",
      "266 / 1176\n",
      "267 / 1176\n",
      "268 / 1176\n",
      "269 / 1176\n",
      "270 / 1176\n",
      "271 / 1176\n",
      "272 / 1176\n",
      "273 / 1176\n",
      "274 / 1176\n",
      "275 / 1176\n",
      "276 / 1176\n",
      "277 / 1176\n",
      "278 / 1176\n",
      "279 / 1176\n",
      "280 / 1176\n",
      "281 / 1176\n",
      "282 / 1176\n",
      "283 / 1176\n",
      "284 / 1176\n",
      "285 / 1176\n",
      "286 / 1176\n",
      "287 / 1176\n",
      "288 / 1176\n",
      "289 / 1176\n",
      "290 / 1176\n",
      "291 / 1176\n",
      "292 / 1176\n",
      "293 / 1176\n",
      "294 / 1176\n",
      "295 / 1176\n",
      "296 / 1176\n",
      "297 / 1176\n",
      "298 / 1176\n",
      "299 / 1176\n",
      "300 / 1176\n",
      "301 / 1176\n",
      "302 / 1176\n",
      "303 / 1176\n",
      "304 / 1176\n",
      "305 / 1176\n",
      "306 / 1176\n",
      "307 / 1176\n",
      "308 / 1176\n",
      "309 / 1176\n",
      "310 / 1176\n",
      "311 / 1176\n",
      "312 / 1176\n",
      "313 / 1176\n",
      "314 / 1176\n",
      "315 / 1176\n",
      "316 / 1176\n",
      "317 / 1176\n",
      "318 / 1176\n",
      "319 / 1176\n",
      "320 / 1176\n",
      "321 / 1176\n",
      "322 / 1176\n",
      "323 / 1176\n",
      "324 / 1176\n",
      "325 / 1176\n",
      "326 / 1176\n",
      "327 / 1176\n",
      "328 / 1176\n",
      "329 / 1176\n",
      "330 / 1176\n",
      "331 / 1176\n",
      "332 / 1176\n",
      "333 / 1176\n",
      "334 / 1176\n",
      "335 / 1176\n",
      "336 / 1176\n",
      "337 / 1176\n",
      "338 / 1176\n",
      "339 / 1176\n",
      "340 / 1176\n",
      "341 / 1176\n",
      "342 / 1176\n",
      "343 / 1176\n",
      "344 / 1176\n",
      "345 / 1176\n",
      "346 / 1176\n",
      "347 / 1176\n",
      "348 / 1176\n",
      "349 / 1176\n",
      "350 / 1176\n",
      "351 / 1176\n",
      "352 / 1176\n",
      "353 / 1176\n",
      "354 / 1176\n",
      "355 / 1176\n",
      "356 / 1176\n",
      "357 / 1176\n",
      "358 / 1176\n",
      "359 / 1176\n",
      "360 / 1176\n",
      "361 / 1176\n",
      "362 / 1176\n",
      "363 / 1176\n",
      "364 / 1176\n",
      "365 / 1176\n",
      "366 / 1176\n",
      "367 / 1176\n",
      "368 / 1176\n",
      "369 / 1176\n",
      "370 / 1176\n",
      "371 / 1176\n",
      "372 / 1176\n",
      "373 / 1176\n",
      "374 / 1176\n",
      "375 / 1176\n",
      "376 / 1176\n",
      "377 / 1176\n",
      "378 / 1176\n",
      "379 / 1176\n",
      "380 / 1176\n",
      "381 / 1176\n",
      "382 / 1176\n",
      "383 / 1176\n",
      "384 / 1176\n",
      "385 / 1176\n",
      "386 / 1176\n",
      "387 / 1176\n",
      "388 / 1176\n",
      "389 / 1176\n",
      "390 / 1176\n",
      "391 / 1176\n",
      "392 / 1176\n",
      "393 / 1176\n",
      "394 / 1176\n",
      "395 / 1176\n",
      "396 / 1176\n",
      "397 / 1176\n",
      "398 / 1176\n",
      "399 / 1176\n",
      "400 / 1176\n",
      "401 / 1176\n",
      "402 / 1176\n",
      "403 / 1176\n",
      "404 / 1176\n",
      "405 / 1176\n",
      "406 / 1176\n",
      "407 / 1176\n",
      "408 / 1176\n",
      "409 / 1176\n",
      "410 / 1176\n",
      "411 / 1176\n",
      "412 / 1176\n",
      "413 / 1176\n",
      "414 / 1176\n",
      "415 / 1176\n",
      "416 / 1176\n",
      "417 / 1176\n",
      "418 / 1176\n",
      "419 / 1176\n",
      "420 / 1176\n",
      "421 / 1176\n",
      "422 / 1176\n",
      "423 / 1176\n",
      "424 / 1176\n",
      "425 / 1176\n",
      "426 / 1176\n",
      "427 / 1176\n",
      "428 / 1176\n",
      "429 / 1176\n",
      "430 / 1176\n",
      "431 / 1176\n",
      "432 / 1176\n",
      "433 / 1176\n",
      "434 / 1176\n",
      "435 / 1176\n",
      "436 / 1176\n",
      "437 / 1176\n",
      "438 / 1176\n",
      "439 / 1176\n",
      "440 / 1176\n",
      "441 / 1176\n",
      "442 / 1176\n",
      "443 / 1176\n",
      "444 / 1176\n",
      "445 / 1176\n",
      "446 / 1176\n",
      "447 / 1176\n",
      "448 / 1176\n",
      "449 / 1176\n",
      "450 / 1176\n",
      "451 / 1176\n",
      "452 / 1176\n",
      "453 / 1176\n",
      "454 / 1176\n",
      "455 / 1176\n",
      "456 / 1176\n",
      "457 / 1176\n",
      "458 / 1176\n",
      "459 / 1176\n",
      "460 / 1176\n",
      "461 / 1176\n",
      "462 / 1176\n",
      "463 / 1176\n",
      "464 / 1176\n",
      "465 / 1176\n",
      "466 / 1176\n",
      "467 / 1176\n",
      "468 / 1176\n",
      "469 / 1176\n",
      "470 / 1176\n",
      "471 / 1176\n",
      "472 / 1176\n",
      "473 / 1176\n",
      "474 / 1176\n",
      "475 / 1176\n",
      "476 / 1176\n",
      "477 / 1176\n",
      "478 / 1176\n",
      "479 / 1176\n",
      "480 / 1176\n",
      "481 / 1176\n",
      "482 / 1176\n",
      "483 / 1176\n",
      "484 / 1176\n",
      "485 / 1176\n",
      "486 / 1176\n",
      "487 / 1176\n",
      "488 / 1176\n",
      "489 / 1176\n",
      "490 / 1176\n",
      "491 / 1176\n",
      "492 / 1176\n",
      "493 / 1176\n",
      "494 / 1176\n",
      "495 / 1176\n",
      "496 / 1176\n",
      "497 / 1176\n",
      "498 / 1176\n",
      "499 / 1176\n",
      "500 / 1176\n",
      "501 / 1176\n",
      "502 / 1176\n",
      "503 / 1176\n",
      "504 / 1176\n",
      "505 / 1176\n",
      "506 / 1176\n",
      "507 / 1176\n",
      "508 / 1176\n",
      "509 / 1176\n",
      "510 / 1176\n",
      "511 / 1176\n",
      "512 / 1176\n",
      "513 / 1176\n",
      "514 / 1176\n",
      "515 / 1176\n",
      "516 / 1176\n",
      "517 / 1176\n",
      "518 / 1176\n",
      "519 / 1176\n",
      "520 / 1176\n",
      "521 / 1176\n",
      "522 / 1176\n",
      "523 / 1176\n",
      "524 / 1176\n",
      "525 / 1176\n",
      "526 / 1176\n",
      "527 / 1176\n",
      "528 / 1176\n",
      "529 / 1176\n",
      "530 / 1176\n",
      "531 / 1176\n",
      "532 / 1176\n",
      "533 / 1176\n",
      "534 / 1176\n",
      "535 / 1176\n",
      "536 / 1176\n",
      "537 / 1176\n",
      "538 / 1176\n",
      "539 / 1176\n",
      "540 / 1176\n",
      "541 / 1176\n",
      "542 / 1176\n",
      "543 / 1176\n",
      "544 / 1176\n",
      "545 / 1176\n",
      "546 / 1176\n",
      "547 / 1176\n",
      "548 / 1176\n",
      "549 / 1176\n",
      "550 / 1176\n",
      "551 / 1176\n",
      "552 / 1176\n",
      "553 / 1176\n",
      "554 / 1176\n",
      "555 / 1176\n",
      "556 / 1176\n",
      "557 / 1176\n",
      "558 / 1176\n",
      "559 / 1176\n",
      "560 / 1176\n",
      "561 / 1176\n",
      "562 / 1176\n",
      "563 / 1176\n",
      "564 / 1176\n",
      "565 / 1176\n",
      "566 / 1176\n",
      "567 / 1176\n",
      "568 / 1176\n",
      "569 / 1176\n",
      "570 / 1176\n",
      "571 / 1176\n",
      "572 / 1176\n",
      "573 / 1176\n",
      "574 / 1176\n",
      "575 / 1176\n",
      "576 / 1176\n",
      "577 / 1176\n",
      "578 / 1176\n",
      "579 / 1176\n",
      "580 / 1176\n",
      "581 / 1176\n",
      "582 / 1176\n",
      "583 / 1176\n",
      "584 / 1176\n",
      "585 / 1176\n",
      "586 / 1176\n",
      "587 / 1176\n",
      "588 / 1176\n",
      "589 / 1176\n",
      "590 / 1176\n",
      "591 / 1176\n",
      "592 / 1176\n",
      "593 / 1176\n",
      "594 / 1176\n",
      "595 / 1176\n",
      "596 / 1176\n",
      "597 / 1176\n",
      "598 / 1176\n",
      "599 / 1176\n",
      "600 / 1176\n",
      "601 / 1176\n",
      "602 / 1176\n",
      "603 / 1176\n",
      "604 / 1176\n",
      "605 / 1176\n",
      "606 / 1176\n",
      "607 / 1176\n",
      "608 / 1176\n",
      "609 / 1176\n",
      "610 / 1176\n",
      "611 / 1176\n",
      "612 / 1176\n",
      "613 / 1176\n",
      "614 / 1176\n",
      "615 / 1176\n",
      "616 / 1176\n",
      "617 / 1176\n",
      "618 / 1176\n",
      "619 / 1176\n",
      "620 / 1176\n",
      "621 / 1176\n",
      "622 / 1176\n",
      "623 / 1176\n",
      "624 / 1176\n",
      "625 / 1176\n",
      "626 / 1176\n",
      "627 / 1176\n",
      "628 / 1176\n",
      "629 / 1176\n",
      "630 / 1176\n",
      "631 / 1176\n",
      "632 / 1176\n",
      "633 / 1176\n",
      "634 / 1176\n",
      "635 / 1176\n",
      "636 / 1176\n",
      "637 / 1176\n",
      "638 / 1176\n",
      "639 / 1176\n",
      "640 / 1176\n",
      "641 / 1176\n",
      "642 / 1176\n",
      "643 / 1176\n",
      "644 / 1176\n",
      "645 / 1176\n",
      "646 / 1176\n",
      "647 / 1176\n",
      "648 / 1176\n",
      "649 / 1176\n",
      "650 / 1176\n",
      "651 / 1176\n",
      "652 / 1176\n",
      "653 / 1176\n",
      "654 / 1176\n",
      "655 / 1176\n",
      "656 / 1176\n",
      "657 / 1176\n",
      "658 / 1176\n",
      "659 / 1176\n",
      "660 / 1176\n",
      "661 / 1176\n",
      "662 / 1176\n",
      "663 / 1176\n",
      "664 / 1176\n",
      "665 / 1176\n",
      "666 / 1176\n",
      "667 / 1176\n",
      "668 / 1176\n",
      "669 / 1176\n",
      "670 / 1176\n",
      "671 / 1176\n",
      "672 / 1176\n",
      "673 / 1176\n",
      "674 / 1176\n",
      "675 / 1176\n",
      "676 / 1176\n",
      "677 / 1176\n",
      "678 / 1176\n",
      "679 / 1176\n",
      "680 / 1176\n",
      "681 / 1176\n",
      "682 / 1176\n",
      "683 / 1176\n",
      "684 / 1176\n",
      "685 / 1176\n",
      "686 / 1176\n",
      "687 / 1176\n",
      "688 / 1176\n",
      "689 / 1176\n",
      "690 / 1176\n",
      "691 / 1176\n",
      "692 / 1176\n",
      "693 / 1176\n",
      "694 / 1176\n",
      "695 / 1176\n",
      "696 / 1176\n",
      "697 / 1176\n",
      "698 / 1176\n",
      "699 / 1176\n",
      "700 / 1176\n",
      "701 / 1176\n",
      "702 / 1176\n",
      "703 / 1176\n",
      "704 / 1176\n",
      "705 / 1176\n",
      "706 / 1176\n",
      "707 / 1176\n",
      "708 / 1176\n",
      "709 / 1176\n",
      "710 / 1176\n",
      "711 / 1176\n",
      "712 / 1176\n",
      "713 / 1176\n",
      "714 / 1176\n",
      "715 / 1176\n",
      "716 / 1176\n",
      "717 / 1176\n",
      "718 / 1176\n",
      "719 / 1176\n",
      "720 / 1176\n",
      "721 / 1176\n",
      "722 / 1176\n",
      "723 / 1176\n",
      "724 / 1176\n",
      "725 / 1176\n",
      "726 / 1176\n",
      "727 / 1176\n",
      "728 / 1176\n",
      "729 / 1176\n",
      "730 / 1176\n",
      "731 / 1176\n",
      "732 / 1176\n",
      "733 / 1176\n",
      "734 / 1176\n",
      "735 / 1176\n",
      "736 / 1176\n",
      "737 / 1176\n",
      "738 / 1176\n",
      "739 / 1176\n",
      "740 / 1176\n",
      "741 / 1176\n",
      "742 / 1176\n",
      "743 / 1176\n",
      "744 / 1176\n",
      "745 / 1176\n",
      "746 / 1176\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "747 / 1176\n",
      "748 / 1176\n",
      "749 / 1176\n",
      "750 / 1176\n",
      "751 / 1176\n",
      "752 / 1176\n",
      "753 / 1176\n",
      "754 / 1176\n",
      "755 / 1176\n",
      "756 / 1176\n",
      "757 / 1176\n",
      "758 / 1176\n",
      "759 / 1176\n",
      "760 / 1176\n",
      "761 / 1176\n",
      "762 / 1176\n",
      "763 / 1176\n",
      "764 / 1176\n",
      "765 / 1176\n",
      "766 / 1176\n",
      "767 / 1176\n",
      "768 / 1176\n",
      "769 / 1176\n",
      "770 / 1176\n",
      "771 / 1176\n",
      "772 / 1176\n",
      "773 / 1176\n",
      "774 / 1176\n",
      "775 / 1176\n",
      "776 / 1176\n",
      "777 / 1176\n",
      "778 / 1176\n",
      "779 / 1176\n",
      "780 / 1176\n",
      "781 / 1176\n",
      "782 / 1176\n",
      "783 / 1176\n",
      "784 / 1176\n",
      "785 / 1176\n",
      "786 / 1176\n",
      "787 / 1176\n",
      "788 / 1176\n",
      "789 / 1176\n",
      "790 / 1176\n",
      "791 / 1176\n",
      "792 / 1176\n",
      "793 / 1176\n",
      "794 / 1176\n",
      "795 / 1176\n",
      "796 / 1176\n",
      "797 / 1176\n",
      "798 / 1176\n",
      "799 / 1176\n",
      "800 / 1176\n",
      "801 / 1176\n",
      "802 / 1176\n",
      "803 / 1176\n",
      "804 / 1176\n",
      "805 / 1176\n",
      "806 / 1176\n",
      "807 / 1176\n",
      "808 / 1176\n",
      "809 / 1176\n",
      "810 / 1176\n",
      "811 / 1176\n",
      "812 / 1176\n",
      "813 / 1176\n",
      "814 / 1176\n",
      "815 / 1176\n",
      "816 / 1176\n",
      "817 / 1176\n",
      "818 / 1176\n",
      "819 / 1176\n",
      "820 / 1176\n",
      "821 / 1176\n",
      "822 / 1176\n",
      "823 / 1176\n",
      "824 / 1176\n",
      "825 / 1176\n",
      "826 / 1176\n",
      "827 / 1176\n",
      "828 / 1176\n",
      "829 / 1176\n",
      "830 / 1176\n",
      "831 / 1176\n",
      "832 / 1176\n",
      "833 / 1176\n",
      "834 / 1176\n",
      "835 / 1176\n",
      "836 / 1176\n",
      "837 / 1176\n",
      "838 / 1176\n",
      "839 / 1176\n",
      "840 / 1176\n",
      "841 / 1176\n",
      "842 / 1176\n",
      "843 / 1176\n",
      "844 / 1176\n",
      "845 / 1176\n",
      "846 / 1176\n",
      "847 / 1176\n",
      "848 / 1176\n",
      "849 / 1176\n",
      "850 / 1176\n",
      "851 / 1176\n",
      "852 / 1176\n",
      "853 / 1176\n",
      "854 / 1176\n",
      "855 / 1176\n",
      "856 / 1176\n",
      "857 / 1176\n",
      "858 / 1176\n",
      "859 / 1176\n",
      "860 / 1176\n",
      "861 / 1176\n",
      "862 / 1176\n",
      "863 / 1176\n",
      "864 / 1176\n",
      "865 / 1176\n",
      "866 / 1176\n",
      "867 / 1176\n",
      "868 / 1176\n",
      "869 / 1176\n",
      "870 / 1176\n",
      "871 / 1176\n",
      "872 / 1176\n",
      "873 / 1176\n",
      "874 / 1176\n",
      "875 / 1176\n",
      "876 / 1176\n",
      "877 / 1176\n",
      "878 / 1176\n",
      "879 / 1176\n",
      "880 / 1176\n",
      "881 / 1176\n",
      "882 / 1176\n",
      "883 / 1176\n",
      "884 / 1176\n",
      "885 / 1176\n",
      "886 / 1176\n",
      "887 / 1176\n",
      "888 / 1176\n",
      "889 / 1176\n",
      "890 / 1176\n",
      "891 / 1176\n",
      "892 / 1176\n",
      "893 / 1176\n",
      "894 / 1176\n",
      "895 / 1176\n",
      "896 / 1176\n",
      "897 / 1176\n",
      "898 / 1176\n",
      "899 / 1176\n",
      "900 / 1176\n",
      "901 / 1176\n",
      "902 / 1176\n",
      "903 / 1176\n",
      "904 / 1176\n",
      "905 / 1176\n",
      "906 / 1176\n",
      "907 / 1176\n",
      "908 / 1176\n",
      "909 / 1176\n",
      "910 / 1176\n",
      "911 / 1176\n",
      "912 / 1176\n",
      "913 / 1176\n",
      "914 / 1176\n",
      "915 / 1176\n",
      "916 / 1176\n",
      "917 / 1176\n",
      "918 / 1176\n",
      "919 / 1176\n",
      "920 / 1176\n",
      "921 / 1176\n",
      "922 / 1176\n",
      "923 / 1176\n",
      "924 / 1176\n",
      "925 / 1176\n",
      "926 / 1176\n",
      "927 / 1176\n",
      "928 / 1176\n",
      "929 / 1176\n",
      "930 / 1176\n",
      "931 / 1176\n",
      "932 / 1176\n",
      "933 / 1176\n",
      "934 / 1176\n",
      "935 / 1176\n",
      "936 / 1176\n",
      "937 / 1176\n",
      "938 / 1176\n",
      "939 / 1176\n",
      "940 / 1176\n",
      "941 / 1176\n",
      "942 / 1176\n",
      "943 / 1176\n",
      "944 / 1176\n",
      "945 / 1176\n",
      "946 / 1176\n",
      "947 / 1176\n",
      "948 / 1176\n",
      "949 / 1176\n",
      "950 / 1176\n",
      "951 / 1176\n",
      "952 / 1176\n",
      "953 / 1176\n",
      "954 / 1176\n",
      "955 / 1176\n",
      "956 / 1176\n",
      "957 / 1176\n",
      "958 / 1176\n",
      "959 / 1176\n",
      "960 / 1176\n",
      "961 / 1176\n",
      "962 / 1176\n",
      "963 / 1176\n",
      "964 / 1176\n",
      "965 / 1176\n",
      "966 / 1176\n",
      "967 / 1176\n",
      "968 / 1176\n",
      "969 / 1176\n",
      "970 / 1176\n",
      "971 / 1176\n",
      "972 / 1176\n",
      "973 / 1176\n",
      "974 / 1176\n",
      "975 / 1176\n",
      "976 / 1176\n",
      "977 / 1176\n",
      "978 / 1176\n",
      "979 / 1176\n",
      "980 / 1176\n",
      "981 / 1176\n",
      "982 / 1176\n",
      "983 / 1176\n",
      "984 / 1176\n",
      "985 / 1176\n",
      "986 / 1176\n",
      "987 / 1176\n",
      "988 / 1176\n",
      "989 / 1176\n",
      "990 / 1176\n",
      "991 / 1176\n",
      "992 / 1176\n",
      "993 / 1176\n",
      "994 / 1176\n",
      "995 / 1176\n",
      "996 / 1176\n",
      "997 / 1176\n",
      "998 / 1176\n",
      "999 / 1176\n",
      "1000 / 1176\n",
      "1001 / 1176\n",
      "1002 / 1176\n",
      "1003 / 1176\n",
      "1004 / 1176\n",
      "1005 / 1176\n",
      "1006 / 1176\n",
      "1007 / 1176\n",
      "1008 / 1176\n",
      "1009 / 1176\n",
      "1010 / 1176\n",
      "1011 / 1176\n",
      "1012 / 1176\n",
      "1013 / 1176\n",
      "1014 / 1176\n",
      "1015 / 1176\n",
      "1016 / 1176\n",
      "1017 / 1176\n",
      "1018 / 1176\n",
      "1019 / 1176\n",
      "1020 / 1176\n",
      "1021 / 1176\n",
      "1022 / 1176\n",
      "1023 / 1176\n",
      "1024 / 1176\n",
      "1025 / 1176\n",
      "1026 / 1176\n",
      "1027 / 1176\n",
      "1028 / 1176\n",
      "1029 / 1176\n",
      "1030 / 1176\n",
      "1031 / 1176\n",
      "1032 / 1176\n",
      "1033 / 1176\n",
      "1034 / 1176\n",
      "1035 / 1176\n",
      "1036 / 1176\n",
      "1037 / 1176\n",
      "1038 / 1176\n",
      "1039 / 1176\n",
      "1040 / 1176\n",
      "1041 / 1176\n",
      "1042 / 1176\n",
      "1043 / 1176\n",
      "1044 / 1176\n",
      "1045 / 1176\n",
      "1046 / 1176\n",
      "1047 / 1176\n",
      "1048 / 1176\n",
      "1049 / 1176\n",
      "1050 / 1176\n",
      "1051 / 1176\n",
      "1052 / 1176\n",
      "1053 / 1176\n",
      "1054 / 1176\n",
      "1055 / 1176\n",
      "1056 / 1176\n",
      "1057 / 1176\n",
      "1058 / 1176\n",
      "1059 / 1176\n",
      "1060 / 1176\n",
      "1061 / 1176\n",
      "1062 / 1176\n",
      "1063 / 1176\n",
      "1064 / 1176\n",
      "1065 / 1176\n",
      "1066 / 1176\n",
      "1067 / 1176\n",
      "1068 / 1176\n",
      "1069 / 1176\n",
      "1070 / 1176\n",
      "1071 / 1176\n",
      "1072 / 1176\n",
      "1073 / 1176\n",
      "1074 / 1176\n",
      "1075 / 1176\n",
      "1076 / 1176\n",
      "1077 / 1176\n",
      "1078 / 1176\n",
      "1079 / 1176\n",
      "1080 / 1176\n",
      "1081 / 1176\n",
      "1082 / 1176\n",
      "1083 / 1176\n",
      "1084 / 1176\n",
      "1085 / 1176\n",
      "1086 / 1176\n",
      "1087 / 1176\n",
      "1088 / 1176\n",
      "1089 / 1176\n",
      "1090 / 1176\n",
      "1091 / 1176\n",
      "1092 / 1176\n",
      "1093 / 1176\n",
      "1094 / 1176\n",
      "1095 / 1176\n",
      "1096 / 1176\n",
      "1097 / 1176\n",
      "1098 / 1176\n",
      "1099 / 1176\n",
      "1100 / 1176\n",
      "1101 / 1176\n",
      "1102 / 1176\n",
      "1103 / 1176\n",
      "1104 / 1176\n",
      "1105 / 1176\n",
      "1106 / 1176\n",
      "1107 / 1176\n",
      "1108 / 1176\n",
      "1109 / 1176\n",
      "1110 / 1176\n",
      "1111 / 1176\n",
      "1112 / 1176\n",
      "1113 / 1176\n",
      "1114 / 1176\n",
      "1115 / 1176\n",
      "1116 / 1176\n",
      "1117 / 1176\n",
      "1118 / 1176\n",
      "1119 / 1176\n",
      "1120 / 1176\n",
      "1121 / 1176\n",
      "1122 / 1176\n",
      "1123 / 1176\n",
      "1124 / 1176\n",
      "1125 / 1176\n",
      "1126 / 1176\n",
      "1127 / 1176\n",
      "1128 / 1176\n",
      "1129 / 1176\n",
      "1130 / 1176\n",
      "1131 / 1176\n",
      "1132 / 1176\n",
      "1133 / 1176\n",
      "1134 / 1176\n",
      "1135 / 1176\n",
      "1136 / 1176\n",
      "1137 / 1176\n",
      "1138 / 1176\n",
      "1139 / 1176\n",
      "1140 / 1176\n",
      "1141 / 1176\n",
      "1142 / 1176\n",
      "1143 / 1176\n",
      "1144 / 1176\n",
      "1145 / 1176\n",
      "1146 / 1176\n",
      "1147 / 1176\n",
      "1148 / 1176\n",
      "1149 / 1176\n",
      "1150 / 1176\n",
      "1151 / 1176\n",
      "1152 / 1176\n",
      "1153 / 1176\n",
      "1154 / 1176\n",
      "1155 / 1176\n",
      "1156 / 1176\n",
      "1157 / 1176\n",
      "1158 / 1176\n",
      "1159 / 1176\n",
      "1160 / 1176\n",
      "1161 / 1176\n",
      "1162 / 1176\n",
      "1163 / 1176\n",
      "1164 / 1176\n",
      "1165 / 1176\n",
      "1166 / 1176\n",
      "1167 / 1176\n",
      "1168 / 1176\n",
      "1169 / 1176\n",
      "1170 / 1176\n",
      "1171 / 1176\n",
      "1172 / 1176\n",
      "1173 / 1176\n",
      "1174 / 1176\n",
      "1175 / 1176\n",
      "1176 / 1176\n",
      "531  Files found\n",
      "Loading images...\n",
      "1 / 531\n",
      "2 / 531\n",
      "3 / 531\n",
      "4 / 531\n",
      "5 / 531\n",
      "6 / 531\n",
      "7 / 531\n",
      "8 / 531\n",
      "9 / 531\n",
      "10 / 531\n",
      "11 / 531\n",
      "12 / 531\n",
      "13 / 531\n",
      "14 / 531\n",
      "15 / 531\n",
      "16 / 531\n",
      "17 / 531\n",
      "18 / 531\n",
      "19 / 531\n",
      "20 / 531\n",
      "21 / 531\n",
      "22 / 531\n",
      "23 / 531\n",
      "24 / 531\n",
      "25 / 531\n",
      "26 / 531\n",
      "27 / 531\n",
      "28 / 531\n",
      "29 / 531\n",
      "30 / 531\n",
      "31 / 531\n",
      "32 / 531\n",
      "33 / 531\n",
      "34 / 531\n",
      "35 / 531\n",
      "36 / 531\n",
      "37 / 531\n",
      "38 / 531\n",
      "39 / 531\n",
      "40 / 531\n",
      "41 / 531\n",
      "42 / 531\n",
      "43 / 531\n",
      "44 / 531\n",
      "45 / 531\n",
      "46 / 531\n",
      "47 / 531\n",
      "48 / 531\n",
      "49 / 531\n",
      "50 / 531\n",
      "51 / 531\n",
      "52 / 531\n",
      "53 / 531\n",
      "54 / 531\n",
      "55 / 531\n",
      "56 / 531\n",
      "57 / 531\n",
      "58 / 531\n",
      "59 / 531\n",
      "60 / 531\n",
      "61 / 531\n",
      "62 / 531\n",
      "63 / 531\n",
      "64 / 531\n",
      "65 / 531\n",
      "66 / 531\n",
      "67 / 531\n",
      "68 / 531\n",
      "69 / 531\n",
      "70 / 531\n",
      "71 / 531\n",
      "72 / 531\n",
      "73 / 531\n",
      "74 / 531\n",
      "75 / 531\n",
      "76 / 531\n",
      "77 / 531\n",
      "78 / 531\n",
      "79 / 531\n",
      "80 / 531\n",
      "81 / 531\n",
      "82 / 531\n",
      "83 / 531\n",
      "84 / 531\n",
      "85 / 531\n",
      "86 / 531\n",
      "87 / 531\n",
      "88 / 531\n",
      "89 / 531\n",
      "90 / 531\n",
      "91 / 531\n",
      "92 / 531\n",
      "93 / 531\n",
      "94 / 531\n",
      "95 / 531\n",
      "96 / 531\n",
      "97 / 531\n",
      "98 / 531\n",
      "99 / 531\n",
      "100 / 531\n",
      "101 / 531\n",
      "102 / 531\n",
      "103 / 531\n",
      "104 / 531\n",
      "105 / 531\n",
      "106 / 531\n",
      "107 / 531\n",
      "108 / 531\n",
      "109 / 531\n",
      "110 / 531\n",
      "111 / 531\n",
      "112 / 531\n",
      "113 / 531\n",
      "114 / 531\n",
      "115 / 531\n",
      "116 / 531\n",
      "117 / 531\n",
      "118 / 531\n",
      "119 / 531\n",
      "120 / 531\n",
      "121 / 531\n",
      "122 / 531\n",
      "123 / 531\n",
      "124 / 531\n",
      "125 / 531\n",
      "126 / 531\n",
      "127 / 531\n",
      "128 / 531\n",
      "129 / 531\n",
      "130 / 531\n",
      "131 / 531\n",
      "132 / 531\n",
      "133 / 531\n",
      "134 / 531\n",
      "135 / 531\n",
      "136 / 531\n",
      "137 / 531\n",
      "138 / 531\n",
      "139 / 531\n",
      "140 / 531\n",
      "141 / 531\n",
      "142 / 531\n",
      "143 / 531\n",
      "144 / 531\n",
      "145 / 531\n",
      "146 / 531\n",
      "147 / 531\n",
      "148 / 531\n",
      "149 / 531\n",
      "150 / 531\n",
      "151 / 531\n",
      "152 / 531\n",
      "153 / 531\n",
      "154 / 531\n",
      "155 / 531\n",
      "156 / 531\n",
      "157 / 531\n",
      "158 / 531\n",
      "159 / 531\n",
      "160 / 531\n",
      "161 / 531\n",
      "162 / 531\n",
      "163 / 531\n",
      "164 / 531\n",
      "165 / 531\n",
      "166 / 531\n",
      "167 / 531\n",
      "168 / 531\n",
      "169 / 531\n",
      "170 / 531\n",
      "171 / 531\n",
      "172 / 531\n",
      "173 / 531\n",
      "174 / 531\n",
      "175 / 531\n",
      "176 / 531\n",
      "177 / 531\n",
      "178 / 531\n",
      "179 / 531\n",
      "180 / 531\n",
      "181 / 531\n",
      "182 / 531\n",
      "183 / 531\n",
      "184 / 531\n",
      "185 / 531\n",
      "186 / 531\n",
      "187 / 531\n",
      "188 / 531\n",
      "189 / 531\n",
      "190 / 531\n",
      "191 / 531\n",
      "192 / 531\n",
      "193 / 531\n",
      "194 / 531\n",
      "195 / 531\n",
      "196 / 531\n",
      "197 / 531\n",
      "198 / 531\n",
      "199 / 531\n",
      "200 / 531\n",
      "201 / 531\n",
      "202 / 531\n",
      "203 / 531\n",
      "204 / 531\n",
      "205 / 531\n",
      "206 / 531\n",
      "207 / 531\n",
      "208 / 531\n",
      "209 / 531\n",
      "210 / 531\n",
      "211 / 531\n",
      "212 / 531\n",
      "213 / 531\n",
      "214 / 531\n",
      "215 / 531\n",
      "216 / 531\n",
      "217 / 531\n",
      "218 / 531\n",
      "219 / 531\n",
      "220 / 531\n",
      "221 / 531\n",
      "222 / 531\n",
      "223 / 531\n",
      "224 / 531\n",
      "225 / 531\n",
      "226 / 531\n",
      "227 / 531\n",
      "228 / 531\n",
      "229 / 531\n",
      "230 / 531\n",
      "231 / 531\n",
      "232 / 531\n",
      "233 / 531\n",
      "234 / 531\n",
      "235 / 531\n",
      "236 / 531\n",
      "237 / 531\n",
      "238 / 531\n",
      "239 / 531\n",
      "240 / 531\n",
      "241 / 531\n",
      "242 / 531\n",
      "243 / 531\n",
      "244 / 531\n",
      "245 / 531\n",
      "246 / 531\n",
      "247 / 531\n",
      "248 / 531\n",
      "249 / 531\n",
      "250 / 531\n",
      "251 / 531\n",
      "252 / 531\n",
      "253 / 531\n",
      "254 / 531\n",
      "255 / 531\n",
      "256 / 531\n",
      "257 / 531\n",
      "258 / 531\n",
      "259 / 531\n",
      "260 / 531\n",
      "261 / 531\n",
      "262 / 531\n",
      "263 / 531\n",
      "264 / 531\n",
      "265 / 531\n",
      "266 / 531\n",
      "267 / 531\n",
      "268 / 531\n",
      "269 / 531\n",
      "270 / 531\n",
      "271 / 531\n",
      "272 / 531\n",
      "273 / 531\n",
      "274 / 531\n",
      "275 / 531\n",
      "276 / 531\n",
      "277 / 531\n",
      "278 / 531\n",
      "279 / 531\n",
      "280 / 531\n",
      "281 / 531\n",
      "282 / 531\n",
      "283 / 531\n",
      "284 / 531\n",
      "285 / 531\n",
      "286 / 531\n",
      "287 / 531\n",
      "288 / 531\n",
      "289 / 531\n",
      "290 / 531\n",
      "291 / 531\n",
      "292 / 531\n",
      "293 / 531\n",
      "294 / 531\n",
      "295 / 531\n",
      "296 / 531\n",
      "297 / 531\n",
      "298 / 531\n",
      "299 / 531\n",
      "300 / 531\n",
      "301 / 531\n",
      "302 / 531\n",
      "303 / 531\n",
      "304 / 531\n",
      "305 / 531\n",
      "306 / 531\n",
      "307 / 531\n",
      "308 / 531\n",
      "309 / 531\n",
      "310 / 531\n",
      "311 / 531\n",
      "312 / 531\n",
      "313 / 531\n",
      "314 / 531\n",
      "315 / 531\n",
      "316 / 531\n",
      "317 / 531\n",
      "318 / 531\n",
      "319 / 531\n",
      "320 / 531\n",
      "321 / 531\n",
      "322 / 531\n",
      "323 / 531\n",
      "324 / 531\n",
      "325 / 531\n",
      "326 / 531\n",
      "327 / 531\n",
      "328 / 531\n",
      "329 / 531\n",
      "330 / 531\n",
      "331 / 531\n",
      "332 / 531\n",
      "333 / 531\n",
      "334 / 531\n",
      "335 / 531\n",
      "336 / 531\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "337 / 531\n",
      "338 / 531\n",
      "339 / 531\n",
      "340 / 531\n",
      "341 / 531\n",
      "342 / 531\n",
      "343 / 531\n",
      "344 / 531\n",
      "345 / 531\n",
      "346 / 531\n",
      "347 / 531\n",
      "348 / 531\n",
      "349 / 531\n",
      "350 / 531\n",
      "351 / 531\n",
      "352 / 531\n",
      "353 / 531\n",
      "354 / 531\n",
      "355 / 531\n",
      "356 / 531\n",
      "357 / 531\n",
      "358 / 531\n",
      "359 / 531\n",
      "360 / 531\n",
      "361 / 531\n",
      "362 / 531\n",
      "363 / 531\n",
      "364 / 531\n",
      "365 / 531\n",
      "366 / 531\n",
      "367 / 531\n",
      "368 / 531\n",
      "369 / 531\n",
      "370 / 531\n",
      "371 / 531\n",
      "372 / 531\n",
      "373 / 531\n",
      "374 / 531\n",
      "375 / 531\n",
      "376 / 531\n",
      "377 / 531\n",
      "378 / 531\n",
      "379 / 531\n",
      "380 / 531\n",
      "381 / 531\n",
      "382 / 531\n",
      "383 / 531\n",
      "384 / 531\n",
      "385 / 531\n",
      "386 / 531\n",
      "387 / 531\n",
      "388 / 531\n",
      "389 / 531\n",
      "390 / 531\n",
      "391 / 531\n",
      "392 / 531\n",
      "393 / 531\n",
      "394 / 531\n",
      "395 / 531\n",
      "396 / 531\n",
      "397 / 531\n",
      "398 / 531\n",
      "399 / 531\n",
      "400 / 531\n",
      "401 / 531\n",
      "402 / 531\n",
      "403 / 531\n",
      "404 / 531\n",
      "405 / 531\n",
      "406 / 531\n",
      "407 / 531\n",
      "408 / 531\n",
      "409 / 531\n",
      "410 / 531\n",
      "411 / 531\n",
      "412 / 531\n",
      "413 / 531\n",
      "414 / 531\n",
      "415 / 531\n",
      "416 / 531\n",
      "417 / 531\n",
      "418 / 531\n",
      "419 / 531\n",
      "420 / 531\n",
      "421 / 531\n",
      "422 / 531\n",
      "423 / 531\n",
      "424 / 531\n",
      "425 / 531\n",
      "426 / 531\n",
      "427 / 531\n",
      "428 / 531\n",
      "429 / 531\n",
      "430 / 531\n",
      "431 / 531\n",
      "432 / 531\n",
      "433 / 531\n",
      "434 / 531\n",
      "435 / 531\n",
      "436 / 531\n",
      "437 / 531\n",
      "438 / 531\n",
      "439 / 531\n",
      "440 / 531\n",
      "441 / 531\n",
      "442 / 531\n",
      "443 / 531\n",
      "444 / 531\n",
      "445 / 531\n",
      "446 / 531\n",
      "447 / 531\n",
      "448 / 531\n",
      "449 / 531\n",
      "450 / 531\n",
      "451 / 531\n",
      "452 / 531\n",
      "453 / 531\n",
      "454 / 531\n",
      "455 / 531\n",
      "456 / 531\n",
      "457 / 531\n",
      "458 / 531\n",
      "459 / 531\n",
      "460 / 531\n",
      "461 / 531\n",
      "462 / 531\n",
      "463 / 531\n",
      "464 / 531\n",
      "465 / 531\n",
      "466 / 531\n",
      "467 / 531\n",
      "468 / 531\n",
      "469 / 531\n",
      "470 / 531\n",
      "471 / 531\n",
      "472 / 531\n",
      "473 / 531\n",
      "474 / 531\n",
      "475 / 531\n",
      "476 / 531\n",
      "477 / 531\n",
      "478 / 531\n",
      "479 / 531\n",
      "480 / 531\n",
      "481 / 531\n",
      "482 / 531\n",
      "483 / 531\n",
      "484 / 531\n",
      "485 / 531\n",
      "486 / 531\n",
      "487 / 531\n",
      "488 / 531\n",
      "489 / 531\n",
      "490 / 531\n",
      "491 / 531\n",
      "492 / 531\n",
      "493 / 531\n",
      "494 / 531\n",
      "495 / 531\n",
      "496 / 531\n",
      "497 / 531\n",
      "498 / 531\n",
      "499 / 531\n",
      "500 / 531\n",
      "501 / 531\n",
      "502 / 531\n",
      "503 / 531\n",
      "504 / 531\n",
      "505 / 531\n",
      "506 / 531\n",
      "507 / 531\n",
      "508 / 531\n",
      "509 / 531\n",
      "510 / 531\n",
      "511 / 531\n",
      "512 / 531\n",
      "513 / 531\n",
      "514 / 531\n",
      "515 / 531\n",
      "516 / 531\n",
      "517 / 531\n",
      "518 / 531\n",
      "519 / 531\n",
      "520 / 531\n",
      "521 / 531\n",
      "522 / 531\n",
      "523 / 531\n",
      "524 / 531\n",
      "525 / 531\n",
      "526 / 531\n",
      "527 / 531\n",
      "528 / 531\n",
      "529 / 531\n",
      "530 / 531\n",
      "531 / 531\n",
      "Train...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/user/HS204/wm0015/anaconda3/envs/tensorflow/lib/python3.6/site-packages/keras/callbacks.py:432: RuntimeWarning: Can save best model only with val_accuracy available, skipping.\n",
      "  'skipping.' % (self.monitor), RuntimeWarning)\n"
     ]
    }
   ],
   "source": [
    "# fold\n",
    "import numpy as np\n",
    "import cv2\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "from keras.models import Sequential\n",
    "import keras\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.utils import np_utils\n",
    "from keras import optimizers\n",
    "# For some reason I have to tell it to use TensorFlows dimension ordering\n",
    "from keras import backend as K\n",
    "K.set_image_dim_ordering('tf')\n",
    "from keras.callbacks import TensorBoard, EarlyStopping, ModelCheckpoint\n",
    "from time import time\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from keras import applications\n",
    "from keras.utils import multi_gpu_model\n",
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "config = tf.ConfigProto()\n",
    "#config.gpu_options.per_process_gpu_memory_fraction = 0.5\n",
    "config.gpu_options.visible_device_list = \"2,3\"\n",
    "config.gpu_options.allow_growth = True\n",
    "set_session(tf.Session(config=config))\n",
    "\n",
    "# Globals\n",
    "VERBOSE = 0\n",
    "ARCHITECTURE = 0\n",
    "NORMALISE = 1\n",
    "# Class 0 = backgrounds\n",
    "CLASSDIR_0 = '/vol/vssp/cvpwrkspc01/scratch/wm0015/crops256/normal/*'\n",
    "CLASSDIR_1 = '/vol/vssp/cvpwrkspc01/scratch/wm0015/crops256/malignant/*'\n",
    "\n",
    "# Calcs\n",
    "#CLASSDIR_0 = '/user/HS204/wm0015/student/allCalcs/0/*'\n",
    "#CLASSDIR_1 = '/user/HS204/wm0015/student/allCalcs/1/*'\n",
    "MODEL_SAVE = '/vol/vssp/cvpwrkspc01/scratch/wm0015/models/best_model.h5'\n",
    "BATCH_SIZE = 100\n",
    "EPOCHS = 5000\n",
    "#INPUT_SHAPE = [256, 256, 3]\n",
    "INPUT_SHAPE = [429, 429, 1]\n",
    "#INPUT_SHAPE = [385, 385, 3]\n",
    "FOLDS = 5\n",
    "PATIENCE = 500\n",
    "\n",
    "class TrainValTensorBoard(TensorBoard):\n",
    "    def __init__(self, log_dir='/vol/vssp/mammo2/will/logs/new', **kwargs):\n",
    "        # Make the original `TensorBoard` log to a subdirectory 'training'\n",
    "        fCount=0\n",
    "        while os.path.exists(os.path.join(log_dir, 'training' + '_' + str(fCount))):\n",
    "            fCount+=1\n",
    "        training_log_dir = os.path.join(log_dir, 'training' + '_' + str(fCount))\n",
    "        super(TrainValTensorBoard, self).__init__(training_log_dir, **kwargs)\n",
    "\n",
    "        # Log the validation metrics to a separate subdirectory\n",
    "        self.val_log_dir = os.path.join(log_dir, 'validation' + '_' + str(fCount))\n",
    "\n",
    "    def set_model(self, model):\n",
    "        # Setup writer for validation metrics\n",
    "        self.val_writer = tf.summary.FileWriter(self.val_log_dir)\n",
    "        super(TrainValTensorBoard, self).set_model(model)\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        # Pop the validation logs and handle them separately with\n",
    "        # `self.val_writer`. Also rename the keys so that they can\n",
    "        # be plotted on the same figure with the training metrics\n",
    "        logs = logs or {}\n",
    "        val_logs = {k.replace('val_', ''): v for k, v in logs.items() if k.startswith('val_')}\n",
    "        for name, value in val_logs.items():\n",
    "            summary = tf.Summary()\n",
    "            summary_value = summary.value.add()\n",
    "            summary_value.simple_value = value.item()\n",
    "            summary_value.tag = name\n",
    "            self.val_writer.add_summary(summary, epoch)\n",
    "        self.val_writer.flush()\n",
    "\n",
    "        # Pass the remaining logs to `TensorBoard.on_epoch_end`\n",
    "        logs = {k: v for k, v in logs.items() if not k.startswith('val_')}\n",
    "        super(TrainValTensorBoard, self).on_epoch_end(epoch, logs)\n",
    "\n",
    "    def on_train_end(self, logs=None):\n",
    "        super(TrainValTensorBoard, self).on_train_end(logs)\n",
    "        self.val_writer.close()\n",
    "\n",
    "\n",
    "def get_images(path, dataSpecs):\n",
    "    fileList = glob.glob(path) #'BengaliBMPConvert/*.bmp'   \n",
    "    num = len(fileList)\n",
    "    dataSpecs['classLength'].append(len(fileList))\n",
    "    x = np.array([(cv2.imread(fname)) for fname in fileList])\n",
    "    return x\n",
    "\n",
    "def get_labels_one_hot(num_classes, class_id, num_samples):\n",
    "    x = np.zeros((num_samples, num_classes))\n",
    "    x[np.arange(num_samples),class_id] = 1\n",
    "    return x\n",
    "\n",
    "def fourCNN():\n",
    "    model = Sequential()\n",
    "    # Layer 1\n",
    "    model.add(Conv2D(32, (3,3), activation='relu', input_shape=INPUT_SHAPE, data_format='channels_last'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    # Layer 2\n",
    "    model.add(Conv2D(32, (3,3), activation='relu')) \n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    # Layer 3    \n",
    "    model.add(Conv2D(32, (3,3), activation='relu'))  \n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    # Layer 4     \n",
    "    model.add(Conv2D(32, (3,3), activation='relu'))   \n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))    \n",
    "    # Layer 5     \n",
    "    #model.add(Conv2D(32, (3,3), activation='relu'))   \n",
    "    #model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    # Layer 6\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1024, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(2, activation='softmax'))\n",
    "    return model\n",
    "    \n",
    "def fiveCNN():\n",
    "    model = Sequential()\n",
    "    # Layer 1\n",
    "    model.add(Conv2D(32, (3,3), activation='relu', input_shape=INPUT_SHAPE, data_format='channels_last'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    # Layer 2\n",
    "    model.add(Conv2D(32, (3,3), activation='relu')) \n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    # Layer 3    \n",
    "    model.add(Conv2D(32, (3,3), activation='relu'))  \n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    # Layer 4     \n",
    "    model.add(Conv2D(32, (3,3), activation='relu'))   \n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))    \n",
    "    # Layer 5     \n",
    "    model.add(Conv2D(32, (3,3), activation='relu'))   \n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    # Layer 6\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1024, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(2, activation='softmax'))  \n",
    "    return model\n",
    "    \n",
    "def bigCNN():\n",
    "    model = Sequential()\n",
    "    # Layer 1\n",
    "    model.add(Conv2D(32, (3,3), activation='relu', input_shape=INPUT_SHAPE, data_format='channels_last'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    # Layer 2\n",
    "    model.add(Conv2D(64, (3,3), activation='relu')) \n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    # Layer 3    \n",
    "    model.add(Conv2D(124, (3,3), activation='relu'))  \n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    # Layer 4     \n",
    "    model.add(Conv2D(256, (3,3), activation='relu'))   \n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))    \n",
    "    # Layer 5     \n",
    "    model.add(Conv2D(512, (3,3), activation='relu'))   \n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    # Layer 6\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1024, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(2, activation='softmax'))  \n",
    "    return model\n",
    "\n",
    "def vgg():\n",
    "    vggModel = applications.VGG19(weights = 'imagenet', include_top=False, input_shape = INPUT_SHAPE)\n",
    "    # Add custom final layer\n",
    "    model = vggModel.output\n",
    "    model = Flatten()(model)\n",
    "    model = Dense(2, activation='softmax')(model)\n",
    "    model = keras.models.Model(inputs=vggModel.input, outputs=model)\n",
    "    return model\n",
    "\n",
    "def tlVGG(train_data, val_data):\n",
    "    print('Compute bottleneck features...')\n",
    "    vggModel = applications.VGG19(weights = \"imagenet\", include_top=False, input_shape = INPUT_SHAPE)\n",
    "    # Freeze all layers\n",
    "    for layer in vggModel.layers:\n",
    "        layer.trainable = False\n",
    "    # Add custom final layer\n",
    "    bNModel = vggModel.output\n",
    "    bNModel = Flatten()(bNModel)\n",
    "    final_model = keras.models.Model(inputs=vggModel.input, outputs=bNModel)\n",
    "    train_bNFeatures = {'img': 0, 'label': train_data['label']}\n",
    "    val_bNFeatures = {'img': 0, 'label': val_data['label']}\n",
    "    train_bNFeatures['img'] = final_model.predict(train_data['img'], batch_size=16)\n",
    "    val_bNFeatures['img'] = final_model.predict(val_data['img'], batch_size=16)\n",
    "    #Undo one hot - ROC does not work with onehot\n",
    "    val_bNFeatures.update({'labelIndex': np.where(val_data['label']==1)[1]})\n",
    "    print('train_bNFeatures[img].shape = ', train_bNFeatures['img'].shape)\n",
    "    print('val_bNFeatures[img].shape = ', val_bNFeatures['img'].shape)\n",
    "\n",
    "    print('Train head...')\n",
    "    head = Sequential()\n",
    "    #head.add(Dense(32, input_dim=train_bNFeatures['img'].shape[1], activation='relu'))\n",
    "    head.add(Dense(2, activation='softmax'))    \n",
    "    return head, train_bNFeatures, val_bNFeatures\n",
    "\n",
    "    # Why oh why are they in a directory structure like this\n",
    "def getPremFiles(imgPath, dataSpecs):\n",
    "    import pydicom\n",
    "    from fnmatch import fnmatch\n",
    "    # First get all the 6mm lesions\n",
    "    fileList = []\n",
    "    for path, subdirs, files in os.walk(imgPath):\n",
    "        for name in files:\n",
    "            if fnmatch(name, '2D_dim2d.dcm'):\n",
    "                fileList.append(os.path.join(path, name))\n",
    "    # I can't remember why I thought dataSpecs was a good idea\n",
    "    # I suppose this means that class 0 needs to be loaded in first\n",
    "    dataSpecs['classLength'].append(len(fileList))\n",
    "    \n",
    "    # Load the files from filelist into an array\n",
    "    print(len(fileList), ' Files found')\n",
    "    print('Loading images...')\n",
    "    dicomImg = np.asarray([])\n",
    "    count = 0\n",
    "    for f in fileList:\n",
    "        dicomImg = np.append(dicomImg, pydicom.dcmread(f).pixel_array)\n",
    "        count += 1\n",
    "        print(count, '/', len(fileList))\n",
    "    return dicomImg\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "def main():\n",
    "    import keras\n",
    "    print('keras version: ', keras.__version__)\n",
    "    print('TensorFlow version: ', tf.__version__)\n",
    "    print('\\nLoad images...')\n",
    "    \n",
    "    # Get images and labels\n",
    "    data = {'img': 0, 'label': 0}\n",
    "    dataSpecs = {'classLength': []}\n",
    "    dataSpecs['classLength'] = []\n",
    "    \n",
    "    # Comment out for prem images\n",
    "#     data['img'] = np.concatenate((\n",
    "#             get_images(CLASSDIR_0, dataSpecs), # Class 0 (backgrounds)\n",
    "#             get_images(CLASSDIR_1, dataSpecs) # Class 1 \n",
    "#     ))      \n",
    "\n",
    "    past1 = get_images(CLASSDIR_0, dataSpecs)\n",
    "    past2 = get_images(CLASSDIR_1, dataSpecs)\n",
    "    pastConcat = np.concatenate((past1, past2))\n",
    "\n",
    "\n",
    "    # Prem images\n",
    "    prem1 = getPremFiles('/vol/vssp/cvpwrkspc01/scratch/wm0015/download/prem/Segments', dataSpecs)\n",
    "    prem2 = getPremFiles('/vol/vssp/cvpwrkspc01/scratch/wm0015/download/prem/2D/6mm', dataSpecs)\n",
    "    prem1 = prem1.reshape((-1, 429, 429, 1))\n",
    "    prem2 = prem2.reshape((-1, 429, 429, 1))\n",
    "#     print('prem1.shape: ', prem1.shape)\n",
    "#     print('prem2.shape: ', prem2.shape)\n",
    "#     print('past1.shape: ', past1.shape)\n",
    "#     print('past2.shape: ', past2.shape)\n",
    "#     print('pastConcat.shape: ', pastConcat.shape)\n",
    "#     print('prem1[0].shape: ', prem1[0].shape)\n",
    "#     print('prem2[0].shape: ', prem2[0].shape)\n",
    "    data['img'] = np.concatenate((prem1, prem2))\n",
    "\n",
    "    # Normalise\n",
    "    data['img'] = data['img']/NORMALISE   \n",
    "    # Print image    \n",
    "#     img_calc = data['img']   \n",
    "#     plt.imshow(img_calc[0], cmap='gray')\n",
    "#     plt.show()\n",
    "    \n",
    "    # Create one hot labels\n",
    "    labels_bg = get_labels_one_hot(2, 0, dataSpecs['classLength'][0])  \n",
    "    labels_calc = get_labels_one_hot(2, 1, dataSpecs['classLength'][1])\n",
    "    data['label'] = np.concatenate((\n",
    "            get_labels_one_hot(2, 0, dataSpecs['classLength'][0]), # Class 0 \n",
    "            get_labels_one_hot(2, 1, dataSpecs['classLength'][1]) # Class 1\n",
    "    ))\n",
    "    # Drop from 3 colour channels to 1 (greyscale)\n",
    "    if 1==0:\n",
    "        data['img'] = data['img'][:,:,:,0]\n",
    "        data['img'] = np.reshape(data['img'], (data['img'].shape[0],data['img'].shape[1],data['img'].shape[2],1))\n",
    "        print('new data shape = ', data['img'].shape)\n",
    "    \n",
    "    valStats = []\n",
    "    for crossVal in range(FOLDS):\n",
    "\n",
    "        # Shuffle data\n",
    "        seed = 33\n",
    "        np.random.seed(seed) # Has to be set before each use of random\n",
    "        shuffleMask = np.random.permutation(data['img'].shape[0])    \n",
    "        data['img'] = data['img'][shuffleMask, :, :, :]\n",
    "        data['label'] = data['label'][shuffleMask, :]\n",
    "\n",
    "        # Split traing and validation data        \n",
    "        splitRatio = 0.9\n",
    "        splitPoint = math.floor(data['img'].shape[0]*splitRatio)\n",
    "        train_data = {'img': data['img'][0:splitPoint], 'label': data['label'][0:splitPoint]}\n",
    "        val_data = {'img': data['img'][splitPoint:], 'label': data['label'][splitPoint:]}\n",
    "        #Undo one hot - ROC does not work with onehot\n",
    "        val_data.update({'labelIndex': np.where(val_data['label']==1)[1]})\n",
    "\n",
    "        \n",
    "\n",
    "        #model, train_data, val_data = tlVGG(train_data, val_data)\n",
    "        model = fiveCNN()\n",
    "        if ARCHITECTURE != 0:\n",
    "            model.summary()  \n",
    "        model = multi_gpu_model(model, gpus=2)\n",
    "        \n",
    "        sgd = optimizers.SGD(lr=5, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "        adam = optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False) #0.001\n",
    "        model.compile(loss='binary_crossentropy',\n",
    "                    optimizer=adam,\n",
    "                     metrics=['accuracy'])\n",
    "        tensorboard = TensorBoard(log_dir='/vol/vssp/mammo2/will/logs/new'.format(time()), write_images=True)\n",
    "\n",
    "        # Data augmentation settings\n",
    "        from keras.preprocessing.image import ImageDataGenerator\n",
    "        trainDatagen = ImageDataGenerator(\n",
    "            featurewise_center=True,\n",
    "            featurewise_std_normalization=True,\n",
    "            rotation_range=20,\n",
    "            width_shift_range=0.2,\n",
    "            height_shift_range=0.2,\n",
    "            horizontal_flip=True)\n",
    "        trainDatagen.fit(train_data['img'])\n",
    "        valDatagen = ImageDataGenerator(\n",
    "            featurewise_center=True,\n",
    "            featurewise_std_normalization=True,\n",
    "            #rotation_range=20,\n",
    "            #width_shift_range=0.2,\n",
    "            #height_shift_range=0.2,\n",
    "            #horizontal_flip=True\n",
    "            )\n",
    "        valDatagen.fit(val_data['img'])\n",
    "        \n",
    "#         # Normalise myself\n",
    "#         mean_data = np.mean(train_data['img'])\n",
    "#         std_data = np.std(train_data['img'])\n",
    "#         train_data['img'] = (train_data['img']-mean_data)/std_data\n",
    "#         val_data['img'] = (val_data['img']-mean_data/std_data)\n",
    "        \n",
    "#        # Train, with data augmentation\n",
    "#         print('Train...')\n",
    "#         model.fit_generator(trainDatagen.flow(train_data['img'], train_data['label'], batch_size=32),\n",
    "#                     steps_per_epoch=len(train_data['img']) / 32, epochs=EPOCHS, verbose=VERBOSE,\n",
    "#                            callbacks=[\n",
    "#                                TrainValTensorBoard(write_graph=False),\n",
    "#                                EarlyStopping(monitor='val_loss', patience=PATIENCE, verbose=1),\n",
    "#                                ModelCheckpoint(filepath=MODEL_SAVE, monitor='val_accuracy', save_best_only=True)],\n",
    "#                            validation_data=valDatagen.flow(x = val_data['img'], y = val_data['label']))\n",
    "        \n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "        # Train\n",
    "        print('Train...')\n",
    "        model.fit(train_data['img'], train_data['label'], \n",
    "                batch_size=BATCH_SIZE, epochs=EPOCHS, verbose=VERBOSE,\n",
    "                callbacks=[\n",
    "                    TrainValTensorBoard(write_graph=False),\n",
    "                    EarlyStopping(monitor='val_loss', patience=PATIENCE, verbose=1),\n",
    "                    ModelCheckpoint(filepath=MODEL_SAVE, monitor='val_accuracy', save_best_only=True)],\n",
    "                validation_data=(val_data['img'], val_data['label']))\n",
    "        \n",
    "        # Restore best model\n",
    "        model.load_weights(MODEL_SAVE)\n",
    "        \n",
    "        # Produce ROC curve\n",
    "        \n",
    "        y_pred_keras = model.predict(val_data['img'])  \n",
    "        y_true = val_data['labelIndex']\n",
    "        y_score = y_pred_keras[:,1]\n",
    "        fpr_keras, tpr_keras, thresholds_keras = roc_curve(y_true, y_score)\n",
    "        from sklearn.metrics import auc\n",
    "        auc_keras = auc(fpr_keras, tpr_keras)\n",
    "        plt.figure(1)\n",
    "        plt.plot([0, 1], [0, 1], 'k--')\n",
    "        plt.plot(fpr_keras, tpr_keras, label='Keras (area = {:.3f})'.format(auc_keras))\n",
    "        plt.xlabel('False positive rate')\n",
    "        plt.ylabel('True positive rate')\n",
    "        plt.title('ROC curve')\n",
    "        plt.legend(loc='best')\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "        # Evaluate\n",
    "        score = model.evaluate(val_data['img'], val_data['label'], verbose=0)\n",
    "        valStats.append(score)\n",
    "        print('The score is......\\n', score)\n",
    "        \n",
    "  \n",
    "\n",
    "    valStats = np.asarray(valStats)\n",
    "    print('Validations: \\n', valStats[:, 1])\n",
    "    print('Average loss: ', sum(valStats[:, 0])/FOLDS)\n",
    "    print('Average validation: ', sum(valStats[:, 1])/FOLDS)\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-05T16:34:48.948581Z",
     "start_time": "2018-08-05T16:34:48.943230Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello world\n"
     ]
    }
   ],
   "source": [
    "print('hello world')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-31T18:09:00.228920Z",
     "start_time": "2018-07-31T18:09:00.221319Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "def test():\n",
    "    return 1, 2, 3\n",
    "\n",
    "x, y, z = test()\n",
    "print(x)\n",
    "print(y)dd\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-13T13:06:34.579475Z",
     "start_time": "2018-07-13T13:06:34.562536Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[6.53083827 0.59259259]\n",
      " [0.16470135 0.94444444]\n",
      " [0.15422182 0.94444444]\n",
      " [0.19875195 0.9382716 ]] \n",
      "\n",
      "6.5308382717179665\n",
      "[6.53083827 0.16470135 0.15422182 0.19875195]\n",
      "(4, 2)\n"
     ]
    }
   ],
   "source": [
    "x = [[6.5308382717179665, 0.5925925925925926], [0.16470135086112553, 0.9444444444444444], [0.15422181794304907, 0.9444444444444444], [0.19875195217721256, 0.9382716049382716]] \n",
    "x = np.asarray(x)\n",
    "print(x, '\\n')\n",
    "print(x[0][0])\n",
    "print(x[:, 0])\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "144px",
    "left": "1504px",
    "right": "20px",
    "top": "140px",
    "width": "350px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
