{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-06T17:56:31.127792Z",
     "start_time": "2018-08-06T17:46:59.891953Z"
    },
    "code_folding": [
     91,
     115,
     163,
     172
    ],
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keras version:  2.2.0\n",
      "TensorFlow version:  1.7.1\n",
      "\n",
      "Load images...\n",
      "1176  Files found\n",
      "Loading images...\n",
      "1 / 1176\n",
      "2 / 1176\n",
      "3 / 1176\n",
      "4 / 1176\n",
      "5 / 1176\n",
      "6 / 1176\n",
      "7 / 1176\n",
      "8 / 1176\n",
      "9 / 1176\n",
      "10 / 1176\n",
      "11 / 1176\n",
      "12 / 1176\n",
      "13 / 1176\n",
      "14 / 1176\n",
      "15 / 1176\n",
      "16 / 1176\n",
      "17 / 1176\n",
      "18 / 1176\n",
      "19 / 1176\n",
      "20 / 1176\n",
      "21 / 1176\n",
      "22 / 1176\n",
      "23 / 1176\n",
      "24 / 1176\n",
      "25 / 1176\n",
      "26 / 1176\n",
      "27 / 1176\n",
      "28 / 1176\n",
      "29 / 1176\n",
      "30 / 1176\n",
      "31 / 1176\n",
      "32 / 1176\n",
      "33 / 1176\n",
      "34 / 1176\n",
      "35 / 1176\n",
      "36 / 1176\n",
      "37 / 1176\n",
      "38 / 1176\n",
      "39 / 1176\n",
      "40 / 1176\n",
      "41 / 1176\n",
      "42 / 1176\n",
      "43 / 1176\n",
      "44 / 1176\n",
      "45 / 1176\n",
      "46 / 1176\n",
      "47 / 1176\n",
      "48 / 1176\n",
      "49 / 1176\n",
      "50 / 1176\n",
      "51 / 1176\n",
      "52 / 1176\n",
      "53 / 1176\n",
      "54 / 1176\n",
      "55 / 1176\n",
      "56 / 1176\n",
      "57 / 1176\n",
      "58 / 1176\n",
      "59 / 1176\n",
      "60 / 1176\n",
      "61 / 1176\n",
      "62 / 1176\n",
      "63 / 1176\n",
      "64 / 1176\n",
      "65 / 1176\n",
      "66 / 1176\n",
      "67 / 1176\n",
      "68 / 1176\n",
      "69 / 1176\n",
      "70 / 1176\n",
      "71 / 1176\n",
      "72 / 1176\n",
      "73 / 1176\n",
      "74 / 1176\n",
      "75 / 1176\n",
      "76 / 1176\n",
      "77 / 1176\n",
      "78 / 1176\n",
      "79 / 1176\n",
      "80 / 1176\n",
      "81 / 1176\n",
      "82 / 1176\n",
      "83 / 1176\n",
      "84 / 1176\n",
      "85 / 1176\n",
      "86 / 1176\n",
      "87 / 1176\n",
      "88 / 1176\n",
      "89 / 1176\n",
      "90 / 1176\n",
      "91 / 1176\n",
      "92 / 1176\n",
      "93 / 1176\n",
      "94 / 1176\n",
      "95 / 1176\n",
      "96 / 1176\n",
      "97 / 1176\n",
      "98 / 1176\n",
      "99 / 1176\n",
      "100 / 1176\n",
      "101 / 1176\n",
      "102 / 1176\n",
      "103 / 1176\n",
      "104 / 1176\n",
      "105 / 1176\n",
      "106 / 1176\n",
      "107 / 1176\n",
      "108 / 1176\n",
      "109 / 1176\n",
      "110 / 1176\n",
      "111 / 1176\n",
      "112 / 1176\n",
      "113 / 1176\n",
      "114 / 1176\n",
      "115 / 1176\n",
      "116 / 1176\n",
      "117 / 1176\n",
      "118 / 1176\n",
      "119 / 1176\n",
      "120 / 1176\n",
      "121 / 1176\n",
      "122 / 1176\n",
      "123 / 1176\n",
      "124 / 1176\n",
      "125 / 1176\n",
      "126 / 1176\n",
      "127 / 1176\n",
      "128 / 1176\n",
      "129 / 1176\n",
      "130 / 1176\n",
      "131 / 1176\n",
      "132 / 1176\n",
      "133 / 1176\n",
      "134 / 1176\n",
      "135 / 1176\n",
      "136 / 1176\n",
      "137 / 1176\n",
      "138 / 1176\n",
      "139 / 1176\n",
      "140 / 1176\n",
      "141 / 1176\n",
      "142 / 1176\n",
      "143 / 1176\n",
      "144 / 1176\n",
      "145 / 1176\n",
      "146 / 1176\n",
      "147 / 1176\n",
      "148 / 1176\n",
      "149 / 1176\n",
      "150 / 1176\n",
      "151 / 1176\n",
      "152 / 1176\n",
      "153 / 1176\n",
      "154 / 1176\n",
      "155 / 1176\n",
      "156 / 1176\n",
      "157 / 1176\n",
      "158 / 1176\n",
      "159 / 1176\n",
      "160 / 1176\n",
      "161 / 1176\n",
      "162 / 1176\n",
      "163 / 1176\n",
      "164 / 1176\n",
      "165 / 1176\n",
      "166 / 1176\n",
      "167 / 1176\n",
      "168 / 1176\n",
      "169 / 1176\n",
      "170 / 1176\n",
      "171 / 1176\n",
      "172 / 1176\n",
      "173 / 1176\n",
      "174 / 1176\n",
      "175 / 1176\n",
      "176 / 1176\n",
      "177 / 1176\n",
      "178 / 1176\n",
      "179 / 1176\n",
      "180 / 1176\n",
      "181 / 1176\n",
      "182 / 1176\n",
      "183 / 1176\n",
      "184 / 1176\n",
      "185 / 1176\n",
      "186 / 1176\n",
      "187 / 1176\n",
      "188 / 1176\n",
      "189 / 1176\n",
      "190 / 1176\n",
      "191 / 1176\n",
      "192 / 1176\n",
      "193 / 1176\n",
      "194 / 1176\n",
      "195 / 1176\n",
      "196 / 1176\n",
      "197 / 1176\n",
      "198 / 1176\n",
      "199 / 1176\n",
      "200 / 1176\n",
      "201 / 1176\n",
      "202 / 1176\n",
      "203 / 1176\n",
      "204 / 1176\n",
      "205 / 1176\n",
      "206 / 1176\n",
      "207 / 1176\n",
      "208 / 1176\n",
      "209 / 1176\n",
      "210 / 1176\n",
      "211 / 1176\n",
      "212 / 1176\n",
      "213 / 1176\n",
      "214 / 1176\n",
      "215 / 1176\n",
      "216 / 1176\n",
      "217 / 1176\n",
      "218 / 1176\n",
      "219 / 1176\n",
      "220 / 1176\n",
      "221 / 1176\n",
      "222 / 1176\n",
      "223 / 1176\n",
      "224 / 1176\n",
      "225 / 1176\n",
      "226 / 1176\n",
      "227 / 1176\n",
      "228 / 1176\n",
      "229 / 1176\n",
      "230 / 1176\n",
      "231 / 1176\n",
      "232 / 1176\n",
      "233 / 1176\n",
      "234 / 1176\n",
      "235 / 1176\n",
      "236 / 1176\n",
      "237 / 1176\n",
      "238 / 1176\n",
      "239 / 1176\n",
      "240 / 1176\n",
      "241 / 1176\n",
      "242 / 1176\n",
      "243 / 1176\n",
      "244 / 1176\n",
      "245 / 1176\n",
      "246 / 1176\n",
      "247 / 1176\n",
      "248 / 1176\n",
      "249 / 1176\n",
      "250 / 1176\n",
      "251 / 1176\n",
      "252 / 1176\n",
      "253 / 1176\n",
      "254 / 1176\n",
      "255 / 1176\n",
      "256 / 1176\n",
      "257 / 1176\n",
      "258 / 1176\n",
      "259 / 1176\n",
      "260 / 1176\n",
      "261 / 1176\n",
      "262 / 1176\n",
      "263 / 1176\n",
      "264 / 1176\n",
      "265 / 1176\n",
      "266 / 1176\n",
      "267 / 1176\n",
      "268 / 1176\n",
      "269 / 1176\n",
      "270 / 1176\n",
      "271 / 1176\n",
      "272 / 1176\n",
      "273 / 1176\n",
      "274 / 1176\n",
      "275 / 1176\n",
      "276 / 1176\n",
      "277 / 1176\n",
      "278 / 1176\n",
      "279 / 1176\n",
      "280 / 1176\n",
      "281 / 1176\n",
      "282 / 1176\n",
      "283 / 1176\n",
      "284 / 1176\n",
      "285 / 1176\n",
      "286 / 1176\n",
      "287 / 1176\n",
      "288 / 1176\n",
      "289 / 1176\n",
      "290 / 1176\n",
      "291 / 1176\n",
      "292 / 1176\n",
      "293 / 1176\n",
      "294 / 1176\n",
      "295 / 1176\n",
      "296 / 1176\n",
      "297 / 1176\n",
      "298 / 1176\n",
      "299 / 1176\n",
      "300 / 1176\n",
      "301 / 1176\n",
      "302 / 1176\n",
      "303 / 1176\n",
      "304 / 1176\n",
      "305 / 1176\n",
      "306 / 1176\n",
      "307 / 1176\n",
      "308 / 1176\n",
      "309 / 1176\n",
      "310 / 1176\n",
      "311 / 1176\n",
      "312 / 1176\n",
      "313 / 1176\n",
      "314 / 1176\n",
      "315 / 1176\n",
      "316 / 1176\n",
      "317 / 1176\n",
      "318 / 1176\n",
      "319 / 1176\n",
      "320 / 1176\n",
      "321 / 1176\n",
      "322 / 1176\n",
      "323 / 1176\n",
      "324 / 1176\n",
      "325 / 1176\n",
      "326 / 1176\n",
      "327 / 1176\n",
      "328 / 1176\n",
      "329 / 1176\n",
      "330 / 1176\n",
      "331 / 1176\n",
      "332 / 1176\n",
      "333 / 1176\n",
      "334 / 1176\n",
      "335 / 1176\n",
      "336 / 1176\n",
      "337 / 1176\n",
      "338 / 1176\n",
      "339 / 1176\n",
      "340 / 1176\n",
      "341 / 1176\n",
      "342 / 1176\n",
      "343 / 1176\n",
      "344 / 1176\n",
      "345 / 1176\n",
      "346 / 1176\n",
      "347 / 1176\n",
      "348 / 1176\n",
      "349 / 1176\n",
      "350 / 1176\n",
      "351 / 1176\n",
      "352 / 1176\n",
      "353 / 1176\n",
      "354 / 1176\n",
      "355 / 1176\n",
      "356 / 1176\n",
      "357 / 1176\n",
      "358 / 1176\n",
      "359 / 1176\n",
      "360 / 1176\n",
      "361 / 1176\n",
      "362 / 1176\n",
      "363 / 1176\n",
      "364 / 1176\n",
      "365 / 1176\n",
      "366 / 1176\n",
      "367 / 1176\n",
      "368 / 1176\n",
      "369 / 1176\n",
      "370 / 1176\n",
      "371 / 1176\n",
      "372 / 1176\n",
      "373 / 1176\n",
      "374 / 1176\n",
      "375 / 1176\n",
      "376 / 1176\n",
      "377 / 1176\n",
      "378 / 1176\n",
      "379 / 1176\n",
      "380 / 1176\n",
      "381 / 1176\n",
      "382 / 1176\n",
      "383 / 1176\n",
      "384 / 1176\n",
      "385 / 1176\n",
      "386 / 1176\n",
      "387 / 1176\n",
      "388 / 1176\n",
      "389 / 1176\n",
      "390 / 1176\n",
      "391 / 1176\n",
      "392 / 1176\n",
      "393 / 1176\n",
      "394 / 1176\n",
      "395 / 1176\n",
      "396 / 1176\n",
      "397 / 1176\n",
      "398 / 1176\n",
      "399 / 1176\n",
      "400 / 1176\n",
      "401 / 1176\n",
      "402 / 1176\n",
      "403 / 1176\n",
      "404 / 1176\n",
      "405 / 1176\n",
      "406 / 1176\n",
      "407 / 1176\n",
      "408 / 1176\n",
      "409 / 1176\n",
      "410 / 1176\n",
      "411 / 1176\n",
      "412 / 1176\n",
      "413 / 1176\n",
      "414 / 1176\n",
      "415 / 1176\n",
      "416 / 1176\n",
      "417 / 1176\n",
      "418 / 1176\n",
      "419 / 1176\n",
      "420 / 1176\n",
      "421 / 1176\n",
      "422 / 1176\n",
      "423 / 1176\n",
      "424 / 1176\n",
      "425 / 1176\n",
      "426 / 1176\n",
      "427 / 1176\n",
      "428 / 1176\n",
      "429 / 1176\n",
      "430 / 1176\n",
      "431 / 1176\n",
      "432 / 1176\n",
      "433 / 1176\n",
      "434 / 1176\n",
      "435 / 1176\n",
      "436 / 1176\n",
      "437 / 1176\n",
      "438 / 1176\n",
      "439 / 1176\n",
      "440 / 1176\n",
      "441 / 1176\n",
      "442 / 1176\n",
      "443 / 1176\n",
      "444 / 1176\n",
      "445 / 1176\n",
      "446 / 1176\n",
      "447 / 1176\n",
      "448 / 1176\n",
      "449 / 1176\n",
      "450 / 1176\n",
      "451 / 1176\n",
      "452 / 1176\n",
      "453 / 1176\n",
      "454 / 1176\n",
      "455 / 1176\n",
      "456 / 1176\n",
      "457 / 1176\n",
      "458 / 1176\n",
      "459 / 1176\n",
      "460 / 1176\n",
      "461 / 1176\n",
      "462 / 1176\n",
      "463 / 1176\n",
      "464 / 1176\n",
      "465 / 1176\n",
      "466 / 1176\n",
      "467 / 1176\n",
      "468 / 1176\n",
      "469 / 1176\n",
      "470 / 1176\n",
      "471 / 1176\n",
      "472 / 1176\n",
      "473 / 1176\n",
      "474 / 1176\n",
      "475 / 1176\n",
      "476 / 1176\n",
      "477 / 1176\n",
      "478 / 1176\n",
      "479 / 1176\n",
      "480 / 1176\n",
      "481 / 1176\n",
      "482 / 1176\n",
      "483 / 1176\n",
      "484 / 1176\n",
      "485 / 1176\n",
      "486 / 1176\n",
      "487 / 1176\n",
      "488 / 1176\n",
      "489 / 1176\n",
      "490 / 1176\n",
      "491 / 1176\n",
      "492 / 1176\n",
      "493 / 1176\n",
      "494 / 1176\n",
      "495 / 1176\n",
      "496 / 1176\n",
      "497 / 1176\n",
      "498 / 1176\n",
      "499 / 1176\n",
      "500 / 1176\n",
      "501 / 1176\n",
      "502 / 1176\n",
      "503 / 1176\n",
      "504 / 1176\n",
      "505 / 1176\n",
      "506 / 1176\n",
      "507 / 1176\n",
      "508 / 1176\n",
      "509 / 1176\n",
      "510 / 1176\n",
      "511 / 1176\n",
      "512 / 1176\n",
      "513 / 1176\n",
      "514 / 1176\n",
      "515 / 1176\n",
      "516 / 1176\n",
      "517 / 1176\n",
      "518 / 1176\n",
      "519 / 1176\n",
      "520 / 1176\n",
      "521 / 1176\n",
      "522 / 1176\n",
      "523 / 1176\n",
      "524 / 1176\n",
      "525 / 1176\n",
      "526 / 1176\n",
      "527 / 1176\n",
      "528 / 1176\n",
      "529 / 1176\n",
      "530 / 1176\n",
      "531 / 1176\n",
      "532 / 1176\n",
      "533 / 1176\n",
      "534 / 1176\n",
      "535 / 1176\n",
      "536 / 1176\n",
      "537 / 1176\n",
      "538 / 1176\n",
      "539 / 1176\n",
      "540 / 1176\n",
      "541 / 1176\n",
      "542 / 1176\n",
      "543 / 1176\n",
      "544 / 1176\n",
      "545 / 1176\n",
      "546 / 1176\n",
      "547 / 1176\n",
      "548 / 1176\n",
      "549 / 1176\n",
      "550 / 1176\n",
      "551 / 1176\n",
      "552 / 1176\n",
      "553 / 1176\n",
      "554 / 1176\n",
      "555 / 1176\n",
      "556 / 1176\n",
      "557 / 1176\n",
      "558 / 1176\n",
      "559 / 1176\n",
      "560 / 1176\n",
      "561 / 1176\n",
      "562 / 1176\n",
      "563 / 1176\n",
      "564 / 1176\n",
      "565 / 1176\n",
      "566 / 1176\n",
      "567 / 1176\n",
      "568 / 1176\n",
      "569 / 1176\n",
      "570 / 1176\n",
      "571 / 1176\n",
      "572 / 1176\n",
      "573 / 1176\n",
      "574 / 1176\n",
      "575 / 1176\n",
      "576 / 1176\n",
      "577 / 1176\n",
      "578 / 1176\n",
      "579 / 1176\n",
      "580 / 1176\n",
      "581 / 1176\n",
      "582 / 1176\n",
      "583 / 1176\n",
      "584 / 1176\n",
      "585 / 1176\n",
      "586 / 1176\n",
      "587 / 1176\n",
      "588 / 1176\n",
      "589 / 1176\n",
      "590 / 1176\n",
      "591 / 1176\n",
      "592 / 1176\n",
      "593 / 1176\n",
      "594 / 1176\n",
      "595 / 1176\n",
      "596 / 1176\n",
      "597 / 1176\n",
      "598 / 1176\n",
      "599 / 1176\n",
      "600 / 1176\n",
      "601 / 1176\n",
      "602 / 1176\n",
      "603 / 1176\n",
      "604 / 1176\n",
      "605 / 1176\n",
      "606 / 1176\n",
      "607 / 1176\n",
      "608 / 1176\n",
      "609 / 1176\n",
      "610 / 1176\n",
      "611 / 1176\n",
      "612 / 1176\n",
      "613 / 1176\n",
      "614 / 1176\n",
      "615 / 1176\n",
      "616 / 1176\n",
      "617 / 1176\n",
      "618 / 1176\n",
      "619 / 1176\n",
      "620 / 1176\n",
      "621 / 1176\n",
      "622 / 1176\n",
      "623 / 1176\n",
      "624 / 1176\n",
      "625 / 1176\n",
      "626 / 1176\n",
      "627 / 1176\n",
      "628 / 1176\n",
      "629 / 1176\n",
      "630 / 1176\n",
      "631 / 1176\n",
      "632 / 1176\n",
      "633 / 1176\n",
      "634 / 1176\n",
      "635 / 1176\n",
      "636 / 1176\n",
      "637 / 1176\n",
      "638 / 1176\n",
      "639 / 1176\n",
      "640 / 1176\n",
      "641 / 1176\n",
      "642 / 1176\n",
      "643 / 1176\n",
      "644 / 1176\n",
      "645 / 1176\n",
      "646 / 1176\n",
      "647 / 1176\n",
      "648 / 1176\n",
      "649 / 1176\n",
      "650 / 1176\n",
      "651 / 1176\n",
      "652 / 1176\n",
      "653 / 1176\n",
      "654 / 1176\n",
      "655 / 1176\n",
      "656 / 1176\n",
      "657 / 1176\n",
      "658 / 1176\n",
      "659 / 1176\n",
      "660 / 1176\n",
      "661 / 1176\n",
      "662 / 1176\n",
      "663 / 1176\n",
      "664 / 1176\n",
      "665 / 1176\n",
      "666 / 1176\n",
      "667 / 1176\n",
      "668 / 1176\n",
      "669 / 1176\n",
      "670 / 1176\n",
      "671 / 1176\n",
      "672 / 1176\n",
      "673 / 1176\n",
      "674 / 1176\n",
      "675 / 1176\n",
      "676 / 1176\n",
      "677 / 1176\n",
      "678 / 1176\n",
      "679 / 1176\n",
      "680 / 1176\n",
      "681 / 1176\n",
      "682 / 1176\n",
      "683 / 1176\n",
      "684 / 1176\n",
      "685 / 1176\n",
      "686 / 1176\n",
      "687 / 1176\n",
      "688 / 1176\n",
      "689 / 1176\n",
      "690 / 1176\n",
      "691 / 1176\n",
      "692 / 1176\n",
      "693 / 1176\n",
      "694 / 1176\n",
      "695 / 1176\n",
      "696 / 1176\n",
      "697 / 1176\n",
      "698 / 1176\n",
      "699 / 1176\n",
      "700 / 1176\n",
      "701 / 1176\n",
      "702 / 1176\n",
      "703 / 1176\n",
      "704 / 1176\n",
      "705 / 1176\n",
      "706 / 1176\n",
      "707 / 1176\n",
      "708 / 1176\n",
      "709 / 1176\n",
      "710 / 1176\n",
      "711 / 1176\n",
      "712 / 1176\n",
      "713 / 1176\n",
      "714 / 1176\n",
      "715 / 1176\n",
      "716 / 1176\n",
      "717 / 1176\n",
      "718 / 1176\n",
      "719 / 1176\n",
      "720 / 1176\n",
      "721 / 1176\n",
      "722 / 1176\n",
      "723 / 1176\n",
      "724 / 1176\n",
      "725 / 1176\n",
      "726 / 1176\n",
      "727 / 1176\n",
      "728 / 1176\n",
      "729 / 1176\n",
      "730 / 1176\n",
      "731 / 1176\n",
      "732 / 1176\n",
      "733 / 1176\n",
      "734 / 1176\n",
      "735 / 1176\n",
      "736 / 1176\n",
      "737 / 1176\n",
      "738 / 1176\n",
      "739 / 1176\n",
      "740 / 1176\n",
      "741 / 1176\n",
      "742 / 1176\n",
      "743 / 1176\n",
      "744 / 1176\n",
      "745 / 1176\n",
      "746 / 1176\n",
      "747 / 1176\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "748 / 1176\n",
      "749 / 1176\n",
      "750 / 1176\n",
      "751 / 1176\n",
      "752 / 1176\n",
      "753 / 1176\n",
      "754 / 1176\n",
      "755 / 1176\n",
      "756 / 1176\n",
      "757 / 1176\n",
      "758 / 1176\n",
      "759 / 1176\n",
      "760 / 1176\n",
      "761 / 1176\n",
      "762 / 1176\n",
      "763 / 1176\n",
      "764 / 1176\n",
      "765 / 1176\n",
      "766 / 1176\n",
      "767 / 1176\n",
      "768 / 1176\n",
      "769 / 1176\n",
      "770 / 1176\n",
      "771 / 1176\n",
      "772 / 1176\n",
      "773 / 1176\n",
      "774 / 1176\n",
      "775 / 1176\n",
      "776 / 1176\n",
      "777 / 1176\n",
      "778 / 1176\n",
      "779 / 1176\n",
      "780 / 1176\n",
      "781 / 1176\n",
      "782 / 1176\n",
      "783 / 1176\n",
      "784 / 1176\n",
      "785 / 1176\n",
      "786 / 1176\n",
      "787 / 1176\n",
      "788 / 1176\n",
      "789 / 1176\n",
      "790 / 1176\n",
      "791 / 1176\n",
      "792 / 1176\n",
      "793 / 1176\n",
      "794 / 1176\n",
      "795 / 1176\n",
      "796 / 1176\n",
      "797 / 1176\n",
      "798 / 1176\n",
      "799 / 1176\n",
      "800 / 1176\n",
      "801 / 1176\n",
      "802 / 1176\n",
      "803 / 1176\n",
      "804 / 1176\n",
      "805 / 1176\n",
      "806 / 1176\n",
      "807 / 1176\n",
      "808 / 1176\n",
      "809 / 1176\n",
      "810 / 1176\n",
      "811 / 1176\n",
      "812 / 1176\n",
      "813 / 1176\n",
      "814 / 1176\n",
      "815 / 1176\n",
      "816 / 1176\n",
      "817 / 1176\n",
      "818 / 1176\n",
      "819 / 1176\n",
      "820 / 1176\n",
      "821 / 1176\n",
      "822 / 1176\n",
      "823 / 1176\n",
      "824 / 1176\n",
      "825 / 1176\n",
      "826 / 1176\n",
      "827 / 1176\n",
      "828 / 1176\n",
      "829 / 1176\n",
      "830 / 1176\n",
      "831 / 1176\n",
      "832 / 1176\n",
      "833 / 1176\n",
      "834 / 1176\n",
      "835 / 1176\n",
      "836 / 1176\n",
      "837 / 1176\n",
      "838 / 1176\n",
      "839 / 1176\n",
      "840 / 1176\n",
      "841 / 1176\n",
      "842 / 1176\n",
      "843 / 1176\n",
      "844 / 1176\n",
      "845 / 1176\n",
      "846 / 1176\n",
      "847 / 1176\n",
      "848 / 1176\n",
      "849 / 1176\n",
      "850 / 1176\n",
      "851 / 1176\n",
      "852 / 1176\n",
      "853 / 1176\n",
      "854 / 1176\n",
      "855 / 1176\n",
      "856 / 1176\n",
      "857 / 1176\n",
      "858 / 1176\n",
      "859 / 1176\n",
      "860 / 1176\n",
      "861 / 1176\n",
      "862 / 1176\n",
      "863 / 1176\n",
      "864 / 1176\n",
      "865 / 1176\n",
      "866 / 1176\n",
      "867 / 1176\n",
      "868 / 1176\n",
      "869 / 1176\n",
      "870 / 1176\n",
      "871 / 1176\n",
      "872 / 1176\n",
      "873 / 1176\n",
      "874 / 1176\n",
      "875 / 1176\n",
      "876 / 1176\n",
      "877 / 1176\n",
      "878 / 1176\n",
      "879 / 1176\n",
      "880 / 1176\n",
      "881 / 1176\n",
      "882 / 1176\n",
      "883 / 1176\n",
      "884 / 1176\n",
      "885 / 1176\n",
      "886 / 1176\n",
      "887 / 1176\n",
      "888 / 1176\n",
      "889 / 1176\n",
      "890 / 1176\n",
      "891 / 1176\n",
      "892 / 1176\n",
      "893 / 1176\n",
      "894 / 1176\n",
      "895 / 1176\n",
      "896 / 1176\n",
      "897 / 1176\n",
      "898 / 1176\n",
      "899 / 1176\n",
      "900 / 1176\n",
      "901 / 1176\n",
      "902 / 1176\n",
      "903 / 1176\n",
      "904 / 1176\n",
      "905 / 1176\n",
      "906 / 1176\n",
      "907 / 1176\n",
      "908 / 1176\n",
      "909 / 1176\n",
      "910 / 1176\n",
      "911 / 1176\n",
      "912 / 1176\n",
      "913 / 1176\n",
      "914 / 1176\n",
      "915 / 1176\n",
      "916 / 1176\n",
      "917 / 1176\n",
      "918 / 1176\n",
      "919 / 1176\n",
      "920 / 1176\n",
      "921 / 1176\n",
      "922 / 1176\n",
      "923 / 1176\n",
      "924 / 1176\n",
      "925 / 1176\n",
      "926 / 1176\n",
      "927 / 1176\n",
      "928 / 1176\n",
      "929 / 1176\n",
      "930 / 1176\n",
      "931 / 1176\n",
      "932 / 1176\n",
      "933 / 1176\n",
      "934 / 1176\n",
      "935 / 1176\n",
      "936 / 1176\n",
      "937 / 1176\n",
      "938 / 1176\n",
      "939 / 1176\n",
      "940 / 1176\n",
      "941 / 1176\n",
      "942 / 1176\n",
      "943 / 1176\n",
      "944 / 1176\n",
      "945 / 1176\n",
      "946 / 1176\n",
      "947 / 1176\n",
      "948 / 1176\n",
      "949 / 1176\n",
      "950 / 1176\n",
      "951 / 1176\n",
      "952 / 1176\n",
      "953 / 1176\n",
      "954 / 1176\n",
      "955 / 1176\n",
      "956 / 1176\n",
      "957 / 1176\n",
      "958 / 1176\n",
      "959 / 1176\n",
      "960 / 1176\n",
      "961 / 1176\n",
      "962 / 1176\n",
      "963 / 1176\n",
      "964 / 1176\n",
      "965 / 1176\n",
      "966 / 1176\n",
      "967 / 1176\n",
      "968 / 1176\n",
      "969 / 1176\n",
      "970 / 1176\n",
      "971 / 1176\n",
      "972 / 1176\n",
      "973 / 1176\n",
      "974 / 1176\n",
      "975 / 1176\n",
      "976 / 1176\n",
      "977 / 1176\n",
      "978 / 1176\n",
      "979 / 1176\n",
      "980 / 1176\n",
      "981 / 1176\n",
      "982 / 1176\n",
      "983 / 1176\n",
      "984 / 1176\n",
      "985 / 1176\n",
      "986 / 1176\n",
      "987 / 1176\n",
      "988 / 1176\n",
      "989 / 1176\n",
      "990 / 1176\n",
      "991 / 1176\n",
      "992 / 1176\n",
      "993 / 1176\n",
      "994 / 1176\n",
      "995 / 1176\n",
      "996 / 1176\n",
      "997 / 1176\n",
      "998 / 1176\n",
      "999 / 1176\n",
      "1000 / 1176\n",
      "1001 / 1176\n",
      "1002 / 1176\n",
      "1003 / 1176\n",
      "1004 / 1176\n",
      "1005 / 1176\n",
      "1006 / 1176\n",
      "1007 / 1176\n",
      "1008 / 1176\n",
      "1009 / 1176\n",
      "1010 / 1176\n",
      "1011 / 1176\n",
      "1012 / 1176\n",
      "1013 / 1176\n",
      "1014 / 1176\n",
      "1015 / 1176\n",
      "1016 / 1176\n",
      "1017 / 1176\n",
      "1018 / 1176\n",
      "1019 / 1176\n",
      "1020 / 1176\n",
      "1021 / 1176\n",
      "1022 / 1176\n",
      "1023 / 1176\n",
      "1024 / 1176\n",
      "1025 / 1176\n",
      "1026 / 1176\n",
      "1027 / 1176\n",
      "1028 / 1176\n",
      "1029 / 1176\n",
      "1030 / 1176\n",
      "1031 / 1176\n",
      "1032 / 1176\n",
      "1033 / 1176\n",
      "1034 / 1176\n",
      "1035 / 1176\n",
      "1036 / 1176\n",
      "1037 / 1176\n",
      "1038 / 1176\n",
      "1039 / 1176\n",
      "1040 / 1176\n",
      "1041 / 1176\n",
      "1042 / 1176\n",
      "1043 / 1176\n",
      "1044 / 1176\n",
      "1045 / 1176\n",
      "1046 / 1176\n",
      "1047 / 1176\n",
      "1048 / 1176\n",
      "1049 / 1176\n",
      "1050 / 1176\n",
      "1051 / 1176\n",
      "1052 / 1176\n",
      "1053 / 1176\n",
      "1054 / 1176\n",
      "1055 / 1176\n",
      "1056 / 1176\n",
      "1057 / 1176\n",
      "1058 / 1176\n",
      "1059 / 1176\n",
      "1060 / 1176\n",
      "1061 / 1176\n",
      "1062 / 1176\n",
      "1063 / 1176\n",
      "1064 / 1176\n",
      "1065 / 1176\n",
      "1066 / 1176\n",
      "1067 / 1176\n",
      "1068 / 1176\n",
      "1069 / 1176\n",
      "1070 / 1176\n",
      "1071 / 1176\n",
      "1072 / 1176\n",
      "1073 / 1176\n",
      "1074 / 1176\n",
      "1075 / 1176\n",
      "1076 / 1176\n",
      "1077 / 1176\n",
      "1078 / 1176\n",
      "1079 / 1176\n",
      "1080 / 1176\n",
      "1081 / 1176\n",
      "1082 / 1176\n",
      "1083 / 1176\n",
      "1084 / 1176\n",
      "1085 / 1176\n",
      "1086 / 1176\n",
      "1087 / 1176\n",
      "1088 / 1176\n",
      "1089 / 1176\n",
      "1090 / 1176\n",
      "1091 / 1176\n",
      "1092 / 1176\n",
      "1093 / 1176\n",
      "1094 / 1176\n",
      "1095 / 1176\n",
      "1096 / 1176\n",
      "1097 / 1176\n",
      "1098 / 1176\n",
      "1099 / 1176\n",
      "1100 / 1176\n",
      "1101 / 1176\n",
      "1102 / 1176\n",
      "1103 / 1176\n",
      "1104 / 1176\n",
      "1105 / 1176\n",
      "1106 / 1176\n",
      "1107 / 1176\n",
      "1108 / 1176\n",
      "1109 / 1176\n",
      "1110 / 1176\n",
      "1111 / 1176\n",
      "1112 / 1176\n",
      "1113 / 1176\n",
      "1114 / 1176\n",
      "1115 / 1176\n",
      "1116 / 1176\n",
      "1117 / 1176\n",
      "1118 / 1176\n",
      "1119 / 1176\n",
      "1120 / 1176\n",
      "1121 / 1176\n",
      "1122 / 1176\n",
      "1123 / 1176\n",
      "1124 / 1176\n",
      "1125 / 1176\n",
      "1126 / 1176\n",
      "1127 / 1176\n",
      "1128 / 1176\n",
      "1129 / 1176\n",
      "1130 / 1176\n",
      "1131 / 1176\n",
      "1132 / 1176\n",
      "1133 / 1176\n",
      "1134 / 1176\n",
      "1135 / 1176\n",
      "1136 / 1176\n",
      "1137 / 1176\n",
      "1138 / 1176\n",
      "1139 / 1176\n",
      "1140 / 1176\n",
      "1141 / 1176\n",
      "1142 / 1176\n",
      "1143 / 1176\n",
      "1144 / 1176\n",
      "1145 / 1176\n",
      "1146 / 1176\n",
      "1147 / 1176\n",
      "1148 / 1176\n",
      "1149 / 1176\n",
      "1150 / 1176\n",
      "1151 / 1176\n",
      "1152 / 1176\n",
      "1153 / 1176\n",
      "1154 / 1176\n",
      "1155 / 1176\n",
      "1156 / 1176\n",
      "1157 / 1176\n",
      "1158 / 1176\n",
      "1159 / 1176\n",
      "1160 / 1176\n",
      "1161 / 1176\n",
      "1162 / 1176\n",
      "1163 / 1176\n",
      "1164 / 1176\n",
      "1165 / 1176\n",
      "1166 / 1176\n",
      "1167 / 1176\n",
      "1168 / 1176\n",
      "1169 / 1176\n",
      "1170 / 1176\n",
      "1171 / 1176\n",
      "1172 / 1176\n",
      "1173 / 1176\n",
      "1174 / 1176\n",
      "1175 / 1176\n",
      "1176 / 1176\n",
      "531  Files found\n",
      "Loading images...\n",
      "1 / 531\n",
      "2 / 531\n",
      "3 / 531\n",
      "4 / 531\n",
      "5 / 531\n",
      "6 / 531\n",
      "7 / 531\n",
      "8 / 531\n",
      "9 / 531\n",
      "10 / 531\n",
      "11 / 531\n",
      "12 / 531\n",
      "13 / 531\n",
      "14 / 531\n",
      "15 / 531\n",
      "16 / 531\n",
      "17 / 531\n",
      "18 / 531\n",
      "19 / 531\n",
      "20 / 531\n",
      "21 / 531\n",
      "22 / 531\n",
      "23 / 531\n",
      "24 / 531\n",
      "25 / 531\n",
      "26 / 531\n",
      "27 / 531\n",
      "28 / 531\n",
      "29 / 531\n",
      "30 / 531\n",
      "31 / 531\n",
      "32 / 531\n",
      "33 / 531\n",
      "34 / 531\n",
      "35 / 531\n",
      "36 / 531\n",
      "37 / 531\n",
      "38 / 531\n",
      "39 / 531\n",
      "40 / 531\n",
      "41 / 531\n",
      "42 / 531\n",
      "43 / 531\n",
      "44 / 531\n",
      "45 / 531\n",
      "46 / 531\n",
      "47 / 531\n",
      "48 / 531\n",
      "49 / 531\n",
      "50 / 531\n",
      "51 / 531\n",
      "52 / 531\n",
      "53 / 531\n",
      "54 / 531\n",
      "55 / 531\n",
      "56 / 531\n",
      "57 / 531\n",
      "58 / 531\n",
      "59 / 531\n",
      "60 / 531\n",
      "61 / 531\n",
      "62 / 531\n",
      "63 / 531\n",
      "64 / 531\n",
      "65 / 531\n",
      "66 / 531\n",
      "67 / 531\n",
      "68 / 531\n",
      "69 / 531\n",
      "70 / 531\n",
      "71 / 531\n",
      "72 / 531\n",
      "73 / 531\n",
      "74 / 531\n",
      "75 / 531\n",
      "76 / 531\n",
      "77 / 531\n",
      "78 / 531\n",
      "79 / 531\n",
      "80 / 531\n",
      "81 / 531\n",
      "82 / 531\n",
      "83 / 531\n",
      "84 / 531\n",
      "85 / 531\n",
      "86 / 531\n",
      "87 / 531\n",
      "88 / 531\n",
      "89 / 531\n",
      "90 / 531\n",
      "91 / 531\n",
      "92 / 531\n",
      "93 / 531\n",
      "94 / 531\n",
      "95 / 531\n",
      "96 / 531\n",
      "97 / 531\n",
      "98 / 531\n",
      "99 / 531\n",
      "100 / 531\n",
      "101 / 531\n",
      "102 / 531\n",
      "103 / 531\n",
      "104 / 531\n",
      "105 / 531\n",
      "106 / 531\n",
      "107 / 531\n",
      "108 / 531\n",
      "109 / 531\n",
      "110 / 531\n",
      "111 / 531\n",
      "112 / 531\n",
      "113 / 531\n",
      "114 / 531\n",
      "115 / 531\n",
      "116 / 531\n",
      "117 / 531\n",
      "118 / 531\n",
      "119 / 531\n",
      "120 / 531\n",
      "121 / 531\n",
      "122 / 531\n",
      "123 / 531\n",
      "124 / 531\n",
      "125 / 531\n",
      "126 / 531\n",
      "127 / 531\n",
      "128 / 531\n",
      "129 / 531\n",
      "130 / 531\n",
      "131 / 531\n",
      "132 / 531\n",
      "133 / 531\n",
      "134 / 531\n",
      "135 / 531\n",
      "136 / 531\n",
      "137 / 531\n",
      "138 / 531\n",
      "139 / 531\n",
      "140 / 531\n",
      "141 / 531\n",
      "142 / 531\n",
      "143 / 531\n",
      "144 / 531\n",
      "145 / 531\n",
      "146 / 531\n",
      "147 / 531\n",
      "148 / 531\n",
      "149 / 531\n",
      "150 / 531\n",
      "151 / 531\n",
      "152 / 531\n",
      "153 / 531\n",
      "154 / 531\n",
      "155 / 531\n",
      "156 / 531\n",
      "157 / 531\n",
      "158 / 531\n",
      "159 / 531\n",
      "160 / 531\n",
      "161 / 531\n",
      "162 / 531\n",
      "163 / 531\n",
      "164 / 531\n",
      "165 / 531\n",
      "166 / 531\n",
      "167 / 531\n",
      "168 / 531\n",
      "169 / 531\n",
      "170 / 531\n",
      "171 / 531\n",
      "172 / 531\n",
      "173 / 531\n",
      "174 / 531\n",
      "175 / 531\n",
      "176 / 531\n",
      "177 / 531\n",
      "178 / 531\n",
      "179 / 531\n",
      "180 / 531\n",
      "181 / 531\n",
      "182 / 531\n",
      "183 / 531\n",
      "184 / 531\n",
      "185 / 531\n",
      "186 / 531\n",
      "187 / 531\n",
      "188 / 531\n",
      "189 / 531\n",
      "190 / 531\n",
      "191 / 531\n",
      "192 / 531\n",
      "193 / 531\n",
      "194 / 531\n",
      "195 / 531\n",
      "196 / 531\n",
      "197 / 531\n",
      "198 / 531\n",
      "199 / 531\n",
      "200 / 531\n",
      "201 / 531\n",
      "202 / 531\n",
      "203 / 531\n",
      "204 / 531\n",
      "205 / 531\n",
      "206 / 531\n",
      "207 / 531\n",
      "208 / 531\n",
      "209 / 531\n",
      "210 / 531\n",
      "211 / 531\n",
      "212 / 531\n",
      "213 / 531\n",
      "214 / 531\n",
      "215 / 531\n",
      "216 / 531\n",
      "217 / 531\n",
      "218 / 531\n",
      "219 / 531\n",
      "220 / 531\n",
      "221 / 531\n",
      "222 / 531\n",
      "223 / 531\n",
      "224 / 531\n",
      "225 / 531\n",
      "226 / 531\n",
      "227 / 531\n",
      "228 / 531\n",
      "229 / 531\n",
      "230 / 531\n",
      "231 / 531\n",
      "232 / 531\n",
      "233 / 531\n",
      "234 / 531\n",
      "235 / 531\n",
      "236 / 531\n",
      "237 / 531\n",
      "238 / 531\n",
      "239 / 531\n",
      "240 / 531\n",
      "241 / 531\n",
      "242 / 531\n",
      "243 / 531\n",
      "244 / 531\n",
      "245 / 531\n",
      "246 / 531\n",
      "247 / 531\n",
      "248 / 531\n",
      "249 / 531\n",
      "250 / 531\n",
      "251 / 531\n",
      "252 / 531\n",
      "253 / 531\n",
      "254 / 531\n",
      "255 / 531\n",
      "256 / 531\n",
      "257 / 531\n",
      "258 / 531\n",
      "259 / 531\n",
      "260 / 531\n",
      "261 / 531\n",
      "262 / 531\n",
      "263 / 531\n",
      "264 / 531\n",
      "265 / 531\n",
      "266 / 531\n",
      "267 / 531\n",
      "268 / 531\n",
      "269 / 531\n",
      "270 / 531\n",
      "271 / 531\n",
      "272 / 531\n",
      "273 / 531\n",
      "274 / 531\n",
      "275 / 531\n",
      "276 / 531\n",
      "277 / 531\n",
      "278 / 531\n",
      "279 / 531\n",
      "280 / 531\n",
      "281 / 531\n",
      "282 / 531\n",
      "283 / 531\n",
      "284 / 531\n",
      "285 / 531\n",
      "286 / 531\n",
      "287 / 531\n",
      "288 / 531\n",
      "289 / 531\n",
      "290 / 531\n",
      "291 / 531\n",
      "292 / 531\n",
      "293 / 531\n",
      "294 / 531\n",
      "295 / 531\n",
      "296 / 531\n",
      "297 / 531\n",
      "298 / 531\n",
      "299 / 531\n",
      "300 / 531\n",
      "301 / 531\n",
      "302 / 531\n",
      "303 / 531\n",
      "304 / 531\n",
      "305 / 531\n",
      "306 / 531\n",
      "307 / 531\n",
      "308 / 531\n",
      "309 / 531\n",
      "310 / 531\n",
      "311 / 531\n",
      "312 / 531\n",
      "313 / 531\n",
      "314 / 531\n",
      "315 / 531\n",
      "316 / 531\n",
      "317 / 531\n",
      "318 / 531\n",
      "319 / 531\n",
      "320 / 531\n",
      "321 / 531\n",
      "322 / 531\n",
      "323 / 531\n",
      "324 / 531\n",
      "325 / 531\n",
      "326 / 531\n",
      "327 / 531\n",
      "328 / 531\n",
      "329 / 531\n",
      "330 / 531\n",
      "331 / 531\n",
      "332 / 531\n",
      "333 / 531\n",
      "334 / 531\n",
      "335 / 531\n",
      "336 / 531\n",
      "337 / 531\n",
      "338 / 531\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "339 / 531\n",
      "340 / 531\n",
      "341 / 531\n",
      "342 / 531\n",
      "343 / 531\n",
      "344 / 531\n",
      "345 / 531\n",
      "346 / 531\n",
      "347 / 531\n",
      "348 / 531\n",
      "349 / 531\n",
      "350 / 531\n",
      "351 / 531\n",
      "352 / 531\n",
      "353 / 531\n",
      "354 / 531\n",
      "355 / 531\n",
      "356 / 531\n",
      "357 / 531\n",
      "358 / 531\n",
      "359 / 531\n",
      "360 / 531\n",
      "361 / 531\n",
      "362 / 531\n",
      "363 / 531\n",
      "364 / 531\n",
      "365 / 531\n",
      "366 / 531\n",
      "367 / 531\n",
      "368 / 531\n",
      "369 / 531\n",
      "370 / 531\n",
      "371 / 531\n",
      "372 / 531\n",
      "373 / 531\n",
      "374 / 531\n",
      "375 / 531\n",
      "376 / 531\n",
      "377 / 531\n",
      "378 / 531\n",
      "379 / 531\n",
      "380 / 531\n",
      "381 / 531\n",
      "382 / 531\n",
      "383 / 531\n",
      "384 / 531\n",
      "385 / 531\n",
      "386 / 531\n",
      "387 / 531\n",
      "388 / 531\n",
      "389 / 531\n",
      "390 / 531\n",
      "391 / 531\n",
      "392 / 531\n",
      "393 / 531\n",
      "394 / 531\n",
      "395 / 531\n",
      "396 / 531\n",
      "397 / 531\n",
      "398 / 531\n",
      "399 / 531\n",
      "400 / 531\n",
      "401 / 531\n",
      "402 / 531\n",
      "403 / 531\n",
      "404 / 531\n",
      "405 / 531\n",
      "406 / 531\n",
      "407 / 531\n",
      "408 / 531\n",
      "409 / 531\n",
      "410 / 531\n",
      "411 / 531\n",
      "412 / 531\n",
      "413 / 531\n",
      "414 / 531\n",
      "415 / 531\n",
      "416 / 531\n",
      "417 / 531\n",
      "418 / 531\n",
      "419 / 531\n",
      "420 / 531\n",
      "421 / 531\n",
      "422 / 531\n",
      "423 / 531\n",
      "424 / 531\n",
      "425 / 531\n",
      "426 / 531\n",
      "427 / 531\n",
      "428 / 531\n",
      "429 / 531\n",
      "430 / 531\n",
      "431 / 531\n",
      "432 / 531\n",
      "433 / 531\n",
      "434 / 531\n",
      "435 / 531\n",
      "436 / 531\n",
      "437 / 531\n",
      "438 / 531\n",
      "439 / 531\n",
      "440 / 531\n",
      "441 / 531\n",
      "442 / 531\n",
      "443 / 531\n",
      "444 / 531\n",
      "445 / 531\n",
      "446 / 531\n",
      "447 / 531\n",
      "448 / 531\n",
      "449 / 531\n",
      "450 / 531\n",
      "451 / 531\n",
      "452 / 531\n",
      "453 / 531\n",
      "454 / 531\n",
      "455 / 531\n",
      "456 / 531\n",
      "457 / 531\n",
      "458 / 531\n",
      "459 / 531\n",
      "460 / 531\n",
      "461 / 531\n",
      "462 / 531\n",
      "463 / 531\n",
      "464 / 531\n",
      "465 / 531\n",
      "466 / 531\n",
      "467 / 531\n",
      "468 / 531\n",
      "469 / 531\n",
      "470 / 531\n",
      "471 / 531\n",
      "472 / 531\n",
      "473 / 531\n",
      "474 / 531\n",
      "475 / 531\n",
      "476 / 531\n",
      "477 / 531\n",
      "478 / 531\n",
      "479 / 531\n",
      "480 / 531\n",
      "481 / 531\n",
      "482 / 531\n",
      "483 / 531\n",
      "484 / 531\n",
      "485 / 531\n",
      "486 / 531\n",
      "487 / 531\n",
      "488 / 531\n",
      "489 / 531\n",
      "490 / 531\n",
      "491 / 531\n",
      "492 / 531\n",
      "493 / 531\n",
      "494 / 531\n",
      "495 / 531\n",
      "496 / 531\n",
      "497 / 531\n",
      "498 / 531\n",
      "499 / 531\n",
      "500 / 531\n",
      "501 / 531\n",
      "502 / 531\n",
      "503 / 531\n",
      "504 / 531\n",
      "505 / 531\n",
      "506 / 531\n",
      "507 / 531\n",
      "508 / 531\n",
      "509 / 531\n",
      "510 / 531\n",
      "511 / 531\n",
      "512 / 531\n",
      "513 / 531\n",
      "514 / 531\n",
      "515 / 531\n",
      "516 / 531\n",
      "517 / 531\n",
      "518 / 531\n",
      "519 / 531\n",
      "520 / 531\n",
      "521 / 531\n",
      "522 / 531\n",
      "523 / 531\n",
      "524 / 531\n",
      "525 / 531\n",
      "526 / 531\n",
      "527 / 531\n",
      "528 / 531\n",
      "529 / 531\n",
      "530 / 531\n",
      "531 / 531\n",
      "prem1.shape:  (537, 429, 429, 1)\n",
      "prem2.shape:  (531, 429, 429, 1)\n",
      "data.shape =  (1068, 429, 429, 3)\n",
      "Train...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/user/HS204/wm0015/anaconda3/envs/tensorflow/lib/python3.6/site-packages/keras/callbacks.py:432: RuntimeWarning: Can save best model only with val_accuracy available, skipping.\n",
      "  'skipping.' % (self.monitor), RuntimeWarning)\n",
      "/user/HS204/wm0015/anaconda3/envs/tensorflow/lib/python3.6/site-packages/sklearn/metrics/ranking.py:571: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  UndefinedMetricWarning)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The score is......\n",
      " [1.0960467095915575e-07, 1.0, 1.0, 1.0]\n",
      "Train...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m-----------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-bf94109defc2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    424\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    425\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 426\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-20-bf94109defc2>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    389\u001b[0m                     \u001b[0mEarlyStopping\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmonitor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'val_loss'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpatience\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mPATIENCE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    390\u001b[0m                     ModelCheckpoint(filepath=MODEL_SAVE, monitor='val_accuracy', save_best_only=True)],\n\u001b[0;32m--> 391\u001b[0;31m                 validation_data=(val_data['img'], val_data['label']))\n\u001b[0m\u001b[1;32m    392\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m         \u001b[0;31m# Restore best model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1040\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1042\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1043\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1044\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.6/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2665\u001b[0m                     \u001b[0;34m'In order to feed symbolic tensors to a Keras model '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2666\u001b[0m                     'in TensorFlow, you need tensorflow 1.8 or higher.')\n\u001b[0;32m-> 2667\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2668\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2669\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_legacy_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2647\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2648\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[0;32m-> 2649\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2650\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2651\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    903\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    904\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 905\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    906\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    907\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1107\u001b[0m             \u001b[0mfeed_handles\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msubfeed_t\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msubfeed_val\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1108\u001b[0m           \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1109\u001b[0;31m             \u001b[0mnp_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubfeed_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msubfeed_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1110\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1111\u001b[0m           if (not is_tensor_handle_feed and\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.6/site-packages/numpy/core/numeric.py\u001b[0m in \u001b[0;36masarray\u001b[0;34m(a, dtype, order)\u001b[0m\n\u001b[1;32m    490\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m     \"\"\"\n\u001b[0;32m--> 492\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    493\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    494\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# fold\n",
    "import numpy as np\n",
    "import cv2\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "from keras.models import Sequential\n",
    "import keras\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.utils import np_utils\n",
    "from keras import optimizers\n",
    "# For some reason I have to tell it to use TensorFlows dimension ordering\n",
    "from keras import backend as K\n",
    "K.set_image_dim_ordering('tf')\n",
    "from keras.callbacks import TensorBoard, EarlyStopping, ModelCheckpoint\n",
    "from time import time\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from keras import applications\n",
    "from keras.utils import multi_gpu_model\n",
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "config = tf.ConfigProto()\n",
    "#config.gpu_options.per_process_gpu_memory_fraction = 0.5\n",
    "config.gpu_options.visible_device_list = \"2,3\"\n",
    "config.gpu_options.allow_growth = True\n",
    "set_session(tf.Session(config=config))\n",
    "\n",
    "# Globals\n",
    "VERBOSE = 0\n",
    "ARCHITECTURE = 0\n",
    "NORMALISE = 1\n",
    "# Class 0 = backgrounds\n",
    "CLASSDIR_0 = '/vol/vssp/cvpwrkspc01/scratch/wm0015/crops256/normal/*'\n",
    "CLASSDIR_1 = '/vol/vssp/cvpwrkspc01/scratch/wm0015/crops256/malignant/*'\n",
    "\n",
    "# Calcs\n",
    "#CLASSDIR_0 = '/user/HS204/wm0015/student/allCalcs/0/*'\n",
    "#CLASSDIR_1 = '/user/HS204/wm0015/student/allCalcs/1/*'\n",
    "MODEL_SAVE = '/vol/vssp/cvpwrkspc01/scratch/wm0015/models/best_model.h5'\n",
    "BATCH_SIZE = 100\n",
    "EPOCHS = 50\n",
    "#INPUT_SHAPE = [256, 256, 3]\n",
    "INPUT_SHAPE = [429, 429, 3]\n",
    "#INPUT_SHAPE = [385, 385, 3]\n",
    "FOLDS = 5\n",
    "PATIENCE = 500\n",
    "\n",
    "class TrainValTensorBoard(TensorBoard):\n",
    "    def __init__(self, log_dir='/vol/vssp/mammo2/will/logs/new', **kwargs):\n",
    "        # Make the original `TensorBoard` log to a subdirectory 'training'\n",
    "        fCount=0\n",
    "        while os.path.exists(os.path.join(log_dir, 'training' + '_' + str(fCount))):\n",
    "            fCount+=1\n",
    "        training_log_dir = os.path.join(log_dir, 'training' + '_' + str(fCount))\n",
    "        super(TrainValTensorBoard, self).__init__(training_log_dir, **kwargs)\n",
    "\n",
    "        # Log the validation metrics to a separate subdirectory\n",
    "        self.val_log_dir = os.path.join(log_dir, 'validation' + '_' + str(fCount))\n",
    "\n",
    "    def set_model(self, model):\n",
    "        # Setup writer for validation metrics\n",
    "        self.val_writer = tf.summary.FileWriter(self.val_log_dir)\n",
    "        super(TrainValTensorBoard, self).set_model(model)\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        # Pop the validation logs and handle them separately with\n",
    "        # `self.val_writer`. Also rename the keys so that they can\n",
    "        # be plotted on the same figure with the training metrics\n",
    "        logs = logs or {}\n",
    "        val_logs = {k.replace('val_', ''): v for k, v in logs.items() if k.startswith('val_')}\n",
    "        for name, value in val_logs.items():\n",
    "            summary = tf.Summary()\n",
    "            summary_value = summary.value.add()\n",
    "            summary_value.simple_value = value.item()\n",
    "            summary_value.tag = name\n",
    "            self.val_writer.add_summary(summary, epoch)\n",
    "        self.val_writer.flush()\n",
    "\n",
    "        # Pass the remaining logs to `TensorBoard.on_epoch_end`\n",
    "        logs = {k: v for k, v in logs.items() if not k.startswith('val_')}\n",
    "        super(TrainValTensorBoard, self).on_epoch_end(epoch, logs)\n",
    "\n",
    "    def on_train_end(self, logs=None):\n",
    "        super(TrainValTensorBoard, self).on_train_end(logs)\n",
    "        self.val_writer.close()\n",
    "        \n",
    "def getSensitivity(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    return true_positives / (possible_positives + K.epsilon())\n",
    "def getSpecificity(y_true, y_pred):\n",
    "    true_negatives = K.sum(K.round(K.clip((1-y_true) * (1-y_pred), 0, 1)))\n",
    "    possible_negatives = K.sum(K.round(K.clip(1-y_true, 0, 1)))\n",
    "    return true_negatives / (possible_negatives + K.epsilon())        \n",
    "\n",
    "\n",
    "def get_images(path, dataSpecs):\n",
    "    fileList = glob.glob(path) #'BengaliBMPConvert/*.bmp'   \n",
    "    num = len(fileList)\n",
    "    dataSpecs['classLength'].append(len(fileList))\n",
    "    x = np.array([(cv2.imread(fname)) for fname in fileList])\n",
    "    return x\n",
    "\n",
    "def get_labels_one_hot(num_classes, class_id, num_samples):\n",
    "    x = np.zeros((num_samples, num_classes))\n",
    "    x[np.arange(num_samples),class_id] = 1\n",
    "    return x\n",
    "\n",
    "def fourCNN():\n",
    "    model = Sequential()\n",
    "    # Layer 1\n",
    "    model.add(Conv2D(32, (3,3), activation='relu', input_shape=INPUT_SHAPE, data_format='channels_last'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    # Layer 2\n",
    "    model.add(Conv2D(32, (3,3), activation='relu')) \n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    # Layer 3    \n",
    "    model.add(Conv2D(32, (3,3), activation='relu'))  \n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    # Layer 4     \n",
    "    model.add(Conv2D(32, (3,3), activation='relu'))   \n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))    \n",
    "    # Layer 5     \n",
    "    #model.add(Conv2D(32, (3,3), activation='relu'))   \n",
    "    #model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    # Layer 6\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1024, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(2, activation='softmax'))\n",
    "    return model\n",
    "    \n",
    "def fiveCNN():\n",
    "    model = Sequential()\n",
    "    # Layer 1\n",
    "    model.add(Conv2D(32, (3,3), activation='relu', input_shape=INPUT_SHAPE, data_format='channels_last'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    # Layer 2\n",
    "    model.add(Conv2D(32, (3,3), activation='relu')) \n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    # Layer 3    \n",
    "    model.add(Conv2D(32, (3,3), activation='relu'))  \n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    # Layer 4     \n",
    "    model.add(Conv2D(32, (3,3), activation='relu'))   \n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))    \n",
    "    # Layer 5     \n",
    "    model.add(Conv2D(32, (3,3), activation='relu'))   \n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    # Layer 6\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1024, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(2, activation='softmax'))  \n",
    "    return model\n",
    "    \n",
    "def bigCNN():\n",
    "    model = Sequential()\n",
    "    # Layer 1\n",
    "    model.add(Conv2D(32, (3,3), activation='relu', input_shape=INPUT_SHAPE, data_format='channels_last'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    # Layer 2\n",
    "    model.add(Conv2D(64, (3,3), activation='relu')) \n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    # Layer 3    \n",
    "    model.add(Conv2D(124, (3,3), activation='relu'))  \n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    # Layer 4     \n",
    "    model.add(Conv2D(256, (3,3), activation='relu'))   \n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))    \n",
    "    # Layer 5     \n",
    "    model.add(Conv2D(512, (3,3), activation='relu'))   \n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    # Layer 6\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1024, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(2, activation='softmax'))  \n",
    "    return model\n",
    "\n",
    "def vgg():\n",
    "    vggModel = applications.VGG19(weights = 'imagenet', include_top=False, input_shape = INPUT_SHAPE)\n",
    "    # Add custom final layer\n",
    "    model = vggModel.output\n",
    "    model = Flatten()(model)\n",
    "    model = Dense(2, activation='softmax')(model)\n",
    "    model = keras.models.Model(inputs=vggModel.input, outputs=model)\n",
    "    return model\n",
    "\n",
    "def tlVGG(train_data, val_data):\n",
    "    print('Compute bottleneck features...')\n",
    "    vggModel = applications.VGG19(weights = \"imagenet\", include_top=False, input_shape = INPUT_SHAPE)\n",
    "    # Freeze all layers\n",
    "    for layer in vggModel.layers:\n",
    "        layer.trainable = False\n",
    "    # Add custom final layer\n",
    "    bNModel = vggModel.output\n",
    "    bNModel = Flatten()(bNModel)\n",
    "    final_model = keras.models.Model(inputs=vggModel.input, outputs=bNModel)\n",
    "    train_bNFeatures = {'img': 0, 'label': train_data['label']}\n",
    "    val_bNFeatures = {'img': 0, 'label': val_data['label']}\n",
    "    train_bNFeatures['img'] = final_model.predict(train_data['img'], batch_size=16)\n",
    "    val_bNFeatures['img'] = final_model.predict(val_data['img'], batch_size=16)\n",
    "    #Undo one hot - ROC does not work with onehot\n",
    "    val_bNFeatures.update({'labelIndex': np.where(val_data['label']==1)[1]})\n",
    "    print('train_bNFeatures[img].shape = ', train_bNFeatures['img'].shape)\n",
    "    print('val_bNFeatures[img].shape = ', val_bNFeatures['img'].shape)\n",
    "\n",
    "    print('Train head...')\n",
    "    head = Sequential()\n",
    "    #head.add(Dense(32, input_dim=train_bNFeatures['img'].shape[1], activation='relu'))\n",
    "    head.add(Dense(2, activation='softmax'))    \n",
    "    return head, train_bNFeatures, val_bNFeatures\n",
    "\n",
    "    # Why oh why are they in a directory structure like this\n",
    "def getPremFiles(imgPath, dataSpecs):\n",
    "    import pydicom\n",
    "    from fnmatch import fnmatch\n",
    "    # First get all the 6mm lesions\n",
    "    fileList = []\n",
    "    for path, subdirs, files in os.walk(imgPath):\n",
    "        for name in files:\n",
    "            if fnmatch(name, '2D_dim2d.dcm'):\n",
    "                fileList.append(os.path.join(path, name))\n",
    "    # I can't remember why I thought dataSpecs was a good idea\n",
    "    # I suppose this means that class 0 needs to be loaded in first\n",
    "    dataSpecs['classLength'].append(len(fileList))\n",
    "    \n",
    "    # Load the files from filelist into an array\n",
    "    print(len(fileList), ' Files found')\n",
    "    print('Loading images...')\n",
    "    dicomImg = np.asarray([])\n",
    "    count = 0\n",
    "    for f in fileList:\n",
    "        dicomImg = np.append(dicomImg, pydicom.dcmread(f).pixel_array)\n",
    "        count += 1\n",
    "        print(count, '/', len(fileList))\n",
    "    return dicomImg\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "def main():\n",
    "    import keras\n",
    "    print('keras version: ', keras.__version__)\n",
    "    print('TensorFlow version: ', tf.__version__)\n",
    "    print('\\nLoad images...')\n",
    "    \n",
    "    # Get images and labels\n",
    "    data = {'img': 0, 'label': 0}\n",
    "    dataSpecs = {'classLength': []}\n",
    "    dataSpecs['classLength'] = []\n",
    "    \n",
    "    # Comment out for prem images\n",
    "#     data['img'] = np.concatenate((\n",
    "#             get_images(CLASSDIR_0, dataSpecs), # Class 0 (backgrounds)\n",
    "#             get_images(CLASSDIR_1, dataSpecs) # Class 1 \n",
    "#     ))      \n",
    "\n",
    "    past1 = get_images(CLASSDIR_0, dataSpecs)\n",
    "    past2 = get_images(CLASSDIR_1, dataSpecs)\n",
    "    pastConcat = np.concatenate((past1, past2))\n",
    "\n",
    "\n",
    "    # Prem images\n",
    "    prem1 = getPremFiles('/vol/vssp/cvpwrkspc01/scratch/wm0015/download/prem/Segments', dataSpecs)\n",
    "    prem2 = getPremFiles('/vol/vssp/cvpwrkspc01/scratch/wm0015/download/prem/2D/6mm', dataSpecs)\n",
    "    prem1 = prem1.reshape((-1, 429, 429, 1))\n",
    "    prem1 = prem1[0:537,:,:,:]\n",
    "    prem2 = prem2.reshape((-1, 429, 429, 1))\n",
    "#     print('prem1.shape: ', prem1.shape)\n",
    "#     print('prem2.shape: ', prem2.shape)\n",
    "#     print('past1.shape: ', past1.shape)\n",
    "#     print('past2.shape: ', past2.shape)\n",
    "#     print('pastConcat.shape: ', pastConcat.shape)\n",
    "#     print('prem1[0].shape: ', prem1[0].shape)\n",
    "#     print('prem2[0].shape: ', prem2[0].shape)\n",
    "    data['img'] = np.concatenate((prem1, prem2))\n",
    "    data['img'] = np.concatenate((data['img'], data['img'], data['img']), axis = 3)\n",
    "    print('prem1.shape: ', prem1.shape)\n",
    "    print('prem2.shape: ', prem2.shape)\n",
    "    print('data.shape = ', data['img'].shape)\n",
    "    #data.shape =  (1707, 429, 429, 1)\n",
    "\n",
    "\n",
    "    # Normalise\n",
    "    data['img'] = data['img']/NORMALISE   \n",
    "    # Print image    \n",
    "#     img_calc = data['img']   \n",
    "#     plt.imshow(img_calc[0], cmap='gray')\n",
    "#     plt.show()\n",
    "    \n",
    "    # Create one hot labels\n",
    "    labels_bg = get_labels_one_hot(2, 0, dataSpecs['classLength'][0])  \n",
    "    labels_calc = get_labels_one_hot(2, 1, dataSpecs['classLength'][1])\n",
    "    data['label'] = np.concatenate((\n",
    "            get_labels_one_hot(2, 0, dataSpecs['classLength'][0]), # Class 0 \n",
    "            get_labels_one_hot(2, 1, dataSpecs['classLength'][1]) # Class 1\n",
    "    ))\n",
    "    # Drop from 3 colour channels to 1 (greyscale)\n",
    "    if 1==0:\n",
    "        data['img'] = data['img'][:,:,:,0]\n",
    "        data['img'] = np.reshape(data['img'], (data['img'].shape[0],data['img'].shape[1],data['img'].shape[2],1))\n",
    "        print('new data shape = ', data['img'].shape)\n",
    "    \n",
    "    valStats = []\n",
    "    for crossVal in range(FOLDS):\n",
    "\n",
    "        # Shuffle data\n",
    "        seed = 33\n",
    "        #np.random.seed(seed) # Has to be set before each use of random\n",
    "        shuffleMask = np.random.permutation(data['img'].shape[0])    \n",
    "        data['img'] = data['img'][shuffleMask, :, :, :]\n",
    "        data['label'] = data['label'][shuffleMask, :]\n",
    "\n",
    "        # Split traing and validation data        \n",
    "        splitRatio = 0.9\n",
    "        splitPoint = math.floor(data['img'].shape[0]*splitRatio)\n",
    "        train_data = {'img': data['img'][0:splitPoint], 'label': data['label'][0:splitPoint]}\n",
    "        val_data = {'img': data['img'][splitPoint:], 'label': data['label'][splitPoint:]}\n",
    "        #Undo one hot - ROC does not work with onehot\n",
    "        val_data.update({'labelIndex': np.where(val_data['label']==1)[1]})\n",
    "\n",
    "        \n",
    "\n",
    "        #model, train_data, val_data = tlVGG(train_data, val_data)\n",
    "        model = fiveCNN()\n",
    "        model = multi_gpu_model(model, gpus=2)\n",
    "        if ARCHITECTURE != 0:\n",
    "            model.summary()  \n",
    "        \n",
    "        sgd = optimizers.SGD(lr=5, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "        adam = optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False) #0.001\n",
    "        model.compile(loss='binary_crossentropy',\n",
    "                    optimizer=adam,\n",
    "                     metrics=['accuracy', getSensitivity, getSpecificity])\n",
    "        tensorboard = TensorBoard(log_dir='/vol/vssp/mammo2/will/logs/new'.format(time()), write_images=True)\n",
    "\n",
    "        # Data augmentation settings\n",
    "        if (1 == 2):\n",
    "            from keras.preprocessing.image import ImageDataGenerator\n",
    "            trainDatagen = ImageDataGenerator(\n",
    "                featurewise_center=True,\n",
    "                featurewise_std_normalization=True,\n",
    "                rotation_range=20,\n",
    "                width_shift_range=0.2,\n",
    "                height_shift_range=0.2,\n",
    "                horizontal_flip=True)\n",
    "            trainDatagen.fit(train_data['img'])\n",
    "            valDatagen = ImageDataGenerator(\n",
    "                featurewise_center=True,\n",
    "                featurewise_std_normalization=True,\n",
    "                #rotation_range=20,\n",
    "                #width_shift_range=0.2,\n",
    "                #height_shift_range=0.2,\n",
    "                #horizontal_flip=True\n",
    "                )\n",
    "            valDatagen.fit(val_data['img'])\n",
    "        \n",
    "#         # Normalise myself\n",
    "#         mean_data = np.mean(train_data['img'])\n",
    "#         std_data = np.std(train_data['img'])\n",
    "#         train_data['img'] = (train_data['img']-mean_data)/std_data\n",
    "#         val_data['img'] = (val_data['img']-mean_data/std_data)\n",
    "        \n",
    "#        # Train, with data augmentation\n",
    "#         print('Train...')\n",
    "#         model.fit_generator(trainDatagen.flow(train_data['img'], train_data['label'], batch_size=32),\n",
    "#                     steps_per_epoch=len(train_data['img']) / 32, epochs=EPOCHS, verbose=VERBOSE,\n",
    "#                            callbacks=[\n",
    "#                                TrainValTensorBoard(write_graph=False),\n",
    "#                                EarlyStopping(monitor='val_loss', patience=PATIENCE, verbose=1),\n",
    "#                                ModelCheckpoint(filepath=MODEL_SAVE, monitor='val_accuracy', save_best_only=True)],\n",
    "#                            validation_data=valDatagen.flow(x = val_data['img'], y = val_data['label']))\n",
    "        \n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "        # Train\n",
    "        print('Train...')\n",
    "        model.fit(train_data['img'], train_data['label'], \n",
    "                batch_size=BATCH_SIZE, epochs=EPOCHS, verbose=VERBOSE,\n",
    "                callbacks=[\n",
    "                    TrainValTensorBoard(write_graph=False),\n",
    "                    EarlyStopping(monitor='val_loss', patience=PATIENCE, verbose=1),\n",
    "                    ModelCheckpoint(filepath=MODEL_SAVE, monitor='val_accuracy', save_best_only=True)],\n",
    "                validation_data=(val_data['img'], val_data['label']))\n",
    "        \n",
    "        # Restore best model\n",
    "        #model.load_weights(MODEL_SAVE)\n",
    "        \n",
    "        # Produce ROC curve\n",
    "        \n",
    "        y_pred_keras = model.predict(val_data['img'])  \n",
    "        y_true = val_data['labelIndex']\n",
    "        y_score = y_pred_keras[:,1]\n",
    "        fpr_keras, tpr_keras, thresholds_keras = roc_curve(y_true, y_score)\n",
    "        from sklearn.metrics import auc\n",
    "        auc_keras = auc(fpr_keras, tpr_keras)\n",
    "        plt.figure(1)\n",
    "        plt.plot([0, 1], [0, 1], 'k--')\n",
    "        plt.plot(fpr_keras, tpr_keras, label='Keras (area = {:.3f})'.format(auc_keras))\n",
    "        plt.xlabel('False positive rate')\n",
    "        plt.ylabel('True positive rate')\n",
    "        plt.title('ROC curve')\n",
    "        plt.legend(loc='best')\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "        # Evaluate\n",
    "        score = model.evaluate(val_data['img'], val_data['label'], verbose=0)\n",
    "        valStats.append(score)\n",
    "        print('The score is......\\n', score)\n",
    "  \n",
    "\n",
    "    valStats = np.asarray(valStats)\n",
    "    print('Validations: \\n', valStats[:, 1])\n",
    "    print('Average loss: ', sum(valStats[:, 0])/FOLDS)\n",
    "    print('Average validation: ', sum(valStats[:, 1])/FOLDS)\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-05T16:34:48.948581Z",
     "start_time": "2018-08-05T16:34:48.943230Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello world\n"
     ]
    }
   ],
   "source": [
    "print('hello world')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-06T10:27:54.188540Z",
     "start_time": "2018-08-06T10:27:54.183265Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9, 2)\n"
     ]
    }
   ],
   "source": [
    "x = np.asarray(range(9))\n",
    "x.shape = (-1, 1)\n",
    "x = np.concatenate((x,x), axis = 1)\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-13T13:06:34.579475Z",
     "start_time": "2018-07-13T13:06:34.562536Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[6.53083827 0.59259259]\n",
      " [0.16470135 0.94444444]\n",
      " [0.15422182 0.94444444]\n",
      " [0.19875195 0.9382716 ]] \n",
      "\n",
      "6.5308382717179665\n",
      "[6.53083827 0.16470135 0.15422182 0.19875195]\n",
      "(4, 2)\n"
     ]
    }
   ],
   "source": [
    "x = [[6.5308382717179665, 0.5925925925925926], [0.16470135086112553, 0.9444444444444444], [0.15422181794304907, 0.9444444444444444], [0.19875195217721256, 0.9382716049382716]] \n",
    "x = np.asarray(x)\n",
    "print(x, '\\n')\n",
    "print(x[0][0])\n",
    "print(x[:, 0])\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "144px",
    "left": "1504px",
    "right": "20px",
    "top": "140px",
    "width": "350px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
