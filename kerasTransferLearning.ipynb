{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-10T10:31:02.898141Z",
     "start_time": "2018-07-10T10:30:59.560699Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Fold\n",
    "from keras import applications\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import optimizers\n",
    "from keras.models import Sequential, Model \n",
    "from keras.layers import Dropout, Flatten, Dense, GlobalAveragePooling2D\n",
    "from keras import backend as k \n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler, TensorBoard, EarlyStopping\n",
    "\n",
    "img_width, img_height = 256, 256\n",
    "train_data_dir = \"data/train\"\n",
    "validation_data_dir = \"data/val\"\n",
    "nb_train_samples = 4125\n",
    "nb_validation_samples = 466 \n",
    "batch_size = 16\n",
    "epochs = 50\n",
    "\n",
    "model = applications.VGG19(weights = \"imagenet\", include_top=False, input_shape = (img_width, img_height, 1))\n",
    "\n",
    "\"\"\"\n",
    "Layer (type)                 Output Shape              Param #   \n",
    "=================================================================\n",
    "input_1 (InputLayer)         (None, 256, 256, 3)       0         \n",
    "_________________________________________________________________\n",
    "block1_conv1 (Conv2D)        (None, 256, 256, 64)      1792      \n",
    "_________________________________________________________________\n",
    "block1_conv2 (Conv2D)        (None, 256, 256, 64)      36928     \n",
    "_________________________________________________________________\n",
    "block1_pool (MaxPooling2D)   (None, 128, 128, 64)      0         \n",
    "_________________________________________________________________\n",
    "block2_conv1 (Conv2D)        (None, 128, 128, 128)     73856     \n",
    "_________________________________________________________________\n",
    "block2_conv2 (Conv2D)        (None, 128, 128, 128)     147584    \n",
    "_________________________________________________________________\n",
    "block2_pool (MaxPooling2D)   (None, 64, 64, 128)       0         \n",
    "_________________________________________________________________\n",
    "block3_conv1 (Conv2D)        (None, 64, 64, 256)       295168    \n",
    "_________________________________________________________________\n",
    "block3_conv2 (Conv2D)        (None, 64, 64, 256)       590080    \n",
    "_________________________________________________________________\n",
    "block3_conv3 (Conv2D)        (None, 64, 64, 256)       590080    \n",
    "_________________________________________________________________\n",
    "block3_conv4 (Conv2D)        (None, 64, 64, 256)       590080    \n",
    "_________________________________________________________________\n",
    "block3_pool (MaxPooling2D)   (None, 32, 32, 256)       0         \n",
    "_________________________________________________________________\n",
    "block4_conv1 (Conv2D)        (None, 32, 32, 512)       1180160   \n",
    "_________________________________________________________________\n",
    "block4_conv2 (Conv2D)        (None, 32, 32, 512)       2359808   \n",
    "_________________________________________________________________\n",
    "block4_conv3 (Conv2D)        (None, 32, 32, 512)       2359808   \n",
    "_________________________________________________________________\n",
    "block4_conv4 (Conv2D)        (None, 32, 32, 512)       2359808   \n",
    "_________________________________________________________________\n",
    "block4_pool (MaxPooling2D)   (None, 16, 16, 512)       0         \n",
    "_________________________________________________________________\n",
    "block5_conv1 (Conv2D)        (None, 16, 16, 512)       2359808   \n",
    "_________________________________________________________________\n",
    "block5_conv2 (Conv2D)        (None, 16, 16, 512)       2359808   \n",
    "_________________________________________________________________\n",
    "block5_conv3 (Conv2D)        (None, 16, 16, 512)       2359808   \n",
    "_________________________________________________________________\n",
    "block5_conv4 (Conv2D)        (None, 16, 16, 512)       2359808   \n",
    "_________________________________________________________________\n",
    "block5_pool (MaxPooling2D)   (None, 8, 8, 512)         0         \n",
    "=================================================================\n",
    "Total params: 20,024,384.0\n",
    "Trainable params: 20,024,384.0\n",
    "Non-trainable params: 0.0\n",
    "\"\"\"\n",
    "\n",
    "# Freeze the layers which you don't want to train. Here I am freezing the first 5 layers.\n",
    "for layer in model.layers[:5]:\n",
    "    layer.trainable = False\n",
    "\n",
    "#Adding custom Layers \n",
    "x = model.output\n",
    "x = Flatten()(x)\n",
    "x = Dense(1024, activation=\"relu\")(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(1024, activation=\"relu\")(x)\n",
    "predictions = Dense(16, activation=\"softmax\")(x)\n",
    "\n",
    "# creating the final model \n",
    "model_final = Model(input = model.input, output = predictions)\n",
    "\n",
    "# compile the model \n",
    "model_final.compile(loss = \"categorical_crossentropy\", optimizer = optimizers.SGD(lr=0.0001, momentum=0.9), metrics=[\"accuracy\"])\n",
    "\n",
    "# Initiate the train and test generators with data Augumentation \n",
    "train_datagen = ImageDataGenerator(\n",
    "rescale = 1./255,\n",
    "horizontal_flip = True,\n",
    "fill_mode = \"nearest\",\n",
    "zoom_range = 0.3,\n",
    "width_shift_range = 0.3,\n",
    "height_shift_range=0.3,\n",
    "rotation_range=30)\n",
    "\n",
    "test_datagen = ImageDataGenerator(\n",
    "rescale = 1./255,\n",
    "horizontal_flip = True,\n",
    "fill_mode = \"nearest\",\n",
    "zoom_range = 0.3,\n",
    "width_shift_range = 0.3,\n",
    "height_shift_range=0.3,\n",
    "rotation_range=30)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "train_data_dir,\n",
    "target_size = (img_height, img_width),\n",
    "batch_size = batch_size, \n",
    "class_mode = \"categorical\")\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "validation_data_dir,\n",
    "target_size = (img_height, img_width),\n",
    "class_mode = \"categorical\")\n",
    "\n",
    "# Save the model according to the conditions  \n",
    "checkpoint = ModelCheckpoint(\"vgg16_1.h5\", monitor='val_acc', verbose=1, save_best_only=True, save_weights_only=False, mode='auto', period=1)\n",
    "early = EarlyStopping(monitor='val_acc', min_delta=0, patience=10, verbose=1, mode='auto')\n",
    "\n",
    "\n",
    "# Train the model \n",
    "model_final.fit_generator(\n",
    "train_generator,\n",
    "samples_per_epoch = nb_train_samples,\n",
    "epochs = epochs,\n",
    "validation_data = validation_generator,\n",
    "nb_val_samples = nb_validation_samples,\n",
    "callbacks = [checkpoint, early])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-10T13:08:39.960045Z",
     "start_time": "2018-07-10T13:03:59.008367Z"
    },
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started\n",
      "dataSpecs =  {'classLength': [901]}\n",
      "dataSpecs =  {'classLength': [901, 719]}\n",
      "*** data[img].shape =  (1620, 385, 385, 3)\n",
      "[64 64 64]\n",
      "[64 64 64]\n",
      "[61 61 61]\n",
      "[53 53 53]\n",
      "[47 47 47]\n",
      "[43 43 43]\n",
      "[40 40 40]\n",
      "[36 36 36]\n",
      "[32 32 32]\n",
      "[29 29 29]\n",
      "[30 30 30]\n",
      "[32 32 32]\n",
      "[32 32 32]\n",
      "[36 36 36]\n",
      "[42 42 42]\n",
      "[44 44 44]\n",
      "[44 44 44]\n",
      "[49 49 49]\n",
      "[55 55 55]\n",
      "[58 58 58]\n",
      "[59 59 59]\n",
      "[58 58 58]\n",
      "[56 56 56]\n",
      "[58 58 58]\n",
      "[61 61 61]\n",
      "[62 62 62]\n",
      "[60 60 60]\n",
      "[59 59 59]\n",
      "[60 60 60]\n",
      "[62 62 62]\n",
      "[61 61 61]\n",
      "[57 57 57]\n",
      "[53 53 53]\n",
      "[49 49 49]\n",
      "[44 44 44]\n",
      "[46 46 46]\n",
      "[53 53 53]\n",
      "[57 57 57]\n",
      "[58 58 58]\n",
      "[60 60 60]\n",
      "[61 61 61]\n",
      "[62 62 62]\n",
      "[69 69 69]\n",
      "[78 78 78]\n",
      "[82 82 82]\n",
      "[84 84 84]\n",
      "[89 89 89]\n",
      "[94 94 94]\n",
      "[100 100 100]\n",
      "[106 106 106]\n",
      "[109 109 109]\n",
      "[106 106 106]\n",
      "[101 101 101]\n",
      "[96 96 96]\n",
      "[86 86 86]\n",
      "[77 77 77]\n",
      "[73 73 73]\n",
      "[73 73 73]\n",
      "[72 72 72]\n",
      "[71 71 71]\n",
      "[75 75 75]\n",
      "[86 86 86]\n",
      "[95 95 95]\n",
      "[100 100 100]\n",
      "[103 103 103]\n",
      "[109 109 109]\n",
      "[122 122 122]\n",
      "[134 134 134]\n",
      "[136 136 136]\n",
      "[130 130 130]\n",
      "[125 125 125]\n",
      "[121 121 121]\n",
      "[116 116 116]\n",
      "[113 113 113]\n",
      "[107 107 107]\n",
      "[97 97 97]\n",
      "[89 89 89]\n",
      "[87 87 87]\n",
      "[85 85 85]\n",
      "[83 83 83]\n",
      "[81 81 81]\n",
      "[79 79 79]\n",
      "[79 79 79]\n",
      "[85 85 85]\n",
      "[92 92 92]\n",
      "[93 93 93]\n",
      "[90 90 90]\n",
      "[88 88 88]\n",
      "[85 85 85]\n",
      "[87 87 87]\n",
      "[94 94 94]\n",
      "[98 98 98]\n",
      "[94 94 94]\n",
      "[92 92 92]\n",
      "[99 99 99]\n",
      "[111 111 111]\n",
      "[116 116 116]\n",
      "[113 113 113]\n",
      "[114 114 114]\n",
      "[120 120 120]\n",
      "[122 122 122]\n",
      "[122 122 122]\n",
      "[121 121 121]\n",
      "[120 120 120]\n",
      "[119 119 119]\n",
      "[115 115 115]\n",
      "[107 107 107]\n",
      "[107 107 107]\n",
      "[116 116 116]\n",
      "[121 121 121]\n",
      "[122 122 122]\n",
      "[124 124 124]\n",
      "[126 126 126]\n",
      "[128 128 128]\n",
      "[129 129 129]\n",
      "[125 125 125]\n",
      "[120 120 120]\n",
      "[120 120 120]\n",
      "[125 125 125]\n",
      "[127 127 127]\n",
      "[121 121 121]\n",
      "[118 118 118]\n",
      "[119 119 119]\n",
      "[119 119 119]\n",
      "[118 118 118]\n",
      "[115 115 115]\n",
      "[111 111 111]\n",
      "[111 111 111]\n",
      "[116 116 116]\n",
      "[114 114 114]\n",
      "[108 108 108]\n",
      "[106 106 106]\n",
      "[115 115 115]\n",
      "[124 124 124]\n",
      "[124 124 124]\n",
      "[115 115 115]\n",
      "[108 108 108]\n",
      "[107 107 107]\n",
      "[108 108 108]\n",
      "[107 107 107]\n",
      "[99 99 99]\n",
      "[88 88 88]\n",
      "[79 79 79]\n",
      "[77 77 77]\n",
      "[81 81 81]\n",
      "[84 84 84]\n",
      "[82 82 82]\n",
      "[78 78 78]\n",
      "[76 76 76]\n",
      "[75 75 75]\n",
      "[73 73 73]\n",
      "[77 77 77]\n",
      "[84 84 84]\n",
      "[86 86 86]\n",
      "[81 81 81]\n",
      "[77 77 77]\n",
      "[78 78 78]\n",
      "[79 79 79]\n",
      "[77 77 77]\n",
      "[70 70 70]\n",
      "[63 63 63]\n",
      "[61 61 61]\n",
      "[57 57 57]\n",
      "[52 52 52]\n",
      "[56 56 56]\n",
      "[65 65 65]\n",
      "[70 70 70]\n",
      "[71 71 71]\n",
      "[70 70 70]\n",
      "[68 68 68]\n",
      "[67 67 67]\n",
      "[69 69 69]\n",
      "[76 76 76]\n",
      "[84 84 84]\n",
      "[89 89 89]\n",
      "[89 89 89]\n",
      "[85 85 85]\n",
      "[84 84 84]\n",
      "[84 84 84]\n",
      "[83 83 83]\n",
      "[85 85 85]\n",
      "[91 91 91]\n",
      "[92 92 92]\n",
      "[85 85 85]\n",
      "[83 83 83]\n",
      "[89 89 89]\n",
      "[92 92 92]\n",
      "[87 87 87]\n",
      "[80 80 80]\n",
      "[76 76 76]\n",
      "[78 78 78]\n",
      "[88 88 88]\n",
      "[104 104 104]\n",
      "[115 115 115]\n",
      "[114 114 114]\n",
      "[105 105 105]\n",
      "[98 98 98]\n",
      "[97 97 97]\n",
      "[97 97 97]\n",
      "[93 93 93]\n",
      "[86 86 86]\n",
      "[83 83 83]\n",
      "[81 81 81]\n",
      "[78 78 78]\n",
      "[73 73 73]\n",
      "[69 69 69]\n",
      "[68 68 68]\n",
      "[62 62 62]\n",
      "[50 50 50]\n",
      "[36 36 36]\n",
      "[26 26 26]\n",
      "[23 23 23]\n",
      "[24 24 24]\n",
      "[28 28 28]\n",
      "[36 36 36]\n",
      "[44 44 44]\n",
      "[48 48 48]\n",
      "[53 53 53]\n",
      "[56 56 56]\n",
      "[53 53 53]\n",
      "[48 48 48]\n",
      "[45 45 45]\n",
      "[45 45 45]\n",
      "[44 44 44]\n",
      "[41 41 41]\n",
      "[37 37 37]\n",
      "[34 34 34]\n",
      "[30 30 30]\n",
      "[22 22 22]\n",
      "[16 16 16]\n",
      "[14 14 14]\n",
      "[17 17 17]\n",
      "[21 21 21]\n",
      "[25 25 25]\n",
      "[27 27 27]\n",
      "[29 29 29]\n",
      "[29 29 29]\n",
      "[29 29 29]\n",
      "[30 30 30]\n",
      "[35 35 35]\n",
      "[40 40 40]\n",
      "[49 49 49]\n",
      "[60 60 60]\n",
      "[66 66 66]\n",
      "[62 62 62]\n",
      "[56 56 56]\n",
      "[54 54 54]\n",
      "[58 58 58]\n",
      "[67 67 67]\n",
      "[75 75 75]\n",
      "[80 80 80]\n",
      "[83 83 83]\n",
      "[87 87 87]\n",
      "[90 90 90]\n",
      "[92 92 92]\n",
      "[91 91 91]\n",
      "[84 84 84]\n",
      "[72 72 72]\n",
      "[59 59 59]\n",
      "[51 51 51]\n",
      "[49 49 49]\n",
      "[50 50 50]\n",
      "[52 52 52]\n",
      "[53 53 53]\n",
      "[52 52 52]\n",
      "[48 48 48]\n",
      "[44 44 44]\n",
      "[44 44 44]\n",
      "[50 50 50]\n",
      "[55 55 55]\n",
      "[60 60 60]\n",
      "[67 67 67]\n",
      "[77 77 77]\n",
      "[84 84 84]\n",
      "[89 89 89]\n",
      "[97 97 97]\n",
      "[108 108 108]\n",
      "[115 115 115]\n",
      "[120 120 120]\n",
      "[124 124 124]\n",
      "[130 130 130]\n",
      "[137 137 137]\n",
      "[134 134 134]\n",
      "[118 118 118]\n",
      "[99 99 99]\n",
      "[87 87 87]\n",
      "[83 83 83]\n",
      "[80 80 80]\n",
      "[77 77 77]\n",
      "[73 73 73]\n",
      "[69 69 69]\n",
      "[67 67 67]\n",
      "[68 68 68]\n",
      "[68 68 68]\n",
      "[64 64 64]\n",
      "[61 61 61]\n",
      "[63 63 63]\n",
      "[68 68 68]\n",
      "[74 74 74]\n",
      "[81 81 81]\n",
      "[84 84 84]\n",
      "[82 82 82]\n",
      "[80 80 80]\n",
      "[83 83 83]\n",
      "[90 90 90]\n",
      "[98 98 98]\n",
      "[101 101 101]\n",
      "[97 97 97]\n",
      "[91 91 91]\n",
      "[90 90 90]\n",
      "[93 93 93]\n",
      "[95 95 95]\n",
      "[93 93 93]\n",
      "[91 91 91]\n",
      "[92 92 92]\n",
      "[95 95 95]\n",
      "[93 93 93]\n",
      "[86 86 86]\n",
      "[82 82 82]\n",
      "[86 86 86]\n",
      "[92 92 92]\n",
      "[93 93 93]\n",
      "[89 89 89]\n",
      "[88 88 88]\n",
      "[95 95 95]\n",
      "[103 103 103]\n",
      "[105 105 105]\n",
      "[104 104 104]\n",
      "[102 102 102]\n",
      "[95 95 95]\n",
      "[88 88 88]\n",
      "[88 88 88]\n",
      "[89 89 89]\n",
      "[82 82 82]\n",
      "[75 75 75]\n",
      "[73 73 73]\n",
      "[75 75 75]\n",
      "[75 75 75]\n",
      "[75 75 75]\n",
      "[76 76 76]\n",
      "[77 77 77]\n",
      "[77 77 77]\n",
      "[75 75 75]\n",
      "[73 73 73]\n",
      "[74 74 74]\n",
      "[75 75 75]\n",
      "[69 69 69]\n",
      "[59 59 59]\n",
      "[53 53 53]\n",
      "[52 52 52]\n",
      "[48 48 48]\n",
      "[44 44 44]\n",
      "[43 43 43]\n",
      "[42 42 42]\n",
      "[45 45 45]\n",
      "[50 50 50]\n",
      "[50 50 50]\n",
      "[43 43 43]\n",
      "[35 35 35]\n",
      "[30 30 30]\n",
      "[28 28 28]\n",
      "[26 26 26]\n",
      "[27 27 27]\n",
      "[30 30 30]\n",
      "[34 34 34]\n",
      "[38 38 38]\n",
      "[42 42 42]\n",
      "[46 46 46]\n",
      "[48 48 48]\n",
      "[47 47 47]\n",
      "[42 42 42]\n",
      "[41 41 41]\n",
      "[47 47 47]\n",
      "[55 55 55]\n",
      "[61 61 61]\n",
      "[63 63 63]\n",
      "[63 63 63]\n",
      "[62 62 62]\n",
      "[61 61 61]\n",
      "[63 63 63]\n",
      "[71 71 71]\n",
      "[78 78 78]\n",
      "[79 79 79]\n",
      "[79 79 79]\n",
      "[79 79 79]\n",
      "dataSpecs =  [901, 719]\n",
      "719\n",
      "new data shape =  (1620, 385, 385, 1)\n",
      "train_data[img].shape =  (1458, 385, 385, 1)\n",
      "train_data[label].shape =  (1458, 2)\n",
      "validation_data[img].shape =  (162, 385, 385, 1)\n",
      "valdiation_data[label].shape =  (162, 2)\n",
      "(60000, 1, 28, 28)\n",
      "(60000, 10)\n",
      "Epoch 1/6\n",
      "60000/60000 [==============================] - 46s 760us/step - loss: 0.1149 - acc: 0.9654\n",
      "Epoch 2/6\n",
      "60000/60000 [==============================] - 45s 744us/step - loss: 0.0514 - acc: 0.9846\n",
      "Epoch 3/6\n",
      "60000/60000 [==============================] - 45s 754us/step - loss: 0.0376 - acc: 0.9888\n",
      "Epoch 4/6\n",
      "60000/60000 [==============================] - 45s 751us/step - loss: 0.0298 - acc: 0.9911\n",
      "Epoch 5/6\n",
      "60000/60000 [==============================] - 45s 746us/step - loss: 0.0262 - acc: 0.9927\n",
      "Epoch 6/6\n",
      "60000/60000 [==============================] - 43s 724us/step - loss: 0.0234 - acc: 0.9930\n",
      "The score is......\n",
      " [0.006169231473230957, 0.9982333333333333]\n"
     ]
    }
   ],
   "source": [
    "# fold\n",
    "import cv2\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "from keras.models import Sequential\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.utils import np_utils\n",
    "from keras import optimizers\n",
    "# add magic\n",
    "from keras import backend as K\n",
    "K.set_image_dim_ordering('th')\n",
    "\n",
    "def get_images(path, dataSpecs):\n",
    "    fileList = glob.glob(path) #'BengaliBMPConvert/*.bmp'   \n",
    "    num = len(fileList)\n",
    "    dataSpecs['classLength'].append(len(fileList))\n",
    "    print('dataSpecs = ', dataSpecs)\n",
    "    x = np.array([(cv2.imread(fname)) for fname in fileList])\n",
    "    return x\n",
    "\n",
    "def get_labels_one_hot(num_classes, class_id, num_samples):\n",
    "    x = np.zeros((num_samples, num_classes))\n",
    "    x[np.arange(num_samples),class_id] = 1\n",
    "    return x\n",
    " \n",
    "    \n",
    "    \n",
    "def main():\n",
    "    # Get images and labels\n",
    "    print('Started')\n",
    "    data = {'img': 0, 'label': 0}\n",
    "    dataSpecs = {'classLength': []}\n",
    "    dataSpecs['classLength'] = []\n",
    "    data['img'] = np.concatenate((\n",
    "            #get_images('/vol/vssp/mammo2/will/data/simulated/calcs/small_sample/0/*', dataSpecs), # Class 0\n",
    "            #get_images('/vol/vssp/mammo2/will/data/simulated/calcs/small_sample/1/*', dataSpecs) # Class 1\n",
    "            get_images('/user/HS204/wm0015/student/allCalcs/0/*', dataSpecs), # Class 0\n",
    "            get_images('/user/HS204/wm0015/student/allCalcs/1/*', dataSpecs) # Class 1\n",
    "    ))  \n",
    "    print('*** data[img].shape = ', data['img'].shape)\n",
    "    for _ in range(385):\n",
    "        print(data['img'][0,_,50,:]) \n",
    "    print('dataSpecs = ', dataSpecs['classLength'])\n",
    "    print(dataSpecs['classLength'][1])\n",
    "    labels_bg = get_labels_one_hot(2, 0, dataSpecs['classLength'][0])  \n",
    "    labels_calc = get_labels_one_hot(2, 1, dataSpecs['classLength'][1])\n",
    "    data['label'] = np.concatenate((\n",
    "            get_labels_one_hot(2, 0, dataSpecs['classLength'][0]), # Class 0 \n",
    "            get_labels_one_hot(2, 1, dataSpecs['classLength'][1]) # Class 1\n",
    "    ))\n",
    "    # Drop from 3 colour channels to 1 (greyscale)\n",
    "    data['img'] = data['img'][:,:,:,0]\n",
    "    data['img'] = np.reshape(data['img'], (data['img'].shape[0],data['img'].shape[1],data['img'].shape[2],1))\n",
    "    print('new data shape = ', data['img'].shape)\n",
    "    # Shuffle data\n",
    "#     seed = 33\n",
    "#     np.random.seed(seed) # Has to be set before each use of random\n",
    "#     shuffleMask = np.random.permutation(data['img'].shape[0])    \n",
    "#     data['img'] = data['img'][shuffleMask, :, :, :]\n",
    "#     data['label'] = data['label'][shuffleMask, :]\n",
    "    \n",
    "    # Split traing and validation data        \n",
    "    splitRatio = 0.9\n",
    "    splitPoint = math.floor(data['img'].shape[0]*splitRatio)\n",
    "    train_data = {'img': data['img'][0:splitPoint], 'label': data['label'][0:splitPoint]}\n",
    "    validation_data = {'img': data['img'][splitPoint:], 'label': data['label'][splitPoint:]}\n",
    "    print('train_data[img].shape = ', train_data['img'].shape)\n",
    "    print('train_data[label].shape = ', train_data['label'].shape)\n",
    "    print('validation_data[img].shape = ', validation_data['img'].shape)\n",
    "    print('valdiation_data[label].shape = ', validation_data['label'].shape)\n",
    "    \n",
    "    # Print image    \n",
    "    img_calc = train_data['img']/255    \n",
    "#     plt.imshow(img_calc[0], cmap='gray')\n",
    "#     plt.show()\n",
    "    \n",
    "    # Keras!\n",
    "    model = Sequential()\n",
    "    \n",
    "    # Layer 1\n",
    "    model.add(Conv2D(32, (3,3), activation='relu', input_shape=(1,28,28))) # (385, 385,1)\n",
    "    #model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    # Layer 2\n",
    "    model.add(Conv2D(32, (3,3), activation='relu'))   \n",
    "    #model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    # Layer 3    \n",
    "    model.add(Conv2D(32, (3,3), activation='relu'))  \n",
    "    #model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    # Layer 4     \n",
    "    model.add(Conv2D(32, (3,3), activation='relu'))   \n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    # Layer 5\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1024, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(10, activation='softmax'))\n",
    "    \n",
    "    \n",
    "    from keras.datasets import mnist\n",
    "    # Load pre-shuffled MNIST data into train and test sets\n",
    "    (X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "    X_train = X_train.reshape(X_train.shape[0], 1, 28, 28)\n",
    "    X_test = X_test.reshape(X_test.shape[0], 1, 28, 28)\n",
    "    print(X_train.shape)\n",
    "    X_train = X_train.astype('float32')\n",
    "    X_test = X_test.astype('float32')\n",
    "    X_train /= 255\n",
    "    X_test /= 255\n",
    "    # Convert 1-dimensional class arrays to 10-dimensional class matrices\n",
    "    Y_train = np_utils.to_categorical(y_train, 10)\n",
    "    Y_test = np_utils.to_categorical(y_test, 10)\n",
    "    print(Y_train.shape)\n",
    "    \n",
    "    sgd = optimizers.SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "    adam = optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "            optimizer=adam,\n",
    "            metrics=['accuracy']) # Accuracy will now be returned when evaluate is called\n",
    "    # Train\n",
    "#     model.fit(train_data['img'], train_data['label'], \n",
    "#           batch_size=100, epochs=100, verbose=1)\n",
    "    model.fit(X_train, Y_train, \n",
    "      batch_size=10, epochs=6, verbose=1)\n",
    "    \n",
    "    # Evaluate\n",
    "    # I think by default this returns the loss and accuracy\n",
    "    #score = model.evaluate(validation_data['img'], validation_data['label'], verbose=0)\n",
    "    score = model.evaluate(X_train, Y_train, verbose=0)\n",
    "    print('The score is......\\n', score)\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-10T11:38:43.242191Z",
     "start_time": "2018-07-10T11:36:50.408561Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 10)\n",
      "(60000, 1, 28, 28)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/user/HS204/wm0015/anaconda3/envs/tensorflow/lib/python3.6/site-packages/ipykernel_launcher.py:33: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), activation=\"relu\", input_shape=(1, 28, 28...)`\n",
      "/user/HS204/wm0015/anaconda3/envs/tensorflow/lib/python3.6/site-packages/ipykernel_launcher.py:34: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), activation=\"relu\")`\n",
      "/user/HS204/wm0015/anaconda3/envs/tensorflow/lib/python3.6/site-packages/ipykernel_launcher.py:50: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 12s 205us/step - loss: 0.2067 - acc: 0.9358\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 12s 193us/step - loss: 0.0864 - acc: 0.9746\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 11s 183us/step - loss: 0.0663 - acc: 0.9798\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 11s 175us/step - loss: 0.0554 - acc: 0.9828\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 11s 182us/step - loss: 0.0477 - acc: 0.9857\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 11s 178us/step - loss: 0.0436 - acc: 0.9865\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 10s 172us/step - loss: 0.0389 - acc: 0.9875\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 11s 187us/step - loss: 0.0354 - acc: 0.9889\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 11s 189us/step - loss: 0.0322 - acc: 0.9901\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 11s 189us/step - loss: 0.0297 - acc: 0.9905\n"
     ]
    }
   ],
   "source": [
    "# 3. Import libraries and modules\n",
    "import numpy as np\n",
    "from keras import backend as K\n",
    "K.set_image_dim_ordering('th')\n",
    "np.random.seed(123)  # for reproducibility\n",
    " \n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Convolution2D, MaxPooling2D\n",
    "from keras.utils import np_utils\n",
    "from keras.datasets import mnist\n",
    " \n",
    "# 4. Load pre-shuffled MNIST data into train and test sets\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    " \n",
    "# 5. Preprocess input data\n",
    "X_train = X_train.reshape(X_train.shape[0], 1, 28, 28)\n",
    "X_test = X_test.reshape(X_test.shape[0], 1, 28, 28)\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    " \n",
    "# 6. Preprocess class labels\n",
    "Y_train = np_utils.to_categorical(y_train, 10)\n",
    "Y_test = np_utils.to_categorical(y_test, 10)\n",
    "print(Y_train.shape)\n",
    "print(X_train.shape)\n",
    " \n",
    "# 7. Define model architecture\n",
    "model = Sequential()\n",
    " \n",
    "model.add(Convolution2D(32, 3, 3, activation='relu', input_shape=(1,28,28)))\n",
    "model.add(Convolution2D(32, 3, 3, activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    " \n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    " \n",
    "# 8. Compile model\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    " \n",
    "# 9. Fit model on training data\n",
    "model.fit(X_train, Y_train, \n",
    "          batch_size=32, nb_epoch=10, verbose=1)\n",
    " \n",
    "# 10. Evaluate model on test data\n",
    "score = model.evaluate(X_test, Y_test, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-09T13:35:51.405562Z",
     "start_time": "2018-07-09T13:35:51.396682Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 2  3  4  5  6  7  8  9 10]\n",
      " [ 2  3  4  5  6  7  8  9 10]\n",
      " [ 2  3  4  5  6  7  8  9 10]]\n",
      "(3, 9)\n",
      "__\n",
      "[0 8 4 5 2 6 3 1 7]\n",
      "[ 2 10  6  7  4  8  5  3  9]\n",
      "\n",
      "\n",
      "\n",
      "[[10  4  7  8  5  3  2  9  6]\n",
      " [10  4  7  8  5  3  2  9  6]\n",
      " [10  4  7  8  5  3  2  9  6]]\n"
     ]
    }
   ],
   "source": [
    "a = np.array([np.arange(9) for i in range(3)])\n",
    "a = a + 2\n",
    "print(a)\n",
    "print(a.shape)\n",
    "print('__')\n",
    "b = np.random.permutation(a.shape[1])\n",
    "print(b)\n",
    "print(a[1,b])\n",
    "print('\\n\\n')\n",
    "np.random.seed(10)  # Has to be set before each use of random\n",
    "a = a[:, np.random.permutation(a.shape[1])]\n",
    "print(a)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-09T09:47:26.059989Z",
     "start_time": "2018-07-09T09:47:26.056266Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello world\n"
     ]
    }
   ],
   "source": [
    "print('hello world')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-09T10:12:29.121519Z",
     "start_time": "2018-07-09T10:12:29.116872Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 2, 3]\n"
     ]
    }
   ],
   "source": [
    "# Mutable objects such as lists act as call by reference\n",
    "# Unmutable objects such as integers, strings act as call by value\n",
    "\n",
    "def test (f):\n",
    "    f[0] = 2\n",
    "x = [1, 2, 3]\n",
    "test(x)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-09T11:15:59.132995Z",
     "start_time": "2018-07-09T11:15:59.124275Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'test': [1, 2, 3]}\n",
      "[1, 2, 3, 99] \n",
      "\n",
      "{'test': [1, 2, 3]}\n",
      "{'test': [9, 9, 9]}\n",
      "\n",
      " [1, 2, 3]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def myFunc (x):\n",
    "    x = x+[99]\n",
    "    print(x, '\\n')\n",
    "def alterDict(x):\n",
    "    x['test'] = [9,9,9]\n",
    "def alterList(x):\n",
    "    x = x + [7]\n",
    "    \n",
    "myDict = {'test': [1,2,3]}\n",
    "print(myDict)\n",
    "myFunc(myDict['test'])\n",
    "\n",
    "print(myDict)\n",
    "alterDict(myDict)\n",
    "print(myDict)\n",
    "\n",
    "y = [1,2,3]\n",
    "alterList(y)\n",
    "print('\\n',y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-09T12:46:07.240758Z",
     "start_time": "2018-07-09T12:46:07.134902Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "144px",
    "left": "1504px",
    "right": "20px",
    "top": "140px",
    "width": "350px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
